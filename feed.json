{
    "version": "https://jsonfeed.org/version/1",
    "title": "pianetararo",
    "description": "",
    "home_page_url": "https://pianetararo.org",
    "feed_url": "https://pianetararo.org/feed.json",
    "user_comment": "",
    "icon": "https://pianetararo.org/media/website/PIANETARARO-1-1-1.svg",
    "author": {
        "name": "Pianetararo Associazione Culturale"
    },
    "items": [
        {
            "id": "https://pianetararo.org/modelli-chiusi-menti-aperte-soluzioni-ai-a-km-0/",
            "url": "https://pianetararo.org/modelli-chiusi-menti-aperte-soluzioni-ai-a-km-0/",
            "title": "Modelli chiusi, menti aperte. Soluzioni AI a Km 0.",
            "summary": "Se nel 2019 avessimo detto a un insegnante o a un genitore che nel giro di quattro anni avrebbero usato chatbot, correttori automatici e assistenti vocali basati su intelligenza artificiale, probabilmente ci avrebbero guardato con un misto di scetticismo e diffidenza. E invece eccoci qui.",
            "content_html": "<p><span style=\"font-weight: 400;\">Se nel 2019 avessimo detto a un insegnante o a un genitore che nel giro di quattro anni avrebbero usato chatbot, correttori automatici e assistenti vocali basati su intelligenza artificiale, probabilmente ci avrebbero guardato con un misto di scetticismo e diffidenza. E invece eccoci qui. L‚Äô<strong>AI √® entrata in classe, in casa, in ufficio</strong>. A volte ci semplifica la vita. Altre volte la complica.¬†</span></p>\n<p><span style=\"font-weight: 400;\">Dalle scuole alle imprese: l‚ÄôAI √® ovunque, ma a quale prezzo? L‚Äôadozione di strumenti di AI cresce a ritmo esponenziale in ogni settore. Nella scuola, applicazioni di tutoraggio intelligente e generatori di testi pongono questioni di metodo ma anche di sorveglianza e tutela dei dati degli studenti. In famiglia, assistenti domestici come Alexa o applicazioni basate sull‚ÄôAI aiutano con la spesa, la domotica, TV o persino intrattengono i bambini (senza contare i <a href=\"https://corporate.mattel.com/news/mattel-and-openai-announce-strategic-collaboration\">futuri giocattoli AI in arrivo</a>), ma raccolgono enormi quantit√† di informazioni personali. Nelle aziende l‚ÄôIA generativa viene sperimentata per customer service, analisi di dati e automazione, promettendo efficienza e nuovi modelli di business.</span></p>\n<p><span style=\"font-weight: 400;\">Ma ci siamo davvero fermati a porci le domande fondamentali ?¬†</span></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span style=\"font-weight: 400;\">Quali dati stiamo cedendo ogni giorno agli strumenti di AI generativa? (un po' ne abbiamo parlato <a href=\"https://pianetararo.org/privacy-e-intelligenza-artificiale-cosa-dobbiamo-sapere-nel-2025/\">qui</a>)</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span style=\"font-weight: 400;\">Chi decide cosa pu√≤ o non pu√≤ rispondere un modello?</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span style=\"font-weight: 400;\">Quanto siamo consapevoli del fatto che ci√≤ che scriviamo nei chatbot pu√≤ essere conservato e riutilizzato?</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span style=\"font-weight: 400;\">I filtri dei modelli proteggono davvero i minori?</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span style=\"font-weight: 400;\">Come possiamo immaginare un'AI pi√π equa, trasparente, e rispettosa ?¬†</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span style=\"font-weight: 400;\">Quali strumenti possono restituire ‚Äúagency‚Äù alle comunit√† scolastiche e famigliari?</span></li>\n</ul>\n<p><span style=\"font-weight: 400;\">Sotto l'interfaccia amichevole di un assistente virtuale AI, si nascondono meccanismi complessi che pongono interrogativi urgenti su </span><strong>privacy, etica, controllo e sostenibilit√†.</strong></p>\n<p><i><span style=\"font-weight: 400;\">‚ÄúGli algoritmi non sono semplicemente procedure computazionali; sono anche attori culturali e sociali che modellano e sono modellati dalla societ√†‚Äù (Tarleton, 2014)</span></i></p>\n<p><span style=\"font-weight: 400;\">Questa affermazione √® particolarmente rilevante oggi, in un contesto in cui l‚Äôeducazione rischia di essere modellata da strumenti digitali opachi, con logiche spesso invisibili agli utenti finali. In ambito educativo, usare un'AI disegnata e gestita da aziende private, addestrata su dati e regole proprietarie (non note), che risponde con logiche non verificabili, rischia di trasformare lo studente da soggetto attivo a </span><strong>consumatore passivo di risposte</strong><span style=\"font-weight: 400;\">.</span></p>\n<p><span style=\"font-weight: 400;\">Le conseguenze non si limitano all‚Äôapprendimento, ma toccano anche aspetti legati all‚Äôautonomia, alla responsabilit√† e alla consapevolezza critica. Quando l'intelligenza artificiale diventa intermediaria dell'accesso alla conoscenza, √® essenziale chiedersi: chi ha scritto il codice che filtra la realt√†? Chi decide quali dati sono inclusi o esclusi? Puoi fidarti del risultato? E, soprattutto: esiste un modo pi√π equo, pi√π aperto, pi√π controllabile di usare l‚Äôintelligenza artificiale?¬†</span></p>\n<p><span style=\"font-weight: 400;\">S√¨, esiste. E si chiama open source. Ma andiamo con ordine.</span></p>\n<h2>A scuola, a casa, al lavoro: l'AI √® gi√† ovunque (e non sempre fa quello che dice)</h2>\n<p><span style=\"font-weight: 400;\">Prendiamo la scuola. Ci sono piattaforme che aiutano gli studenti a scrivere, correggere e imparare meglio. Ma poi leggiamo che gli istituti vietano ChatGPT perch√® si sostituisce all‚Äôalunno nei compiti. E ci accorgiamo che forse la tecnologia √® arrivata troppo in fretta, senza che genitori e insegnanti avessero il tempo di capirla davvero.</span></p>\n<p><span style=\"font-weight: 400;\">In famiglia la situazione non √® molto diversa. Gli assistenti vocali rispondono alle domande dei bambini, accendono le luci, leggono favole. Ma ascoltano anche tutto il resto. Tutto. E salvano le conversazioni su server lontani, gestiti da aziende che non conosciamo.¬†</span></p>\n<p><span style=\"font-weight: 400;\">Sul lavoro, poi, l'IA promette efficienza, automazione, produttivit√†. Ma a che prezzo? In tante aziende i dipendenti temono che le macchine li sostituiscano. In altre, si vieta l‚Äôuso di tool AI proprio per proteggere i dati riservati.¬†</span></p>\n<p><span style=\"font-weight: 400;\">Quando deleghiamo qualcosa all‚Äôintelligenza artificiale, stiamo dando fiducia a un sistema che spesso non capiamo e che non possiamo controllare. Ma davvero deve essere per forza cos√¨?</span></p>\n<h2>L‚Äôalternativa c‚Äô√®: modelli aperti, trasparenti e locali</h2>\n<p><span style=\"font-weight: 400;\">Il mondo dell‚Äôopen source √® quel luogo dove le cose si costruiscono insieme. Non √® solo un modo di scrivere codice: √® un modo di pensare. E quando parliamo di AI open source, parliamo di modelli i cui meccanismi interni sono <strong>visibili, ispezionabili, modificabili</strong>.</span></p>\n<p><span style=\"font-weight: 400;\">Immagina una scuola che installa un modello linguistico su un server locale, senza mandare ogni domanda dei ragazzi a un server americano. O una famiglia che usa un assistente vocale offline, che funziona in casa e non registra nulla nel cloud, sicuri di poter creare ‚Äúla banca dati della famiglia‚Äù. O ancora, una piccola azienda che allena un modello sui propri dati, mantenendo tutto in sede, senza dover pagare abbonamenti, al riparo da segreti industriali e preoccupazioni di copyright.</span></p>\n<p><span style=\"font-weight: 400;\">Se ci fosse uno strumento AI che possiamo installare sul nostro computer o su un server scolastico ? che possiamo modificare, migliorare e comprendere ? che possiamo arricchire con i nostri dati personali che restano sul nostro computer ? magari anche libero, trasparente, e volendo strutturato in modo etico ?</span></p>\n<p><span style=\"font-weight: 400;\">Questa strada oggi esiste e, in certi casi d'uso, √® in grado di produrre risultati equiparabili ai modelli famosi a pagamento. √à la strada dei </span><strong>modelli AI open-source</strong><span style=\"font-weight: 400;\"> eseguiti </span><strong>in locale</strong><span style=\"font-weight: 400;\">, cio√® </span><strong>sul proprio dispositivo</strong><span style=\"font-weight: 400;\">, senza cloud, senza dipendenza da multinazionali, che possiamo alimentare con i nostri dati personali senza doverli condividere.</span></p>\n<p><span style=\"font-weight: 400;\">Certo, serve un minimo di competenza tecnica. Ma le risorse esistono. Le comunit√† crescono e con loro queste soluzioni e strumenti. Oggi possiamo dire che hanno raggiunto una maturit√† tale da essere facilmente accessibili e applicabili in svariati contesti.</span></p>\n<p><span style=\"font-weight: 400;\">Quando parliamo di sistemi ‚Äú<em>chiusi e proprietari</em>‚Äù, ci riferiamo a piattaforme di AI i cui algoritmi, modelli e dati di addestramento non sono pubblici. L‚Äôutente pu√≤ solitamente accedere al servizio senza alcuna visibilit√† su come il risultato sia stato ottenuto. L‚ÄôAI open source, al contrario, punta a rendere disponibili codice, modelli e talvolta dati con licenze libere, consentendo a chiunque di utilizzare, studiare, modificare e condividere il sistema. In altre parole, un modello aperto diventa una sorta di ‚Äústruttura in vetro‚Äù analizzabile autonomamente dall‚Äôutente. La Commissione Europea sta addirittura definendo requisiti per i modelli ‚Äúfully open-source‚Äù nell‚ÄôAI Act, riferendosi a quelli con pesi, codice completo e dati di training pubblicamente disponibili e liberamente riutilizzabili.¬†</span></p>\n<p><span style=\"font-weight: 400;\">Oggi esistono soluzioni completamente open source o soluzioni parziali. LLaMA, Mistral, Phi, Qwen, Whisper, sono nomi che forse non si trovano subito sui giornali, ma che rappresentano un altro modo di usare l‚ÄôAI: pi√π sostenibile, pi√π rispettoso, pi√π libero.</span></p>\n<p><span style=\"font-weight: 400;\">Nei sistemi </span><strong>chiusi</strong><span style=\"font-weight: 400;\"> (Gemini, ChatGPT, Claude, ecc.) l‚Äôalgoritmo √® una</span><strong> scatola nera</strong><span style=\"font-weight: 400;\">: inserisci la domanda, loro macinano, tu ottieni una risposta. Fine della storia.</span></p>\n<p><span style=\"font-weight: 400;\">Con i progetti </span><strong>open-source</strong><span style=\"font-weight: 400;\"> succede l‚Äôopposto:</span></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\">Codice e pesi<span style=\"font-weight: 400;\"> <strong>sono pubblici</strong>.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span style=\"font-weight: 400;\">Puoi installare il modello </span><strong>in locale</strong><span style=\"font-weight: 400;\">, quindi niente viaggio dei dati verso server stranieri.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span style=\"font-weight: 400;\">La community ‚Äúspulcia‚Äù il codice, scova bug, riduce bias, propone ottimizzazioni.</span></li>\n</ul>\n<p><span style=\"font-weight: 400;\">Certo, i sistemi chiusi offrono soluzioni ‚Äúchiavi in mano‚Äù, che fanno risparmiare sul personale tecnico, ma il trade-off √® chiaro: dipendenza tecnologica, minor controllo, esfiltrazione dei dati e costi fissi da una parte, pi√π investimento in competenze interne, controllo dei costi e governo completo dall‚Äôaltra.</span></p>\n<h2>Cosa significa \"modello AI eseguito in locale\"?</h2>\n<p><span style=\"font-weight: 400;\">Un modello AI eseguito in locale √® un software che </span><strong>gira sul proprio computer (o sul proprio server)</strong><span style=\"font-weight: 400;\">, senza dipendere da servizi esterni e senza bisogno di inviare dati personali a un server esterno, senza tracker o blackout dettati da terzi, senza dover pagare un abbonamento. Tutto il processo avviene </span><strong>offline o in rete locale, chiusa</strong><span style=\"font-weight: 400;\">. Nessun dato esce, nessuna informazione viene tracciata da terzi, nessun rischio di indisponibilit√† (basta un computer e la corrente elettrica).</span></p>\n<p><span style=\"font-weight: 400;\">Ok, ma cosa ci potremmo fare ? Ad esempio in ambito educativo:¬†</span></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span style=\"font-weight: 400;\">Chatbot scolastici <strong>addestrati su materiali personalizzati</strong> (es. storia locale, curricoli della classe, materiali personali degli studenti) .</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span style=\"font-weight: 400;\">Tutor AI o strumenti interattivi, con parametri vincolati e personalizzati che funzionano <strong>offline, in sicurezza</strong> anche per bambini.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span style=\"font-weight: 400;\">Traduttori o correttori grammaticali su <strong>lingue non supportate</strong> da modelli a pagamento.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span style=\"font-weight: 400;\">AI locali per coding che <strong>non inviano codice</strong> sorgente in rete.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span style=\"font-weight: 400;\">Sistemi interni di supporto basati su modelli addestrati su <strong>documentazione interna riservati o protetti da copyright</strong>, utilizzabili da dipendenti anche senza connessione a internet.¬†</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span style=\"font-weight: 400;\">Assistenti utilizzabili in ambiti legali o HR con pieno <strong>controllo sui dati sensibili e senza esposizione a rischio di data breach di terzi</strong>.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\">Motori di ricerca interni che interrogano un <strong>corpus documentale privato</strong>, come archivi scolastici, dispense, verbali o materiali formativi dove la condivisione su cloud risulterebbe problematica o una violazione.</li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span style=\"font-weight: 400;\">Generatori di quiz o esercizi didattici a partire da PDF o slide forniti dal docente, con output verificabili offline e senza uso di servizi cloud.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span style=\"font-weight: 400;\">Sistemi di aiuto nella correzione di compiti <strong>senza rischiare di violare la privacy</strong> degli studenti, elaborando i testi localmente senza inviarli a server esterni.</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span style=\"font-weight: 400;\">Creazione di <strong>strumenti di autovalutazione</strong> per esami o interrogazioni che non memorizzano le risposte in rete, proteggendo cos√¨ l'identit√† e i progressi degli alunni.</span></li>\n<li aria-level=\"1\"><span style=\"font-weight: 400;\">Sistemi di assistenza per l‚Äôapprendimento domestico dei figli (ripasso, supporto compiti) completamente offline, <strong>controllabili dall‚Äôeducatore e personalizzabili </strong>su contenuti familiari.</span></li>\n<li aria-level=\"1\"><span style=\"font-weight: 400;\"><strong>Evitare Lock-in tecnologico</strong>: nessuna dipendenza da fornitori esterni. I</span><span style=\"font-weight: 400;\">n scenari geopolitici o di crisi tecnologica, l‚Äôutilizzo di modelli open-source locali si rivela strategico anche per la </span><strong>continuit√† operativa</strong><span style=\"font-weight: 400;\">. Un AI locale permette di funzionare </span><strong>off-grid</strong><span style=\"font-weight: 400;\">, cio√® senza connessione a internet evitando cos√¨ i rischi connessi a embarghi, censure o disattivazioni remote dei servizi.</span></li>\n</ul>\n<p><span style=\"font-weight: 400;\">Per tutti questi casi ed oltre, estendibili a contesti non solo educativi, una soluzione basata su modello open e locale non √® solo una scelta sostenibile, etica o educativa, ma anche una </span><strong>soluzione resiliente</strong><span style=\"font-weight: 400;\"> per proteggere informazioni sensibili e garantire la sovranit√† digitale.</span></p>\n<h2>Facciamoci un p√≤ di domande.</h2>\n<p><span style=\"font-weight: 400;\">Quando accetti i termini di una nuova app AI, li leggi davvero? Quando un algoritmo ti propone un contenuto, ti chiedi perch√© lo fa? Quando uno strumento promette miracoli, ti domandi a che prezzo?</span></p>\n<p><span style=\"font-weight: 400;\">Queste non sono domande da tecnofobi. Sono domande da cittadini. Perch√© l‚Äôintelligenza artificiale non √® magia. √à matematica, codice, dati. E scelte. Tante scelte.</span></p>\n<p><span style=\"font-weight: 400;\">Quindi vale la pena fermarsi un attimo e riflettere: voglio sapere di pi√π su questi strumenti? Voglio capire cosa succede ai miei dati? Posso contribuire, nel mio piccolo, a costruire un futuro digitale pi√π giusto, pi√π aperto, pi√π umano?</span></p>\n<h2>Un futuro condiviso si costruisce ora</h2>\n<p><span style=\"font-weight: 400;\">Quello che spesso manca nel dibattito sull‚Äôintelligenza artificiale √® il senso di agency. Di possibilit√†. Come se tutto fosse gi√† scritto nei laboratori delle big tech. Ma non √® cos√¨. Possiamo scegliere. Possiamo <strong>chiedere modelli trasparenti</strong>, possiamo formarci, possiamo collaborare a progetti open. Possiamo pretendere che le scuole, le pubbliche amministrazioni, le aziende scelgano strumenti che rispettano i nostri diritti.</span></p>\n<p><span style=\"font-weight: 400;\">Trasparenza e controllo: fidarsi √® bene, capire √® meglio. Un algoritmo che decide un prestito o suggerisce una cura DEVE spiegarsi. Con il codice aperto gli auditor possono vedere quali dati ha ‚Äúdigerito‚Äù, quali pesi attribuisce a et√†, reddito, genere. Con la scatola nera no: devi fidarti sulla parola.</span></p>\n<p><span style=\"font-weight: 400;\">E possiamo farlo partendo da piccoli gesti: informandoci, ponendo domande scomode, scegliendo un'app open invece di una chiusa, magari partecipando a un progetto comunitario. L'AI non √® un destino: √® uno strumento. E come ogni strumento, possiamo imparare a usarlo. Insieme.</span></p>\n<h2>L‚Äôintelligenza artificiale in tasca.</h2>\n<p><span style=\"font-weight: 400;\">Noi ci stiamo provando. Abbiamo voluto dare una <strong>risposta, concreta, a domande vere</strong>: ‚Äú<em>Ma come lo spieghi a mia figlia cos‚Äô√® un‚Äôintelligenza artificiale?</em>‚Äù, oppure ‚Äú<em>C‚Äô√® un modo per usarla in classe senza che finisca tutto su qualche server chiss√† dove?</em>‚Äù. E da l√¨ siamo partiti ‚Äî con quel misto di ostinazione artigianale e amore per l‚Äôeducazione che ti spinge a rovistare nei cassetti (e ispirati dall‚Äôimmagine sorniona del Curator di </span><i></i><a href=\"https://www.imdb.com/it/title/tt1677720/\"><i><span style=\"font-weight: 400;\">Ready Player One</span></i><span style=\"font-weight: 400;\"> </span></a><span style=\"font-weight: 400;\">appiccicata sulla bacheca del laboratorio), recuperare un Chromebook rotto e dire: ‚ÄúVediamo se si pu√≤ fare‚Äù.</span></p>\n<figure class=\"post__image post__image--center\"><img loading=\"lazy\"  src=\"https://pianetararo.org/media/posts/25/LLM_LOCALE.png\" alt=\"\" width=\"269\" height=\"368\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://pianetararo.org/media/posts/25/responsive/LLM_LOCALE-xs.png 640w ,https://pianetararo.org/media/posts/25/responsive/LLM_LOCALE-sm.png 768w ,https://pianetararo.org/media/posts/25/responsive/LLM_LOCALE-md.png 1024w ,https://pianetararo.org/media/posts/25/responsive/LLM_LOCALE-lg.png 1366w ,https://pianetararo.org/media/posts/25/responsive/LLM_LOCALE-xl.png 1600w ,https://pianetararo.org/media/posts/25/responsive/LLM_LOCALE-2xl.png 1920w\"></figure>\n<p><span style=\"font-weight: 400;\">Ed ecco il nostro piccolo Frankenstein digitale (ancora in cerca di nome): adotta LLM open-source, arricchiti, eseguiti in locale, racchiusi in un involucro minimale, verde, come i colori di <strong>pianetararo</strong>. Un prototipo di un <strong>LLM ‚Äúda banco‚Äù. </strong>Si tocca. Non serve internet. Non servono abbonamenti. Solo un po‚Äô di curiosit√†, qualche nozione tecnica, e la voglia di capirci qualcosa. Un‚Äô<strong>intelligenza artificiale in tasca</strong>, s√¨, ma nel senso vero: la colleghi via USB a qualsiasi computer ‚Äî Mac, Windows, Linux, poco importa ‚Äî e via, nessun software da installare. Gli studenti la esplorano, ci smanettano, la ‚Äúvedono‚Äù pensare. E in quel momento capiscono: non √® magia, √® codice. √à logica. √à statistica. √à linguaggio. E possono piegarlo, cambiarlo, arricchirlo, fargli dire cose in romagnolo stretto o riscrivere la Guerra dei Trent‚ÄôAnni come se fosse una storia di Instagram. <strong>Quando hai finito, stacchi il cavo e lo metti in tasca</strong>. Lo porti via con te.</span></p>\n<p><span style=\"font-weight: 400;\">Poi certo, ci siamo fatti prendere la mano. Perch√© una AI sola era solo l‚Äôinizio. Cos√¨ ci abbimo infilato una piccola squadra di agenti, autonomi, come quelli di Matrix, ognuno con il suo compito: c‚Äô√® quello che genera podcast dai riassunti delle lezioni, quello che raccoglie fonti da internet e ti prepara una ricerca bella pronta mescolandola a quella segreta della nonna (che ChatGPT non conoscer√† mai), quello che ti costruisce un‚Äôinfografica da mostrare al prof. Ma <strong>tutti funzionano in locale. Tutti rispettano la tua privacy</strong>. Tutti danno la sensazione ‚Äî rara ‚Äî di avere il controllo. Non sei pi√π solo spettatore: diventi autore. Scopri uno strumento al tuo servizio. Un \"Curatore\" al tuo servizio. Solo tuo.</span></p>\n<p><span style=\"font-weight: 400;\">E sai qual √® la cosa pi√π bella? Che non serve essere ingegneri. Serve solo la voglia di provare. Perch√© l‚Äôintelligenza artificiale non √® solo roba ‚Äúda esperti‚Äù.¬†</span></p>\n<p><span style=\"font-weight: 400;\">Lo abbiamo pensato come un <strong>kit didattico</strong>, un <strong>laboratorio educativo</strong> replicabile: te lo metti in tasca e lo porti in aula. Qualsiasi aula. Giovani o adulti. Ma chiaramente √® qualcosa che va oltre. Perch√© quando metti nelle mani delle persone uno strumento che possono comprendere, smontare, controllare ‚Äî senza dover firmare una licenza o cedere i propri dati ‚Äî non stai solo insegnando come funziona un algoritmo. Stai insegnando cosa vuol dire potere digitale, autonomia, cittadinanza. E allora s√¨, parte come un esperimento educativo, ma finisce per diventare un piccolo atto di <strong>libert√† tecnologica</strong>.</span></p>\n<hr>\n<p>Questo post √® parte della rubrica <strong><a href=\"https://pianetararo.org/traiettorie/\">TrAIettorie</a></strong> di cui potete trovare l'indice completo <a href=\"https://pianetararo.org/tags/traiettorie/\">qui</a>.</p>",
            "image": "https://pianetararo.org/media/posts/25/curatore.png",
            "author": {
                "name": "Pianetararo Associazione Culturale"
            },
            "tags": [
                   "TRAIETTORIE"
            ],
            "date_published": "2025-06-14T00:52:00+02:00",
            "date_modified": "2025-06-16T08:12:02+02:00"
        },
        {
            "id": "https://pianetararo.org/come-funzionano-le-ia-che-ci-scrivono/",
            "url": "https://pianetararo.org/come-funzionano-le-ia-che-ci-scrivono/",
            "title": "Come funzionano le AI che ci scrivono",
            "summary": "Utilizzare chatbot AI sta diventando talmente frequente che sta rimpiazzando di pari passo la ricerca sul web classica cos√¨ come la conoscevamo. Chiediamo a un‚ÄôAI di cercare sul web, spiegarci qualcosa che non conosciamo, scriverci il riassunto di un testo, risolvere un compito scolastico, una&hellip;",
            "content_html": "<p><span style=\"font-weight: 400;\">Utilizzare chatbot AI sta diventando talmente frequente che sta rimpiazzando di pari passo la ricerca sul web classica cos√¨ come la conoscevamo. Chiediamo a un‚Äô</span>AI<span style=\"font-weight: 400;\"> di cercare sul web, spiegarci qualcosa che non conosciamo, scriverci il riassunto di un testo, risolvere un compito scolastico, una poesia in rima o un consiglio per la cena, e quella risponde in italiano fluente e creativo. A volte sembra di parlare con un piccolo scrittore artificiale dalla fantasia infinita. </span><strong>Ma come fa, davvero, a generare queste risposte?</strong><span style=\"font-weight: 400;\"> Sta </span><strong>pensando</strong><span style=\"font-weight: 400;\"> e </span><i><span style=\"font-weight: 400;\">capendo</span></i><span style=\"font-weight: 400;\"> la domanda come farebbe una persona? Risposta veloce: No. E capire </span><i><span style=\"font-weight: 400;\">come funziona sul serio</span></i><span style=\"font-weight: 400;\"> un LLM ‚Äì acronimo di </span>Large Language Model<span style=\"font-weight: 400;\">, ovvero modello linguistico di grandi dimensioni ‚Äì √® importante per sfatare alcuni miti e usarlo al meglio.¬†</span></p>\n<p><span style=\"font-weight: 400;\">Questo articolo prover√† a fare chiarezza, semplificando, su cosa avviene </span><i><span style=\"font-weight: 400;\">dietro le quinte</span></i><span style=\"font-weight: 400;\"> quando una di queste AI elabora una domanda e produce una risposta. Con esempi semplici (anche fiabeschi!) vedremo passo passo </span><strong>come √® fatto internamente un LLM, come funziona e come genera testo</strong><span style=\"font-weight: 400;\">, toccando concetti chiave e termini come </span><i><span style=\"font-weight: 400;\">tokenizzazione</span></i><span style=\"font-weight: 400;\">, </span><i><span style=\"font-weight: 400;\">embedding</span></i><span style=\"font-weight: 400;\"> e </span><i><span style=\"font-weight: 400;\">trasformatori</span></i><span style=\"font-weight: 400;\">. Scopriremo inoltre perch√© un LLM, per quanto sofisticato, </span><strong>non √® una mente cosciente</strong><span style=\"font-weight: 400;\"> n√© infallibile, e come conoscere la sua struttura ci aiuta a usarlo in modo pi√π consapevole, apprezzandone le potenzialit√† senza dimenticarne i limiti.¬†</span></p>\n<h2>Come funziona un LLM: dall‚Äôinput alla risposta</h2>\n<p><span style=\"font-weight: 400;\">Immaginiamo di chiedere a un modello come ChatGPT qualcosa di creativo. Ad esempio: </span><i><span style=\"font-weight: 400;\">‚ÄúC‚Äôera una volta un regno incantato dove viveva un giovane drago. Un giorno‚Ä¶‚Äù</span></i><span style=\"font-weight: 400;\"> e gli domandiamo di continuare la storia. In pochi secondi l‚ÄôLLM produce magari un racconto avvincente, pieno di avventure. </span><strong>Cosa √® successo, in termini semplici, dentro il ‚Äúcervello‚Äù artificiale del modello?</strong><span style=\"font-weight: 400;\"> Ecco le fasi principali del processo:</span></p>\n<ol>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><strong>Comprensione del prompt (input):</strong><span style=\"font-weight: 400;\"> il testo della nostra richiesta viene prima </span><i><span style=\"font-weight: 400;\">preparato</span></i><span style=\"font-weight: 400;\"> in modo che il modello possa lavorarci. In pratica l‚ÄôLLM spezzetta la frase in unit√† pi√π piccole chiamate </span><strong>token</strong><span style=\"font-weight: 400;\"> (parole o frammenti di parole) e le converte in numeri. √à un po‚Äô come tradurre la frase in un linguaggio matematico che la macchina possa elaborare.</span><span style=\"font-weight: 400;\"><br><br></span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><strong>Analisi del contesto:</strong><span style=\"font-weight: 400;\"> a questo punto i token numerici vengono passati attraverso la rete neurale del modello. L‚ÄôLLM </span><i><span style=\"font-weight: 400;\">esamina il contesto</span></i><span style=\"font-weight: 400;\"> della frase e, sulla base di ci√≤ che ‚Äúha imparato‚Äù da miliardi di parole di training, stima quale potrebbe essere la parola (o token) pi√π probabile dopo quelle gi√† date. In questa fase interviene il </span><strong>meccanismo di attenzione</strong><span style=\"font-weight: 400;\"> tipico dei trasformatori: il modello valuta in parallelo tutti i termini presenti nel prompt e assegna pi√π peso a quelli pi√π rilevanti, ignorando quelli meno significativi. In altre parole, ‚Äúcapisce‚Äù quali concetti chiave sono emersi finora (es. </span><i><span style=\"font-weight: 400;\">regno incantato</span></i><span style=\"font-weight: 400;\">, </span><i><span style=\"font-weight: 400;\">giovane drago</span></i><span style=\"font-weight: 400;\">) e li usa per predire come la storia potrebbe proseguire.</span><span style=\"font-weight: 400;\"><br><br></span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><strong>Previsione della prossima parola:</strong><span style=\"font-weight: 400;\"> in base all‚Äôanalisi, l‚ÄôLLM produce una sorta di elenco di possibili continuazioni, ciascuna con una certa </span><strong>probabilit√† statistica</strong><span style=\"font-weight: 400;\">. Ad esempio, dopo la frase </span><i><span style=\"font-weight: 400;\">‚ÄúC‚Äôera una volta un giovane drago‚Äù</span></i><span style=\"font-weight: 400;\"> il modello potrebbe calcolare che il token </span><i><span style=\"font-weight: 400;\">‚Äúche‚Äù</span></i><span style=\"font-weight: 400;\"> ha il 40% di probabilit√† di venire dopo, </span><i><span style=\"font-weight: 400;\">‚Äúdragone‚Äù</span></i><span style=\"font-weight: 400;\"> il 15%, </span><i><span style=\"font-weight: 400;\">‚Äúdi‚Äù</span></i><span style=\"font-weight: 400;\"> il 10%, </span><i><span style=\"font-weight: 400;\">‚Äúprincipe‚Äù</span></i><span style=\"font-weight: 400;\"> il 5%, e cos√¨ via ‚Äì a seconda di ci√≤ che ha appreso dai testi durante l‚Äôaddestramento. In effetti, l‚ÄôLLM non inventa dal nulla la continuazione: sta scegliendo la parola successiva basandosi sui </span><strong>pattern linguistici</strong><span style=\"font-weight: 400;\"> che ha gi√† visto moltissime volte.</span><span style=\"font-weight: 400;\"><br><br></span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><strong>Generazione iterativa della risposta:</strong><span style=\"font-weight: 400;\"> una volta ottenute le probabilit√†, il modello </span><strong>sceglie un token</strong><span style=\"font-weight: 400;\"> come prossimo elemento della risposta. Spesso seleziona quello con la probabilit√† pi√π alta, ma pu√≤ introdurre un po‚Äô di casualit√† per rendere il testo meno prevedibile. Immaginiamo che scelga ad esempio </span><i><span style=\"font-weight: 400;\">‚Äúche‚Äù</span></i><span style=\"font-weight: 400;\">. A questo punto il token </span><i><span style=\"font-weight: 400;\">‚Äúche‚Äù</span></i><span style=\"font-weight: 400;\"> viene aggiunto alla frase generata e il modello </span><strong>ripete</strong><span style=\"font-weight: 400;\"> nuovamente il passo 2: rianalizza tutto il contesto aggiornato (</span><i><span style=\"font-weight: 400;\">‚ÄúC‚Äôera una volta un giovane drago che‚Äù</span></i><span style=\"font-weight: 400;\">) e calcola il token successivo. Poi di nuovo e cos√¨ via, parola dopo parola, </span><strong>fino a completare la frase o il paragrafo</strong><span style=\"font-weight: 400;\"> richiesto. Questo processo a catena continua finch√© l‚ÄôLLM produce un segnale di </span><strong>fine risposta</strong><span style=\"font-weight: 400;\"> (ad esempio un token speciale di stop) oppure finch√© raggiunge un limite di lunghezza prestabilito.</span><span style=\"font-weight: 400;\"><br><br></span></li>\n</ol>\n<p><span style=\"font-weight: 400;\">Possiamo paragonare il tutto a </span><strong>un super-autocompletamento</strong><span style=\"font-weight: 400;\"> intelligente: come quando il telefono ci suggerisce le parole mentre digitiamo un messaggio, ma in questo caso con una potenza e una base di conoscenza immensamente pi√π grandi. L‚ÄôLLM, addestrato su innumerevoli esempi di frasi, </span><i><span style=\"font-weight: 400;\">prevede</span></i><span style=\"font-weight: 400;\"> di volta in volta il pezzo mancante successivo, cucendo insieme una risposta frase dopo frase.</span></p>\n<blockquote>\n<h5>üîç Token ed embedding: l‚Äôalfabeto segreto</h5>\n<p><strong><i><br></i></strong><span style=\"font-weight: 400;\">Un computer non ‚Äúcomprende‚Äù realmente le parole testuali: deve rappresentarle con dei numeri. La </span><strong>tokenizzazione</strong><span style=\"font-weight: 400;\"> √® il procedimento che converte il testo in piccoli segmenti (token) che possono essere elaborati dal modello. Spesso i token corrispondono a parole intere, ma possono anche essere sillabe o addirittura singole lettere nei casi complessi. Ad ogni token l‚ÄôLLM associa poi un </span><strong>embedding</strong><span style=\"font-weight: 400;\">, ovvero un </span><strong>vettore di numeri</strong><span style=\"font-weight: 400;\"> (di solito decine o centinaia di valori) che rappresenta quella parola in forma matematica all‚Äôinterno dello spazio ‚Äúmentale‚Äù del modello. L‚Äôidea √® che parole con significato o uso simile avranno vettori (embedding) </span><i><span style=\"font-weight: 400;\">simili</span></i><span style=\"font-weight: 400;\"> tra loro. Ad esempio, in inglese </span><i><span style=\"font-weight: 400;\">‚Äúsea‚Äù</span></i><span style=\"font-weight: 400;\"> e </span><i><span style=\"font-weight: 400;\">‚Äúocean‚Äù</span></i><span style=\"font-weight: 400;\"> (cio√® </span><i><span style=\"font-weight: 400;\">mare</span></i><span style=\"font-weight: 400;\"> e </span><i><span style=\"font-weight: 400;\">oceano</span></i><span style=\"font-weight: 400;\">) risultano molto vicini (perch√© simili) nello spazio vettoriale degli embedding ‚Äì segno che il modello li considera concetti affini. In pratica, l‚Äôembedding √® come un‚Äôimpronta numerica che cattura il senso di un token: √® grazie a queste rappresentazioni che l‚ÄôLLM pu√≤ ‚Äúragionare‚Äù sulle parole in ingresso e trovare connessioni tra termini correlati.</span></p>\n</blockquote>\n<h2>Dentro la scatola nera: com‚Äô√® fatto (e addestrato) un LLM</h2>\n<p><span style=\"font-weight: 400;\">Abbiamo visto a grandi linee </span><i><span style=\"font-weight: 400;\">come</span></i><span style=\"font-weight: 400;\"> un LLM genera testo. Ma com‚Äô√® strutturato internamente questo ‚Äúscrittore automatico‚Äù? La risposta breve: √® una </span><strong>rete neurale</strong><span style=\"font-weight: 400;\"> enorme, con miliardi di connessioni, addestrata su </span><strong>quantit√† mastodontiche di dati testuali</strong><span style=\"font-weight: 400;\">. Due ingredienti, </span><i><span style=\"font-weight: 400;\">scala</span></i><span style=\"font-weight: 400;\"> e </span><i><span style=\"font-weight: 400;\">quantit√†</span></i><span style=\"font-weight: 400;\">, sono stati fondamentali per il salto di qualit√† di questi modelli negli ultimi anni.</span></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><strong>Dati in abbondanza (token):</strong><span style=\"font-weight: 400;\"> i Large Language Model vengono </span><i><span style=\"font-weight: 400;\">pre-addestrati</span></i><span style=\"font-weight: 400;\"> leggendo praticamente tutto quello che trovano. Documenti pubblici, libri, articoli, pagine web, conversazioni di forum ‚Äì un vero tesoro linguistico. Il modello ‚Äúdigerisce‚Äù questo corpus immenso imparando, tramite un lungo processo di ottimizzazione, a predire la parola successiva in ogni frase. Ad esempio, il modello </span>GPT-3<span style=\"font-weight: 400;\"> di OpenAI (sviluppato nel 2020) √® stato addestrato usando circa </span>300 miliardi di token, che corrispondono a circa 45‚Äì60 TB di dati testuali<strong>¬†</strong>(sui modelli successivi non si hanno informazioni ma si ipotizza tra 1 e 5 trilioni di token)<span style=\"font-weight: 400;\">. Durante il training, l‚ÄôLLM macina questi testi miliardi di volte, aggiustando gradualmente i propri parametri per migliorare la capacit√† di indovinare le parole seguenti. </span>Un token pu√≤ essere una parola intera, una radice (es. <em>scriv</em>), una sillaba, o persino una singola lettera o segno di punteggiatura. Tutto dipende dal metodo di tokenizzazione scelto. La frase ‚Äú<em>Ciao, come stai ?</em>‚Äù potrebbe diventare semplicisticamente¬† ‚Üí <code>[\"Ciao\", \",\", \"come\", \"stai\", \"?\"]</code> ‚Üí <strong>5 token</strong>. Ma i metodi sono i pi√π disparati. Ad esempio la stessa frase ChatGPT la \"<em><a href=\"https://platform.openai.com/tokenizer\">tokenizza</a></em>\" ancora pi√π finemente: <figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://pianetararo.org/media/posts/22/token-Screenshot-2025-06-11-121527-2.png\" alt=\"\" width=\"445\" height=\"402\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://pianetararo.org/media/posts/22/responsive/token-Screenshot-2025-06-11-121527-2-xs.png 640w ,https://pianetararo.org/media/posts/22/responsive/token-Screenshot-2025-06-11-121527-2-sm.png 768w ,https://pianetararo.org/media/posts/22/responsive/token-Screenshot-2025-06-11-121527-2-md.png 1024w ,https://pianetararo.org/media/posts/22/responsive/token-Screenshot-2025-06-11-121527-2-lg.png 1366w ,https://pianetararo.org/media/posts/22/responsive/token-Screenshot-2025-06-11-121527-2-xl.png 1600w ,https://pianetararo.org/media/posts/22/responsive/token-Screenshot-2025-06-11-121527-2-2xl.png 1920w\"></figure>¬†</li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><strong>Tanti parametri (il ‚Äúcervello‚Äù della rete):</strong><span style=\"font-weight: 400;\"> se i token sono i pezzi di linguaggio, i parametri sono le <strong>connessioni apprese</strong> durante l‚Äôaddestramento. I parametri di un modello sono i coefficienti numerici (pesi) che collegano i neuroni artificiali al suo interno. Ogni parametro √® come una manopola o un interruttore che il modello pu√≤ regolare mentre impara. Quando il modello √® addestrato, queste ‚Äúmanopole‚Äù restano fisse e determinano come l‚ÄôAI risponde. Pi√π parametri ci sono, pi√π </span><i><span style=\"font-weight: 400;\">capacit√† espressiva</span></i><span style=\"font-weight: 400;\"> ha la rete neurale ‚Äì in teoria ‚Äì per cogliere sfumature e pattern del linguaggio. I moderni LLM sono giganteschi: GPT-3, ad esempio, ha </span><strong>175 miliardi di parametri</strong><span style=\"font-weight: 400;\">. Per dare un‚Äôidea, il suo predecessore GPT-2 ne aveva ‚Äúsolo‚Äù 1,5 miliardi. Questa crescita esponenziale ha permesso al modello di </span><strong>immagazzinare conoscenza linguistica</strong><span style=\"font-weight: 400;\"> molto pi√π approfondita (anche se non organizzata come una conoscenza umana, ovviamente). Pi√π neuroni e connessioni significano che il modello pu√≤ rappresentare concetti molto complessi e variegati. Naturalmente addestrare modelli del genere richiede risorse computazionali enormi (supercomputer con migliaia di GPU che macinano dati per settimane), ma il risultato √® un‚ÄôIA capace di generare testi straordinariamente coerenti.</span></li>\n</ul>\n<p>Immaginiamo che un LLM sia uno <strong>chef che scrive ricette</strong>:</p>\n<ul>\n<li>\n<p>I <strong>token</strong> sono gli <strong>ingredienti</strong> che lo chef usa (le parole da combinare).</p>\n</li>\n<li>\n<p>I <strong>parametri</strong> sono le <strong>esperienze accumulate</strong>, le prove e gli errori che gli hanno insegnato a cucinare bene (cio√® a generare testo sensato).</p>\n</li>\n</ul>\n<p>Pi√π parametri = uno chef pi√π esperto.<br>Pi√π token = pi√π ingredienti con cui preparare nuovi piatti.</p>\n<p><span style=\"font-weight: 400;\">A dare veramente il via a questa nuova generazione di AI linguistiche √® stata per√≤ una </span><strong>svolta architetturale</strong><span style=\"font-weight: 400;\">. Fino a qualche anno fa, i modelli di elaborazione del linguaggio (come i traduttori automatici o i vecchi chatbot) si basavano in gran parte su reti neurali ricorrenti o sequenziali, che leggevano il testo parola per parola in ordine. Nel </span><strong>2017</strong><span style=\"font-weight: 400;\">, un team di ricercatori di Google ha introdotto un modello diverso, chiamato </span><strong>Transformer</strong><span style=\"font-weight: 400;\"> (trasformatore), descrivendolo in un celebre paper scientifico dal titolo </span><i><span style=\"font-weight: 400;\">‚ÄúAttention Is All You Need‚Äù</span></i><span style=\"font-weight: 400;\">. Questa architettura ha rivoluzionato il campo perch√© </span><strong>analizza una sequenza di testo in parallelo anzich√© in sequenza</strong><span style=\"font-weight: 400;\">, usando un meccanismo di </span><strong>self-attention</strong><span style=\"font-weight: 400;\"> (auto-attenzione) che permette al modello di </span><i><span style=\"font-weight: 400;\">concentrarsi</span></i><span style=\"font-weight: 400;\"> sui punti importanti di una frase ignorandone i dettagli meno rilevanti. In pratica il trasformatore guarda all‚Äôintera frase (o anche interi paragrafi) tutta in una volta, e per ogni parola capisce quali altre parole del contesto sono pi√π utili per interpretarla. √à un po‚Äô quello che facciamo noi leggendo: se diciamo ‚Äú</span><strong>il giovane drago</strong><span style=\"font-weight: 400;\"> impar√≤ a volare‚Äù, il nostro cervello collega </span><i><span style=\"font-weight: 400;\">drago</span></i><span style=\"font-weight: 400;\"> con </span><i><span style=\"font-weight: 400;\">volare</span></i><span style=\"font-weight: 400;\"> e non d√† peso a parole come </span><i><span style=\"font-weight: 400;\">il</span></i><span style=\"font-weight: 400;\"> o </span><i><span style=\"font-weight: 400;\">a</span></i><span style=\"font-weight: 400;\">. Il </span><strong>Transformer</strong><span style=\"font-weight: 400;\"> permette all‚ÄôLLM di fare lo stesso tipo di collegamenti in maniera efficiente e accurata.</span></p>\n<p><span style=\"font-weight: 400;\">Questa innovazione ha reso possibili modelli con contesti molto ampi (capaci di ‚Äúricordare‚Äù e tenere in considerazione molte frasi precedenti) e con output di qualit√† molto pi√π alta. Non sorprende che tutti i principali LLM odierni ‚Äì da GPT-3 e GPT-4 di OpenAI ai modelli di Google, Meta, Anthropic ecc. ‚Äì siano basati su architettura transformer. Per chi volesse vedere con i propri occhi come funziona un trasformatore, il </span><strong>Financial Times</strong><span style=\"font-weight: 400;\"> ha pubblicato un bellissimo </span><strong><a href=\"https://ig.ft.com/generative-ai/\">articolo interattivo</a></strong><span style=\"font-weight: 400;\"> (in inglese) che illustra passo passo questi meccanismi. Scorrendo quella pagina web speciale, √® possibile visualizzare come un LLM codifica le parole, come l‚Äôattenzione evidenzia certe parole chiave, e persino come possono emergere fenomeni come le </span><i><span style=\"font-weight: 400;\">allucinazioni</span></i><span style=\"font-weight: 400;\"> durante la generazione di testo. √à un ottimo complemento visuale a quanto stiamo raccontando qui. <em>(</em></span><em>Curiosit√†: il nome stesso di ChatGPT descrive la sua genetica: </em><span style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\"><em>GPT ‚Üí <strong>G</strong>enerative. <strong>P</strong>retrained. <strong>T</strong>ransformer)</em>.¬†</span></p>\n<h2>LLM ‚â† intelligenza umana: miti e realt√†</h2>\n<p><span style=\"font-weight: 400;\">Dopo tutto quello che abbiamo visto, potrebbe sorgere spontanea una domanda: </span><i><span style=\"font-weight: 400;\">ma dunque questi LLM sono davvero ‚Äúintelligenti‚Äù?</span></i><span style=\"font-weight: 400;\"> Dipende da cosa intendiamo per intelligente. Certo, </span><strong>sanno generare testo di senso compiuto</strong><span style=\"font-weight: 400;\">, usare un lessico ricco, perfino imitare stili letterari. Tuttavia, </span><strong>non possiedono una comprensione profonda</strong><span style=\"font-weight: 400;\"> di ci√≤ che scrivono, n√© coscienza o intenzionalit√†. Spesso attribuiamo loro caratteristiche umane (c‚Äô√® chi chiede al chatbot se </span><i><span style=\"font-weight: 400;\">prova emozioni</span></i><span style=\"font-weight: 400;\"> o se </span><i><span style=\"font-weight: 400;\">pensa come noi</span></i><span style=\"font-weight: 400;\">), ma √® un‚Äôillusione. In realt√† un LLM </span><strong>non ‚Äúcapisce‚Äù il significato</strong><span style=\"font-weight: 400;\"> come lo capiremmo noi, ma manipola simboli statistici. Alcuni ricercatori hanno icasticamente definito questi modelli </span><i><span style=\"font-weight: 400;\">‚Äúpappagalli stocastici‚Äù</span></i><span style=\"font-weight: 400;\">: in pratica, imitano il linguaggio umano senza averne la </span><i><span style=\"font-weight: 400;\">consapevolezza</span></i><span style=\"font-weight: 400;\">.</span></p>\n<p><span style=\"font-weight: 400;\">Conoscere la struttura e il metodo di generazione di un LLM ci aiuta a </span><strong>ridimensionare alcune aspettative</strong><span style=\"font-weight: 400;\"> e ad usarlo con maggiore senso critico. Ecco alcuni punti da tenere a mente quando interagiamo con queste AI:</span></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><strong>Non hanno vera comprensione o conoscenza</strong><span style=\"font-weight: 400;\"> ‚Äì Un LLM non </span><i><span style=\"font-weight: 400;\">sa</span></i><span style=\"font-weight: 400;\"> di cosa parla; mette insieme frasi basate sulle probabilit√† apprese. Pu√≤ scrivere </span><i><span style=\"font-weight: 400;\">‚ÄúIl Sole √® una stella‚Äù</span></i><span style=\"font-weight: 400;\"> perch√© ha visto spesso quella frase, ma non ha in testa un modello del sistema solare. Come detto, √® un </span><i><span style=\"font-weight: 400;\">pappagallo statistico</span></i><span style=\"font-weight: 400;\"> che ripete strutture linguistiche plausibili senza ancorarle a un significato vero. Dunque, anche se le sue risposte </span><strong>suonano</strong><span style=\"font-weight: 400;\"> competenti, l‚ÄôLLM non dispone di un vero </span><strong>filtro di verit√†</strong><span style=\"font-weight: 400;\"> o di logica: sta solo seguendo i pattern appresi.</span><span style=\"font-weight: 400;\"><br><br></span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><strong>Possono </strong><strong><i>allucinare</i></strong><strong> (inventare) fatti</strong><span style=\"font-weight: 400;\"> ‚Äì Capita spesso che un LLM fornisca informazioni del tutto sbagliate con tono sicuro. Ad esempio, potrebbe affermare una data storica errata, citare una legge inesistente o mischiare biografie di persone diverse. Questo avviene perch√© il modello </span><strong>non ha modo di verificare</strong><span style=\"font-weight: 400;\"> le sue affermazioni: se certi termini compaiono frequentemente insieme nei suoi dati di training, lui li user√†, anche se l‚Äôinformazione √® falsa. In gergo si parla di </span><i><span style=\"font-weight: 400;\">allucinazioni dell‚ÄôIA</span></i><span style=\"font-weight: 400;\">. Il problema √® che l‚ÄôLLM </span><strong>non sa di non sapere</strong><span style=\"font-weight: 400;\">: non ha un feedback interno che gli dica ‚Äúquesta cosa √® sbagliata‚Äù. Un gruppo di esperti ha sottolineato proprio che, </span><i><span style=\"font-weight: 400;\">‚Äúsiccome si limita a mettere insieme parole in base ai dati di addestramento, un LLM non si rende conto se sta dicendo qualcosa di scorretto o inopportuno‚Äù</span></i><span style=\"font-weight: 400;\">. Sta a noi utenti, quindi, fare da filtro: </span><strong>mai prendere per oro colato</strong><span style=\"font-weight: 400;\"> tutto ci√≤ che esce da ChatGPT &amp; co., specialmente dati di fatto importanti, senza una verifica esterna.</span><span style=\"font-weight: 400;\"><br><br></span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><strong>Hanno i bias dei dati (e dei programmatori)</strong><span style=\"font-weight: 400;\"> ‚Äì Un LLM assorbe pregiudizi, errori e punti di vista presenti nei testi con cui √® stato addestrato. Se gran parte del web contiene un bias (ad esempio stereotipi di genere o discriminazioni razziali), il modello pu√≤ rifletterli nelle sue risposte. E anche se ci sono processi di correzione e filtraggio, non esiste garanzia assoluta di neutralit√† o accuratezza. In pi√π, i </span><strong>valori</strong><span style=\"font-weight: 400;\"> che guidano il modello (cosa considera accettabile o meno dire) dipendono in larga misura da scelte dei suoi sviluppatori durante la fase di fine-tuning. Questo non significa che l‚ÄôLLM sia ‚Äúmalvagio‚Äù o manipolatore di per s√© ‚Äì ricordiamo, non ha volont√† ‚Äì ma che </span><strong>pu√≤ ereditare sia il meglio sia il peggio</strong><span style=\"font-weight: 400;\"> del materiale su cui √® stato addestrato.</span><span style=\"font-weight: 400;\"><br><br></span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><strong>Non provano emozioni (anche se le simulano)</strong><span style=\"font-weight: 400;\"> ‚Äì Gli LLM possono scrivere frasi molto empatiche (</span><i><span style=\"font-weight: 400;\">‚ÄúMi dispiace che tu stia attraversando questo momento difficile‚Ä¶‚Äù</span></i><span style=\"font-weight: 400;\">), ma ci√≤ non implica alcuna esperienza emotiva da parte loro. Quando leggiamo una risposta accorata di un chatbot, siamo tentati di attribuirle un‚Äôintenzione o una sensibilit√†; in realt√† il modello sta semplicemente riproducendo schemi linguistici tipici delle conversazioni empatiche che ha visto nei suoi dati. </span><strong>Non c‚Äô√® un ‚Äúio‚Äù dietro quelle parole</strong><span style=\"font-weight: 400;\">, nessuna coscienza che soffre, gode o tiene davvero a noi. √à fondamentale ricordarlo per evitare di prendere decisioni emotive basate su una falsa percezione dell‚ÄôIA (ad esempio, sentirsi giudicati da lei, o credere che ‚Äúci tenga‚Äù davvero). L‚ÄôLLM √® </span><i><span style=\"font-weight: 400;\">abile imitazione</span></i><span style=\"font-weight: 400;\"> di un parlante umano, ma resta un‚Äôimitazione.</span><span style=\"font-weight: 400;\"><br><br></span></li>\n</ul>\n<p><span style=\"font-weight: 400;\">Conoscere </span><i><span style=\"font-weight: 400;\">come √® fatto e come lavora</span></i><span style=\"font-weight: 400;\"> un Large Language Model ci aiuta a usarlo in modo pi√π </span><strong>maturo e consapevole</strong><span style=\"font-weight: 400;\">. Possiamo ammirarne le capacit√† ‚Äì perch√© √® straordinario che un software </span><strong>autocompleti</strong><span style=\"font-weight: 400;\"> testi cos√¨ bene da sembrare creativi o competenti ‚Äì </span><strong>senza per√≤ mitizzarlo</strong><span style=\"font-weight: 400;\">. Un LLM non √® un oracolo infallibile n√© una mente artificiale dotata di saggezza propria: √® un potente strumento statistico, un prodotto dell‚Äôingegno umano (ricerca, algoritmi e tonnellate di dati). Sta a noi utilizzarlo come </span><i><span style=\"font-weight: 400;\">amplificatore</span></i><span style=\"font-weight: 400;\"> della nostra creativit√† e produttivit√†, ma anche come soggetto da monitorare. In fondo, </span><strong>dietro le quinte di un‚ÄôAI linguistica non c‚Äô√® magia</strong><span style=\"font-weight: 400;\"> ‚Äì c‚Äô√® matematica, informatica e tanta probabilit√†. E pi√π ne siamo consapevoli, meglio potremo sfruttare queste nuove tecnologie senza farci sfruttare da esse.</span></p>\n<h2>Da dove arrivano i dati? (Spoiler: anche da te)¬†</h2>\n<p><span style=\"font-weight: 400;\">Immagina per un attimo un‚ÄôIA come un grande scrittore che non ha mai vissuto nulla in prima persona. Non ha viaggiato, non ha amato, non ha mai mangiato una pizza vera. Eppure scrive poesie, articoli, dialoghi brillanti. Come fa? Semplice: </span><strong><i>legge tutto quello che trova</i></strong><span style=\"font-weight: 400;\">. Interi oceani di parole ‚Äì siti web, manuali, romanzi, ricette, forum, tweet, commenti, newsletter, persino battute da meme e recensioni su Amazon. Se c‚Äô√® stato un momento in cui hai pubblicato qualcosa online, c‚Äô√® una buona possibilit√† che l‚ÄôIA lo abbia letto (o almeno scannerizzato) in silenzio.</span></p>\n<p><span style=\"font-weight: 400;\">Ma ecco il punto critico: per anni si √® attinto a piene mani da Internet ‚Äì tutto a portata di clic. Il problema √® che molti di quei contenuti sono protetti da copyright: libri, articoli, blog, canzoni, manuali. E non sempre chi li ha scritti ha dato il permesso di usarli. Negli Stati Uniti, diversi autori, editori e giornalisti hanno fatto causa a colossi come OpenAI e Meta, accusandoli di aver \"ingurgitato\" opere intere senza autorizzazione per addestrare i loro modelli. Le aziende, dal canto loro, si difendono invocando il ‚Äúfair use‚Äù, una clausola del diritto americano che permette l‚Äôuso di opere protette in certi casi (come ricerca o parodia). Ma il confine tra uso lecito e sfruttamento improprio √® sempre pi√π sottile, specialmente se l‚Äôoutput dell‚ÄôIA finisce per somigliare troppo a un contenuto originale. In Europa, intanto, si spingono nuove regole per obbligare le aziende a dichiarare chiaramente </span><strong>che dati usano, dove li prendono e per che cosa</strong><span style=\"font-weight: 400;\">. Insomma, si sta cercando di trasformare la scatola nera dei LLM in una finestra (almeno socchiusa) sulla loro memoria. E non √® una battaglia da poco: in gioco non c‚Äô√® solo la propriet√† intellettuale, ma il diritto delle persone a sapere se ‚Äì e come ‚Äì i loro contenuti vengono usati per creare ‚Äúl‚Äôintelligenza‚Äù delle macchine.</span></p>\n<p><span style=\"font-weight: 400;\">Ultimamente, parlare di come vengono ‚Äúallenate‚Äù le intelligenze artificiali significa entrare in una cucina in pieno fermento. Gli ingredienti sono testi presi dal web, grandi banche dati, righe di codice, dati artificiali creati da altre AI, e ‚Äì sempre pi√π spesso ‚Äì un pizzico di controversia legale. Le grandi aziende del settore lavorano costantemente per rendere questi modelli pi√π performanti, pi√π affidabili, pi√π ‚Äúumani‚Äù nel modo di rispondere. Ma non si tratta solo di potenza di calcolo: il vero salto lo stanno facendo con tecniche di fine-tuning mirato e dati sintetici. Detto in modo semplice, si prendono modelli generici e li si ‚Äúriprogramma‚Äù su settori specifici ‚Äì medicina, giurisprudenza, creativit√† ‚Äì usando dati nuovi, a volte prodotti proprio da un‚Äôaltra AI. Un po‚Äô come allenare un buon musicista a specializzarsi nel jazz, dopo anni di classica. Si aggiungono e affiancano anche altre tecniche prima di arrivare alla risposta vera e propria come ad esempio il Reinforcement Learning from Human Feedback: s√¨, l‚ÄôAI viene corretta anche a mano da persone in carne e ossa, che le dicono cosa suona naturale, cosa √® fuori luogo, cosa √® utile (avete presente quel pollice su/gi√π che compare alla fine in ogni risposta?). E questo, strano a dirsi, √® ci√≤ che la rende un po‚Äô meno ‚Äúmacchina‚Äù e un po‚Äô pi√π ‚Äúdialogante‚Äù.</span></p>\n<p>¬†</p>\n<h2>LLM con le mani: la nuova generazione di AI che pensa e agisce</h2>\n<p><span style=\"font-weight: 400;\">L‚ÄôAI oggi non si accontenta pi√π di rispondere a una domanda: vuole (o meglio, pu√≤) agire. Stiamo assistendo a un passaggio cruciale, quello dagli LLM tradizionali ‚Äì che producono qualcosa e si fermano l√¨ ‚Äì a </span><strong>sistemi agentici</strong><span style=\"font-weight: 400;\">, cio√® agenti digitali capaci di compiere azioni complesse, in autonomia, su pi√π passaggi. Sembra fantascienza, ma non lo √®. Immagina di chiedere a un‚ÄôIA: ‚Äú</span><i><span style=\"font-weight: 400;\">Prenotami un viaggio per Roma a ottobre, con hotel vicino al centro e voli in orari comodi.</span></i><span style=\"font-weight: 400;\">‚Äù Fino a poco fa avresti ricevuto un elenco di opzioni. Oggi, un </span><i><span style=\"font-weight: 400;\">agente AI</span></i><span style=\"font-weight: 400;\"> come quelli su cui stanno lavorando OpenAI, Google o Meta pu√≤ effettivamente aprire siti, cercare voli e hotel, confrontare prezzi, compilare moduli, e ‚Äì in certi casi ‚Äì completare il tutto. Pu√≤ interagire direttamente e in modo autonomo con piattaforme e servizi di terze parti. Il tutto seguendo una logica propria, imparata in fase di addestramento, pre-allenata dal fornitore dello strumento e </span><i><span style=\"font-weight: 400;\">senza che tu debba intervenire di continuo</span></i><span style=\"font-weight: 400;\">. E non parliamo pi√π solo di esperimenti in laboratorio: OpenAI, ad esempio, ha presentato ‚ÄúOperator‚Äù, un prototipo capace di usare un computer virtuale come farebbe un utente umano, con tanto di mouse e tastiera simulati. √à stato addestrato non solo a generare testo, ma a </span><i><span style=\"font-weight: 400;\">capire cosa fare</span></i><span style=\"font-weight: 400;\"> in contesti digitali complessi, adattandosi passo dopo passo. La novit√†? Questi agenti non sono pi√π solo bravi a scrivere, produrre immagini, audio o video¬† ‚Äì stanno diventando</span><strong> </strong><span style=\"font-weight: 400;\">capaci di </span><strong>comprendere il contesto</strong><span style=\"font-weight: 400;\"> e¬† </span><strong>portare a termine </strong><strong><i>task</i></strong><strong> pratici</strong><span style=\"font-weight: 400;\">. E, se tutto funziona come sperano le big tech, potremmo presto avere agenti personali evoluti che ci gestiscono email, documenti, viaggi e appuntamenti o interi flussi di attivit√† complesse.¬†</span></p>\n<p><span style=\"font-weight: 400;\">Ma, ovviamente, qui iniziano anche le </span><strong>domande spinose, </strong><span style=\"font-weight: 400;\">per ora ce ne poniamo solo qualcuna dato che la lista potrebbe essere molto pi√π ricca:¬†</span></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span style=\"font-weight: 400;\">Quanto possiamo fidarci di un software che agisce al posto nostro?¬†</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span style=\"font-weight: 400;\">Abbiamo davvero controllo su ci√≤ che l‚Äôagente fa quando agisce ‚Äúda solo‚Äù?¬†</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span style=\"font-weight: 400;\">E come assicurarci che faccia davvero ci√≤ che vogliamo ‚Äì e non altro?¬†</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span style=\"font-weight: 400;\">Chi √® responsabile se un agente AI prende una decisione sbagliata o dannosa?¬†</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span style=\"font-weight: 400;\">Chi controlla i filtri, i limiti e le ‚Äúzone cieche‚Äù dell‚Äôagente AI?¬†</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span style=\"font-weight: 400;\">Quanto √® accettabile ‚Äì eticamente e culturalmente ‚Äì permettere che un software ‚Äúparli e agisca per noi‚Äù?¬†</span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span style=\"font-weight: 400;\">Soprattutto nei contesti educativi, professionali o affettivi: vogliamo che le nostre parole siano le nostre, o solo le pi√π efficienti?</span></li>\n</ul>\n<hr>\n<p>Questo post √® parte della rubrica <strong><a href=\"https://pianetararo.org/traiettorie/\">TrAIettorie</a></strong> di cui potete trovare l'indice completo <a href=\"https://pianetararo.org/tags/traiettorie/\">qui</a>.</p>",
            "image": "https://pianetararo.org/media/posts/22/macchina-scrivere-robot-2.png",
            "author": {
                "name": "Pianetararo Associazione Culturale"
            },
            "tags": [
                   "TRAIETTORIE"
            ],
            "date_published": "2025-06-01T20:00:00+02:00",
            "date_modified": "2025-06-15T14:10:09+02:00"
        },
        {
            "id": "https://pianetararo.org/armi-di-distruzione-matematica-cathy-oneil/",
            "url": "https://pianetararo.org/armi-di-distruzione-matematica-cathy-oneil/",
            "title": "Armi di distruzione matematica (Cathy O‚ÄôNeil)",
            "summary": "Quando l‚Äôalgoritmo diventa ingiusto senza che ce ne accorgiamo (Recensione e riflessioni ispirate al libro di Cathy O‚ÄôNeil) C‚Äô√® un‚Äôillusione di fondo che ancora ci accompagna quando pensiamo ai numeri, alle formule, agli algoritmi: quella di una matematica ‚Äúneutrale‚Äù, distaccata, quasi al di sopra dei&hellip;",
            "content_html": "<h4 class=\"align-center\"><strong>Quando l‚Äôalgoritmo diventa ingiusto senza che ce ne accorgiamo</strong></h4>\n<p class=\"align-center\"><em>(Recensione e riflessioni ispirate al libro di Cathy O‚ÄôNeil)</em></p>\n<hr>\n<p>C‚Äô√® un‚Äôillusione di fondo che ancora ci accompagna quando pensiamo ai numeri, alle formule, agli algoritmi: quella di una matematica ‚Äú<em>neutrale</em>‚Äù, distaccata, quasi al di sopra dei pregiudizi umani. <strong>Cathy O‚ÄôNeil</strong>, con il suo libro ‚Äú<strong><a href=\"https://search.worldcat.org/it/title/1015979069\">Armi di distruzione matematica</a></strong>‚Äù, demolisce questa illusione pezzo dopo pezzo, e lo fa con una chiarezza e una passione che davvero costringono a rimettere in discussione tutto ci√≤ che pensavamo di sapere sul potere dei dati.</p>\n<p>Per chi non l‚Äôavesse ancora letto ‚Äì consigliamo vivamente di farlo, magari anche solo per farsi due domande scomode davanti alla prossima richiesta di ‚Äúaccetta i cookie‚Äù ‚Äì O‚ÄôNeil parte proprio dal suo percorso personale. Matematica di formazione, finita tra hedge fund e startup tech, lei per prima aveva creduto che pi√π numeri significasse pi√π giustizia. Invece, a Wall Street, ha visto i modelli matematici gonfiare la bolla dei subprime, amplificare rischi e ingiustizie, e, paradossalmente, fornire una giustificazione ‚Äúscientifica‚Äù a decisioni che poi, di scientifico, avevano ben poco.</p>\n<p>La cosa che colpisce √® come i modelli, una volta usciti dai laboratori e dalle simulazioni accademiche, si siano infilati in ogni anfratto della societ√†. Oggi li troviamo ovunque: dalla scuola ai tribunali, dalle banche alle pubblicit√† che ci inseguono online. E non solo: decidono chi ricever√† un prestito, chi sar√† chiamato per un colloquio, chi verr√† licenziato, chi dovr√† pagare di pi√π per l‚Äôassicurazione auto, chi sar√† sorvegliato da una pattuglia di polizia. Sembra il set di un film distopico, e invece √® la routine di ogni giorno.</p>\n<p>Leggendo O‚ÄôNeil sorge una domanda semplice e spiazzante: <strong>quando un modello matematico diventa pericoloso?</strong> Non basta dire ‚Äúquando sbaglia‚Äù, perch√© anche un modello ben fatto pu√≤ sbagliare di tanto in tanto. Il problema nasce, piuttosto, quando un algoritmo si fa opaco, si applica su vasta scala e produce danni sistemici, colpendo soprattutto chi ha meno mezzi per difendersi. Un po‚Äô come una burocrazia impazzita: fredda, senza volto, incapace di ascoltare. L√¨, s√¨, che diventa un‚Äôarma ‚Äì un‚Äôarma di distruzione matematica.</p>\n<p>Un esempio raccontato ‚Äì che resta in testa come una piccola ingiustizia che nessuno ha voglia di raccontare ‚Äì √® la storia di Sarah Wysocki, insegnante a Washington. Amata da studenti e genitori, si vede licenziata all‚Äôimprovviso perch√© un algoritmo, il famoso IMPACT, l‚Äôaveva bollata come ‚Äútra i peggiori docenti‚Äù. Poco importa se il modello, a monte, era fallato (bastava che l‚Äôanno prima fossero stati truccati i risultati dei test degli studenti per falsare tutto). Poco importa il contesto reale, la storia personale, la voce di chi la conosceva davvero. Il numero parla, il destino si compie. E nessuno che possa contestare, spiegare, nemmeno appellarsi. Cos√¨ nasce il circolo vizioso: pi√π il modello punisce, pi√π la gente impara a ‚Äúgiocare con le regole‚Äù ‚Äì truccando dati, aggirando ostacoli ‚Äì e meno il sistema assomiglia a ci√≤ che dovrebbe valutare.</p>\n<p>Poi ci sono storie pi√π quotidiane ma ugualmente inquietanti, come quella del credit scoring usato nei colloqui di lavoro. Negli Stati Uniti (ma attenzione, la tendenza si sta diffondendo anche altrove), molte aziende ora stanno controllando il punteggio di affidabilit√† creditizia anche prima di assumere. Cos√¨, chi parte gi√† da condizioni svantaggiate ‚Äì magari per colpe non sue ‚Äì si trova chiuso fuori dal mercato del lavoro. Il meccanismo, alla fine, √® quello della doppia pena: povero perch√© non hai credito, senza credito perch√© sei povero, e intanto l‚Äôalgoritmo, come un giudice invisibile, inchioda il futuro a un numero.</p>\n<p>O‚ÄôNeil ci mette in guardia: ogni volta che un modello <strong>decide sulla base di ‚Äúproxy‚Äù</strong> (cio√® sostituti di dati veri, come il codice postale al posto del rischio reale, o il test standardizzato al posto della qualit√† educativa), siamo in zona rossa. Nel baseball, ci ricorda, le statistiche funzionano perch√© ogni dato riflette azioni concrete (un punto segnato, una palla mancata). Ma quando si passa dalla palla al campo sociale, i proxy diventano pericolosi: il codice postale riflette la povert√† e, di riflesso, la razza; i punteggi dei test riflettono il contesto familiare, non solo l‚Äôimpegno. Cos√¨ l‚Äôalgoritmo, travestito da giudice imparziale, diventa lo <strong>specchio dei nostri pregiudizi</strong>.</p>\n<p>Un altro mito che O‚ÄôNeil smonta senza piet√† √® quello del ‚Äúpi√π dati uguale pi√π verit√†‚Äù. Anzi, ci ricorda che <strong>ogni modello √® una semplificazione</strong>, e che senza feedback, senza la capacit√† di correggersi quando sbaglia, rischia solo di cristallizzare gli errori. Prendi le classifiche delle universit√† americane ‚Äì veri e propri totem per studenti e famiglie, al punto che le strategie degli atenei vengono dettate da punteggi decisi da una redazione di rivista. E allora via a gonfiare le statistiche, tagliare i corsi meno redditizi, investire in palestre e campus di lusso per salire in classifica. Il vero senso dell‚Äôeducazione? Quello rischia di perdersi per strada.</p>\n<p>E poi c‚Äô√® il mondo della pubblicit√† online, che di neutrale non ha nulla. O‚ÄôNeil ci porta dietro le quinte delle universit√† ‚Äúfor-profit‚Äù, quelle che campano reclutando studenti fragili ‚Äì madri single, disoccupati, reduci di guerra ‚Äì promettendo miraggi di successo e lasciandoli solo con una montagna di debiti. La pubblicit√† mirata, in questo contesto, diventa una macchina perfetta di propaganda e selezione delle vittime: gli algoritmi scelgono chi colpire sulla base di dati che nessuno controlla, chi sta in cima al sistema incassa, chi sta in basso paga il prezzo, e spesso nemmeno si accorge di essere stato preso di mira da una ‚Äúmacchina‚Äù.</p>\n<p>Le stesse dinamiche si trovano nella giustizia: polizia predittiva, sistemi di valutazione del rischio di recidiva, sorveglianza capillare. Prendi PredPol, il software che promette di ‚Äúprevenire il crimine‚Äù (a <a href=\"https://www.imdb.com/it/title/tt0181689/\">Minority Report</a> ci stiamo arrivando) indirizzando le pattuglie dove il rischio √® pi√π alto. A parole, tutto neutrale. Ma nella pratica, chi viene sorvegliato di pi√π √® chi vive nei quartieri poveri, e cos√¨ pi√π polizia produce pi√π segnalazioni, che producono pi√π dati, che rafforzano la sorveglianza. Il rischio di automantenere un pregiudizio ‚Äì razziale, sociale ‚Äì √® enorme. E peggio ancora, spesso la persona non sa nemmeno di essere giudicata da un algoritmo; non pu√≤ difendersi, non pu√≤ discutere, non pu√≤ nemmeno sapere cosa l‚Äôha condannata. √à una sorta di tribunale segreto, in cui l‚Äôaccusato non pu√≤ parlare.</p>\n<p>Nel lavoro, la musica non cambia. Dai test di personalit√† automatizzati per le assunzioni (che finiscono spesso per discriminare chi ha storie di malattia o semplicemente risponde fuori dagli schemi) ai software che programmano i turni di lavoro nei negozi, l‚Äôalgoritmo diventa il nuovo portiere, spesso pi√π severo e meno trasparente di quelli in carne e ossa. O‚ÄôNeil racconta il caso di Kyle Behm, scartato sistematicamente da supermercati perch√© i test psicometrici lo bollavano come ‚Äúinadatto‚Äù. Nessuno che possa spiegare o correggere. Eppure, dietro la facciata dell‚Äôimparzialit√†, si nascondono nuove forme di esclusione sociale: chi √® gi√† fragile rischia di rimanere tale a tempo indeterminato, chi √® diverso dal ‚Äúmodello vincente‚Äù dell‚Äôazienda viene messo da parte senza diritto di replica.</p>\n<p>Interessante √® notare come queste forme di automazione colpiscano soprattutto i pi√π deboli: i lavori a basso salario, i candidati meno istruiti, le minoranze. La promessa di una valutazione scientifica ed equa svanisce se il sistema premia solo chi gi√† parte avvantaggiato. E chi pensa che basti ‚Äúavere il giusto profilo‚Äù per essere al sicuro, forse dovrebbe chiedersi quanto sia giusto vivere in un mondo in cui il prossimo ‚Äúupdate‚Äù dell‚Äôalgoritmo potrebbe ribaltare tutto senza preavviso.</p>\n<p>Nella sua opera O‚ÄôNeil illustra come sul posto di lavoro, poi, la logica dell‚Äôottimizzazione continua porta ad esempio a turni spezzettati, orari impossibili da conciliare con la vita familiare o stress cronico. Il termine ‚Äúclopening‚Äù, usato per chi fa chiusura serale e apertura mattutina nello stesso locale, √® ormai familiare a molti commessi e camerieri. Tutto questo per inseguire l‚Äôefficienza massima ‚Äì ogni minuto, ogni ora deve produrre qualcosa ‚Äì ma chi paga davvero sono le persone, che vedono evaporare la possibilit√† di organizzarsi, di prendersi cura dei figli, di vivere serenamente. I sistemi che dovrebbero aiutare finiscono per trasformarsi in strumenti di controllo e di precariet√†.</p>\n<p>Anche i \"colletti bianchi\" non sono immuni: software come quelli sviluppati da Cataphora (che analizzano email e scambi digitali per mappare l‚Äôinnovazione e decidere chi licenziare) rischiano di ridurre la ricchezza umana a una manciata di dati quantitativi. E se il tuo contributo non si vede nel grafico, poco importa: puoi essere tagliato senza che nessuno sappia davvero cosa hai portato all‚Äôazienda. La tentazione di ‚Äú<strong>scaricare la colpa sull‚Äôalgoritmo</strong>‚Äù √® forte, e per chi subisce il danno, √® quasi impossibile reagire.</p>\n<p>A livello di societ√†, come ci racconta O‚ÄôNeil nel contesto statunitense, il meccanismo si ripete anche nel settore finanziario. Il credito, un tempo assegnato a discrezione di funzionari spesso prevenuti, √® stato ‚Äúdemocratizzato‚Äù dal punteggio FICO, basato su dati oggettivi. Un progresso, finch√© non √® arrivata la nuova generazione di ‚Äúe-scores‚Äù, punteggi opachi costruiti su dati aggregati dai social, dagli acquisti online, dalla cronologia web. <strong>Nessuno sa davvero come funzionino</strong>, nessuno pu√≤ correggere errori, e spesso si finisce per essere valutati sulla base di variabili che non hanno nulla a che vedere con il proprio merito individuale. Sembra quasi che il vecchio ‚Äúredlining‚Äù sia tornato in versione digitale: se vivi in un certo quartiere, se hai certi amici, se non compri certi prodotti, rischi di essere escluso senza saperlo.</p>\n<p>E mentre in Europa qualcosa si muove (il GDPR offre alcune tutele, bench√© perfettibili), negli Stati Uniti il mercato dei dati personali √® ancora un far west: aziende che comprano e vendono profili comportamentali senza che tu possa dire la tua, errori che si propagano nei sistemi senza possibilit√† di rettifica, discriminazioni che passano inosservate perch√© ‚Äúautomatiche‚Äù. O‚ÄôNeil mostra con esempi concreti come le conseguenze siano spesso grottesche: chi paga l‚Äôassicurazione auto pu√≤ trovarsi premi maggiorati non per come guida, ma per il proprio credit score. Se sei povero, paghi di pi√π, e la spirale della povert√† si rafforza. Oppure pensiamo ai sensori di fitness e ai programmi di wellness aziendale: strumenti pensati per migliorare la salute finiscono per fornire alle aziende un tesoro di dati intimi, che potrebbero diventare un domani criteri di selezione per assunzioni e promozioni. Un ‚Äúhealth score‚Äù troppo basso e rischi di essere scartato, magari senza nemmeno saperlo.</p>\n<p>C‚Äô√® poi il tema della cittadinanza e della democrazia. S√¨, perch√© gli algoritmi non si fermano alla sfera privata: influenzano ci√≤ che vediamo nei feed dei social, quali notizie ci raggiungono, come vengono indirizzate le campagne elettorali. Il caso dell‚Äôesperimento di Facebook ‚Äì mostrare o meno il box ‚Äú<em>Hai votato?</em>‚Äù agli utenti, spingendo (scientificamente!) migliaia di persone in pi√π alle urne ‚Äì √® solo la punta dell‚Äôiceberg. Gia oggi viviamo gli effetti delle <strong>distorsioni </strong>sempre maggiorni a fini politici per mezzo di questi strumenti. Se la personalizzazione delle informazioni portasse a una societ√† di ‚Äú<strong>bolle informative</strong>‚Äù in cui ciascuno vive nella propria realt√† parallela? Il rischio che la democrazia stessa sia manipolata da logiche algoritmiche invisibili √® reale, e O‚ÄôNeil suona l‚Äôallarme senza mezzi termini.</p>\n<p>A questo punto, viene spontaneo chiedersi: <em>‚ÄúTutto questo riguarda davvero anche l‚ÄôItalia, oppure √® solo roba d‚Äôoltreoceano?‚Äù</em> Siamo meno avanti di Stati Uniti e Cina nell‚Äôautomazione selvaggia delle decisioni, ma la nostra quotidianit√† sta gi√† da tempo sperimentando forme pi√π o meno occulte di <em data-start=\"451\" data-end=\"475\">‚Äú<strong>giudizio algoritmico</strong>‚Äù</em>.</p>\n<p>Prendiamo il caso emblematico dell‚ÄôINPS e del cosiddetto ‚Äúalgoritmo dei navigator‚Äù durante il Reddito di Cittadinanza: il sistema, pensato per abbinare offerte di lavoro ai beneficiari, ha mostrato limiti enormi nel valutare profili e opportunit√†, spesso producendo risultati casuali o insensati, tanto che la Corte dei Conti (2023) ha evidenziato le lacune del matching automatico nelle sue relazioni.</p>\n<p><span style=\"font-weight: 400;\">Sempre nel settore del lavoro una vicenda esemplare √® quella di Deliveroo. La piattaforma di food delivery utilizzava un algoritmo (denominato </span>Frank<span style=\"font-weight: 400;\">) per gestire le prenotazioni delle sessioni di lavoro dei rider, assegnando priorit√† in base a un punteggio reputazionale di </span>‚Äúaffidabilit√†‚Äù e ‚Äúpartecipazione‚Äù<span style=\"font-weight: 400;\">. Il funzionamento preciso del modello era opaco, l‚Äôazienda non ha divulgato i criteri, ricostruiti solo grazie alle testimonianze dei rider. In pratica, il sistema penalizzava in modo uniforme qualsiasi cancellazione tardiva di un turno, </span>senza considerare i motivi<span style=\"font-weight: 400;\">. Ci√≤ significava che un rider veniva declassato nel ranking anche se rinunciava a una consegna per causa di forza maggiore, ad esempio sciopero, guasto, incidente o un malessere. Trattando allo stesso modo assenze giustificate e non, l‚Äôalgoritmo finiva per </span><strong>discriminare indirettamente</strong><span style=\"font-weight: 400;\"> i lavoratori riducendo le loro opportunit√† di prenotare le fasce orarie pi√π redditizie. Nel 2020 il Tribunale di Bologna ha riconosciuto questo effetto distorsivo</span><span style=\"font-weight: 400;\">¬†condannando Deliveroo per condotta illegittima nei confronti dei rider.</span></p>\n<p><span style=\"font-weight: 400;\">Anche nel mondo della scuola italiana si √® verificato un caso tipico di algoritmo dagli effetti perversi. Nel 2016, a seguito della riforma detta ‚ÄúBuona Scuola‚Äù, il Ministero dell‚ÄôIstruzione ha utilizzato un sistema automatizzato per gestire la </span>mobilit√† di oltre 100 mila insegnanti<span style=\"font-weight: 400;\"> su tutto il territorio nazionale. L‚Äôobiettivo era assegnare le sedi in base a punteggi di servizio e preferenze, ma il risultato √® stato caotico: </span>migliaia di docenti con punteggi alti sono stati trasferiti lontano da casa<span style=\"font-weight: 400;\">, spesso dal Sud al Nord, mentre cattedre pi√π vicine venivano attribuite a colleghi con punteggi inferiori. L‚Äô‚Äúalgoritmo impazzito‚Äù, come fu ribattezzato, presentava errori e criteri oscuri, generando proteste diffuse per le </span>ingiustizie e disagi familiari<span style=\"font-weight: 400;\"> causati. In seguito, una sentenza del TAR del Lazio ha censurato duramente quel sistema, definendolo un </span><strong>‚Äúmetodo orwelliano‚Äù</strong><span style=\"font-weight: 400;\"> in cui una decisione cos√¨ delicata era lasciata a un algoritmo non supervisionato. I giudici hanno evidenziato che il software operava in modo </span>confuso e lacunoso<span style=\"font-weight: 400;\">, basato su dati inseriti male, e soprattutto che </span>non rispettava il merito.</p>\n<p>In campo finanziario, gli algoritmi di credit scoring ‚Äì usati da banche e finanziarie per decidere a chi concedere un prestito e a quali condizioni ‚Äì possono generare <strong data-start=\"8263\" data-end=\"8292\">discriminazioni indirette</strong> verso determinate categorie. In Italia sono emerse evidenze di bias soprattutto nei confronti dei clienti immigrati. Studi recenti condotti anche dalla Banca d‚ÄôItalia hanno rilevato che, <em>a parit√† di caratteristiche socio-economiche</em>, un richiedente straniero ha una probabilit√† di vedersi rifiutare un mutuo pi√π alta di circa 2-3 punti percentuali rispetto a un pari profilo italiano. Inoltre, anche quando il finanziamento viene erogato o viene dimostrata una storia creditizia solida, ai clienti non nativi spesso tocca un tasso d‚Äôinteresse leggermente superiore (in media pochi decimali in pi√π) rispetto ai mutuatari italiani. Questa disparit√† suggerisce che gli algoritmi utilizzati incorporano variabili o dati proxy correlati con l‚Äôorigine etnica/nazionale.</p>\n<p><span style=\"font-weight: 400;\">Anche nella pubblica amministrazione italiana si stanno affacciando sistemi di </span><strong>punteggio algoritmico dei cittadini</strong><span style=\"font-weight: 400;\"> che hanno sollevato dibattito. Ispirandosi (inconsapevolmente) al discusso modello di ‚Äúcredito sociale‚Äù cinese, alcuni enti locali hanno proposto di premiare con punti i comportamenti virtuosi dei residenti. Ad esempio </span>Roma<span style=\"font-weight: 400;\"> ha testato lo </span><i><span style=\"font-weight: 400;\">Smart Citizen Wallet</span></i><span style=\"font-weight: 400;\">, un portafoglio digitale dove i cittadini accumulano crediti se usano mezzi pubblici o riciclano correttamente; il </span>Comune di Bologna<span style=\"font-weight: 400;\"> ha ipotizzato un sistema simile di </span>incentivi per chi adotta stili di vita ‚Äúgreen‚Äù<span style=\"font-weight: 400;\">, dalla mobilit√† sostenibile alla differenziata. Il caso pi√π estremo √® per√≤ quello di </span>Fidenza<span style=\"font-weight: 400;\">: qui l‚Äôamministrazione ha introdotto un meccanismo a punti per gli inquilini delle </span>case popolari<span style=\"font-weight: 400;\">, valutandone il comportamento sociale. I destinatari degli alloggi ottengono bonus o malus e </span>possono persino essere<strong> sfrattati se perdono tutti i punti</strong><span style=\"font-weight: 400;\"> accumulati negativamente. L‚Äôintento dichiarato √® responsabilizzare e incoraggiare il rispetto delle regole condominiali, ma una simile misura rischia di </span>colpire proprio i pi√π fragili<span style=\"font-weight: 400;\">. Iniziative del genere infatti </span>premiano chi pu√≤ permettersi comportamenti ‚Äúvirtuosi‚Äù.<strong>¬†</strong>Senza un opportuno <strong data-start=\"11889\" data-end=\"11913\">contesto di supporto</strong> (migliori trasporti pubblici, politiche sociali, dialogo con i cittadini), questo ‚Äú<strong>rating civico</strong>‚Äù finisce per amplificare le disuguaglianze: per di pi√π raccogliendo una mole di dati personali sui cittadini. Non sorprende quindi che il Garante Privacy e varie associazioni abbiano espresso allarme su questi progetti, evidenziando il rischio di derive antidemocratiche e chiedendone una revisione prima di una loro eventuale attuazione su larga scala.</p>\n<p>A leggere tutto questo, verrebbe da cedere allo sconforto. E invece il libro di O‚ÄôNeil √®, paradossalmente, un invito a reagire. Non a demonizzare la tecnologia, sia chiaro ‚Äì lei stessa, da matematica, ama la disciplina e sa quanto bene pu√≤ fare quando √® usata con consapevolezza e responsabilit√†. Il punto √® non delegare alla matematica (o meglio, a chi la scrive in codice) il compito di decidere cosa √® giusto e cosa no. Serve trasparenza, s√¨, ma serve soprattutto <strong>coscienza collettiva</strong>. Perch√© ogni algoritmo <strong>nasce da scelte umane</strong> ‚Äì da un‚Äôidea di successo, da una definizione di ‚Äúmerito‚Äù, da una scala di valori. Se quei valori sono mal definiti o ciechi rispetto alle diversit√† reali, allora anche il modello pi√π sofisticato diventa una gabbia, e la matematica smette di essere un‚Äôamica della giustizia.</p>\n<p>Forse √® il momento di pensare a una <strong>‚Äúdeontologia degli algoritmi‚Äù</strong>, come suggerisce O‚ÄôNeil: un codice etico per chi scrive, addestra, implementa sistemi che incidono sulle vite delle persone. Immagina se ogni data scientist dovesse giurare, come un medico, di ‚Äúnon nuocere‚Äù. S√¨, sembra idealistico, ma l‚Äôalternativa √® rassegnarsi a una societ√† in cui nessuno sa davvero perch√© le cose gli capitano ‚Äì se hai ottenuto un mutuo, se sei stato scartato da un lavoro, se hai ricevuto una pubblicit√† mirata proprio nel giorno di maggiore fragilit√†.</p>\n<p>Certo, la soluzione non pu√≤ essere solo individuale. O‚ÄôNeil fa notare che senza organismi di controllo pubblici ‚Äì senza ‚Äúauditor degli algoritmi‚Äù, senza regole chiare su cosa si pu√≤ e non si pu√≤ automatizzare ‚Äì rischiamo di inseguire i problemi senza mai affrontarli davvero. L‚ÄôEuropa con l'AI Act si sta provando ad andare in questa direzione, ma sarebbe ora di pensare a istituzioni che vigilino sui modelli ad alto impatto sociale con la stessa seriet√† con cui si controllano i farmaci o le banche.</p>\n<p>Una nota finale, ma che finale non √®: l‚Äôarma di distruzione matematica, in fondo, non √® altro che la matematica privata del suo feedback umano, cieca al contesto, sorda ai casi particolari, indifferente alla storia. Per renderla innocua ‚Äì o meglio, per trasformarla in un‚Äôalleata ‚Äì <strong>serve reintegrare nel processo decisionale le persone</strong>, le loro voci, la possibilit√† di spiegare e correggere. Non tutto pu√≤ essere ridotto a numero, e la democrazia si misura anche da quanto riesce a difendere questa irriducibile complessit√†.</p>\n<p>Non ci sono risposte facili, ma c‚Äô√® una certezza: <strong>il dibattito va portato fuori dai circoli degli esperti, reso materia di educazione civica e di conversazione pubblica</strong>. Gli algoritmi sono troppo importanti per essere lasciati solo ai tecnici, troppo pervasivi per essere ignorati. Se non vogliamo che diventino la nuova burocrazia inespugnabile del XXI secolo, serve un nuovo patto tra scienza, societ√† e diritti umani. E serve subito.</p>\n<p class=\"align-center\">¬´<em>i modelli non sono altro che opinioni scritte nel linguaggio della matematica</em>¬ª cit.</p>\n<p>Forse la vera domanda non √® se gli algoritmi siano ‚Äú<em>buoni</em>‚Äù o ‚Äú<em>cattivi</em>‚Äù, ma se siamo ancora capaci ‚Äì come societ√† ‚Äì di discuterne insieme, di <strong>pretendere che restino strumenti al nostro servizio</strong>, e non il contrario. O‚ÄôNeil con le sue indagini accende la luce in una stanza che sembrava perfettamente in ordine, e ci mostra la polvere sotto il tappeto. Ora, a noi decidere cosa farne.¬†</p>\n<hr>\n<p>Questo post √® parte della rubrica <strong><a href=\"https://pianetararo.org/traiettorie/\">TrAIettorie</a></strong> di cui potete trovare l'indice completo <a href=\"https://pianetararo.org/tags/traiettorie/\">qui</a>.</p>",
            "image": "https://pianetararo.org/media/posts/23/Gemini_Generated_Image_mh5uqymh5uqymh5u-2.jfif",
            "author": {
                "name": "Pianetararo Associazione Culturale"
            },
            "tags": [
                   "TRAIETTORIE"
            ],
            "date_published": "2025-05-01T21:27:00+02:00",
            "date_modified": "2025-06-13T16:17:12+02:00"
        },
        {
            "id": "https://pianetararo.org/privacy-e-intelligenza-artificiale-cosa-dobbiamo-sapere-nel-2025/",
            "url": "https://pianetararo.org/privacy-e-intelligenza-artificiale-cosa-dobbiamo-sapere-nel-2025/",
            "title": "Privacy e intelligenza artificiale: cosa dobbiamo sapere nel 2025",
            "summary": "Diciamocelo: ormai interagire con un chatbot ‚Äì che sia ChatGPT, Gemini, Claude o uno dei mille assistenti virtuali ‚Äì √® diventato quasi come fare una chiacchierata al bar. Solo che, al posto del barista, c‚Äô√® un algoritmo che ci risponde in un italiano perfetto (o&hellip;",
            "content_html": "<p><span style=\"font-weight: 400;\">Diciamocelo: ormai interagire con un chatbot ‚Äì che sia ChatGPT, Gemini, Claude o uno dei mille assistenti virtuali ‚Äì √® diventato quasi come fare una chiacchierata al bar. Solo che, al posto del barista, c‚Äô√® un algoritmo che ci risponde in un italiano perfetto (o quasi). Studenti, insegnanti, genitori, professionisti ‚Äì chi pi√π chi meno ‚Äì ci siamo messi a ‚Äúparlare‚Äù con queste AI per fare domande, chiedere aiuto, o semplicemente toglierci una curiosit√†. Ma sai cosa? Ogni volta che parliamo con un LLM ‚Äì un modello linguistico generativo, per usare il termine tecnico ‚Äì stiamo lasciando dietro di noi una scia di dati. Un po‚Äô come se, dopo aver chiesto al barista un consiglio, scoprissimo che stava registrando la nostra conversazione per studiarci meglio.</span></p>\n<p><span style=\"font-weight: 400;\">E qui si apre un tema enorme: </span><strong>la privacy</strong><span style=\"font-weight: 400;\">. Perch√© questi strumenti, s√¨, sono incredibili ‚Äì ma a che prezzo? Quali dati cediamo, consapevoli o meno, quando chiediamo un consiglio per l‚Äôansia, carichiamo la foto di famiglia su un generatore d‚Äôimmagini, o raccontiamo una situazione privata al chatbot? Questo articolo (che s√¨, √® lungo, ma merita) prova a fare chiarezza e stimolare qualche riflessione. Analizzeremo i rischi, le leggi in gioco ‚Äì il </span><a href=\"https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32016R0679\"><span style=\"font-weight: 400;\">GDPR</span></a><span style=\"font-weight: 400;\">, l‚Äô</span><a href=\"https://artificialintelligenceact.eu/\"><span style=\"font-weight: 400;\">AI Act</span></a><span style=\"font-weight: 400;\">¬† ‚Äì e ci faremo anche qualche domanda scomoda: </span><strong>cosa fanno le Big Tech con i nostri dati?</strong><span style=\"font-weight: 400;\"> E noi, ci dobbiamo preoccupare?</span></p>\n<p><span style=\"font-weight: 400;\">Prima per√≤, fermiamoci un attimo a guardare i rischi veri. Quelli meno ovvi. Quelli che spesso ignoriamo mentre chattiamo con l‚ÄôIA pensando ‚Äútanto √® solo un robot‚Äù.</span></p>\n<p><span style=\"font-weight: 400;\">Non √® roba da smanettoni o da esperti: riguarda tutti noi. Studenti, insegnanti, genitori, professionisti, chiunque usi questi strumenti per lavorare, imparare o semplicemente divertirsi. Perch√© l‚ÄôIA non √® pi√π ‚Äúroba da laboratorio‚Äù: √® parte della nostra vita di tutti i giorni. E capire come funziona ‚Äì e come pu√≤ influire sulla nostra privacy ‚Äì √® un modo per proteggere non solo i nostri dati, ma anche la nostra libert√† di essere chi siamo, senza che un algoritmo ci metta in un‚Äôetichetta.</span></p>\n<h2>I rischi principali: una panoramica pratica</h2>\n<p><span style=\"font-weight: 400;\">Partiamo dalle basi. Usare uno strumento di Intelligenza artificiale, per esempio un Large Language Model come ChatGPT, non √® come scrivere sul quaderno: √® come parlare in un microfono acceso, con qualcuno (o qualcosa) che sta ascoltando, registrando e, talvolta, imparando da quello che diciamo. Ecco una carrellata di rischi, spiegati in modo semplice ‚Äì con esempi reali, perch√© non stiamo parlando di teorie campate in aria.</span></p>\n<h5>‚ö†Ô∏è Condivisione involontaria di dati</h5>\n<p><span style=\"font-weight: 400;\">Quando scrivi ‚ÄúEhi ChatGPT, dammi un consiglio per il compleanno del mio amico Marco, che soffre di ansia‚Äù? Ecco: in quel momento hai appena dato due informazioni personali ‚Äì il nome di Marco e un dato sensibile sulla sua salute. Magari non ci hai fatto caso, ma il chatbot (e chi lo gestisce) le ha registrate. E potrebbero rimanere l√¨, nei log, anche per mesi.</span></p>\n<h5>‚ö†Ô∏èPrompt conservati e riutilizzati</h5>\n<p><span style=\"font-weight: 400;\">Le conversazioni con gli LLM non spariscono nel nulla. Spesso vengono archiviate e usate per ‚Äúinsegnare‚Äù al modello a migliorare. Quindi il tuo messaggio, la tua storia, le tue domande ‚Äì potrebbero contribuire ad addestrare la prossima versione di quel chatbot. Se pensi che basti cancellare la cronologia per stare tranquilli, sappi che anche in quel caso i dati potrebbero rimanere salvati per 30 giorni (come succedeva e succede anche con alcuni piani con ChatGPT) oppure anche </span><a href=\"https://www.repubblica.it/tecnologia/2025/06/09/news/open-ai-obbligata-conservare-conversazioni-chatgpt-new-york-times-424657181/\"><span style=\"font-weight: 400;\">per sempre</span></a><span style=\"font-weight: 400;\">.</span></p>\n<h5>‚ö†Ô∏èOcchi umani dietro le quinte</h5>\n<p><span style=\"font-weight: 400;\">Non c‚Äô√® solo l‚Äôalgoritmo: a volte, per migliorare l‚ÄôIA, ci sono anche persone in carne e ossa che leggono pezzi delle conversazioni. Certo, si parla di chat ‚Äúanonimizzate‚Äù, ma se scrivi ‚ÄúMio figlio Lorenzo fa le medie a Roma e ha problemi con la matematica‚Äù, quei dati, anche senza il tuo nome, sono comunque riconoscibili. E magari finiscono davanti agli occhi di un revisore umano, chiss√† dove nel mondo.</span></p>\n<h5>‚ö†Ô∏èTracciamento invisibile e fingerprinting</h5>\n<p><span style=\"font-weight: 400;\">Un po‚Äô come quando navighi su un sito e ti senti ‚Äúseguito‚Äù dagli annunci, anche qui i sistemi AI raccolgono informazioni di contorno: il tuo IP, il browser, il dispositivo, perfino quanto tempo rimani su una pagina o a che ora scrivi. Tutti dettagli che, messi insieme, costruiscono un profilo abbastanza dettagliato ‚Äì e tu magari nemmeno te ne accorgi. √à come lasciare briciole digitali che qualcun altro raccoglie.</span></p>\n<h5>‚ö†Ô∏è¬†Profilazione implicita</h5>\n<p><span style=\"font-weight: 400;\">Anche senza dirlo esplicitamente, il chatbot pu√≤ ‚Äúcapire‚Äù cose su di te. Se gli chiedi spesso consigli su sintomi di malattie, oppure parli di viaggi in determinati Paesi, o di hobby particolari, il sistema pu√≤ dedurre ‚Äì e magari registrare ‚Äì che sei interessato a quelle cose. E questo profilo, se finisce in mani sbagliate o viene usato per scopi di marketing, o peggio azioni di condizionamento e diventa un problema serio.</span></p>\n<h5>‚ö†Ô∏è Perdita di controllo sui dati</h5>\n<p><span style=\"font-weight: 400;\">Una volta che i tuoi dati entrano in un sistema AI , non c‚Äô√® pi√π modo di riprenderli indietro. Sono archiviati su server, magari in un altro continente, e chi garantisce che non vengano usati in futuro per scopi diversi? Pensiamo, ad esempio, a una mamma che carica foto di famiglia su un generatore di immagini AI: quelle immagini potrebbero essere usate per altro, e se domani c‚Äô√® una violazione o un cambio di policy, potrebbero anche finire in mani sbagliate.¬†</span></p>\n<h5>‚ö†Ô∏è Memorizzazione nascosta e rischio leak</h5>\n<p><span style=\"font-weight: 400;\">Ecco il punto forse pi√π inquietante: i modelli AI apprendono dai dati, e talvolta possono ‚Äúricordare‚Äù dettagli sensibili, anche se non dovrebbero. Ci sono stati casi in cui i ricercatori hanno dimostrato che un chatbot poteva rigenerare numeri di carte di credito usate durante l‚Äôaddestramento. E se capita con una carta, perch√© non con il tuo indirizzo email o il nome del tuo amico Marco?</span></p>\n<h5>‚ö†Ô∏è Repsonsabilit√† per condivisione di dati riservati</h5>\n<p><span style=\"font-weight: 400;\">Argomento decisamente problematico. Quando condividi con il chatbot un pdf, l'email (magari con dati personali altrui), il codice sorgente, un file excel che desideri rielaborare o riassumere ? Sei sicuro di poterlo fare ? Stai condividendo materiale generico o materiale riservato, magari protetto da diritti autore o segreto industriale? Occorre riflettere e porre attenzione sui materiali che maneggiamo in relazione agli strumenti che utlizziamo. Nel dubbio vale la regola - evitare.</span></p>\n<h5>‚ö†Ô∏è Allucinazioni problematiche o pericolose</h5>\n<p><span style=\"font-weight: 400;\">Le AI non sono infallibili. Possono ‚Äúinventare‚Äù dati ‚Äì e a volte, quei dati inventati riguardano persone vere. Se il chatbot ti d√† la data di nascita sbagliata di un politico, o ti attribuisce un titolo di studio che non hai mai conseguito, si tratta di un problema serio di accuratezza. E correggere questi errori? Spesso impossibile, perch√© l‚ÄôIA non sa nemmeno da dove ha preso quell‚Äôinformazione.</span></p>\n<h5>‚ö†Ô∏è Minori e poca protezione</h5>\n<p><span style=\"font-weight: 400;\">Non dimentichiamo i pi√π giovani: i minorenni usano chatbot senza sempre capire i rischi. Fino al 2023, bastava inserire una data di nascita falsa per usare ChatGPT, anche se avevi 12 anni. Solo dopo interventi dei Garanti (come quello italiano) si √® iniziato a introdurre controlli pi√π robusti, ma il problema rimane: i dati dei minori finiscono spesso nel sistema, senza garanzie e consapevolezza.</span></p>\n<h5>‚ö†Ô∏è Data breach e falle di sicurezza</h5>\n<p><span style=\"font-weight: 400;\">Infine, i bug e le violazioni. √à gi√† successo (ad esempio a marzo 2024, con ChatGPT) che per errore tecnico alcuni utenti vedessero le chat di altri ‚Äì inclusi dettagli su abbonamenti e pagamenti. OpenAI all‚Äôepoca non avvis√≤ subito tutti i Garanti europei, e questo ha portato a una multa salata. √à un promemoria importante: i dati che forniamo a queste piattaforme non sono blindati, e un semplice bug pu√≤ renderli visibili ad altri.</span></p>\n<hr>\n<h2>Le regole del gioco: GDPR, AI Act e il nodo della privacy nell‚ÄôIA</h2>\n<p><span style=\"font-weight: 400;\">Cosa rende il mondo dell‚Äôintelligenza artificiale cos√¨ affascinante, ma anche cos√¨ complicato? Il fatto che corriamo alla velocit√† della luce ‚Äì nuovi modelli, nuove app, nuove possibilit√† ‚Äì mentre le leggi, beh, fanno un po‚Äô fatica a stare al passo. E non √® per cattiveria: regolamentare l‚ÄôIA √® come provare a dare la caccia a un‚Äôombra che cambia forma ogni volta che ti avvicini. Ma vediamo insieme cosa sta succedendo, perch√© se usi un chatbot, agenti o lavori con questi strumenti, capire le regole √® fondamentale.</span></p>\n<h3>Il GDPR: una bussola ancora valida, ma con qualche ammaccatura</h3>\n<p><span style=\"font-weight: 400;\">Partiamo da quello che gi√† conosciamo: il </span><a href=\"https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32016R0679\"><strong>Regolamento Generale sulla Protezione dei Dati (GDPR)</strong></a><span style=\"font-weight: 400;\">. S√¨, proprio quello che ci ricorda di leggere le informative privacy (quelle chilometriche che spesso scorriamo velocemente). Il GDPR non √® roba vecchia: anche nel 2025 resta </span><strong>la cornice principale</strong><span style=\"font-weight: 400;\"> per la protezione dei dati personali in Europa, e si applica pure ai dati trattati dagli LLM.</span></p>\n<p><span style=\"font-weight: 400;\">Perch√© √® importante? Perch√© il GDPR stabilisce principi fondamentali come:</span></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><strong>Trasparenza</strong><span style=\"font-weight: 400;\">: devi sapere come vengono usati i tuoi dati.</span><span style=\"font-weight: 400;\"><br><br></span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><strong>Minimizzazione</strong><span style=\"font-weight: 400;\">: non si possono raccogliere pi√π dati del necessario.</span><span style=\"font-weight: 400;\"><br><br></span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><strong>Esattezza</strong><span style=\"font-weight: 400;\">: i dati personali devono essere corretti e aggiornati.</span><span style=\"font-weight: 400;\"><br><br></span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><strong>Sicurezza</strong><span style=\"font-weight: 400;\">: le aziende devono proteggere i tuoi dati da violazioni o furti.</span><span style=\"font-weight: 400;\"><br><br></span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><span style=\"font-weight: 400;\">E, soprattutto, </span><strong>diritti dell‚Äôinteressato</strong><span style=\"font-weight: 400;\">: puoi chiedere di accedere ai tuoi dati, farli cancellare, correggere o opporsi al trattamento.</span><span style=\"font-weight: 400;\"><br><br></span></li>\n</ul>\n<p><span style=\"font-weight: 400;\">Ora, fin qui tutto chiaro, no? Ma il punto √® che </span><strong>gli LLM non sono come una rubrica telefonica</strong><span style=\"font-weight: 400;\">. Sono sistemi complessi, che apprendono da quantit√† immense di dati ‚Äì inclusi i tuoi post sui social, i tuoi articoli, perfino quel commento lasciato dieci anni fa su un forum dimenticato. E qui casca l‚Äôasino: </span><strong>su quale base legale si fonda il loro addestramento?</strong></p>\n<h3>La questione della base giuridica: legittimo interesse o consenso?</h3>\n<p><span style=\"font-weight: 400;\">Prendiamo </span><a href=\"https://www.agendadigitale.eu/sicurezza/privacy/ai-di-meta-e-davvero-legittimo-interesse-lecito-dubitarne/\"><span style=\"font-weight: 400;\">Meta</span></a><span style=\"font-weight: 400;\"> o OpenAI e ChatGPT come esempio. Quando hanno iniziato a raccogliere dati da internet (forum, blog, pagine web) per addestrare i modelli, non hanno chiesto a nessuno. Nessuna email, nessun banner di consenso. Loro hanno detto: ‚ÄúVa bene cos√¨, √® nel nostro legittimo interesse‚Äù.</span></p>\n<p><span style=\"font-weight: 400;\">Il problema? Beh, il GDPR non √® cos√¨ permissivo. Usare dati personali ‚Äì anche se pubblici ‚Äì per scopi di addestramento richiede una </span><strong>valutazione rigorosa</strong><span style=\"font-weight: 400;\">, e forse anche il consenso esplicito degli interessati. Il Garante Privacy italiano, infatti, ha sollevato la questione: </span><strong>‚ÄúScusate, ma su che base giuridica avete preso e usato questi dati?‚Äù</strong></p>\n<p><span style=\"font-weight: 400;\">Risultato: il caso √® finito per esempio nelle mani dell‚ÄôAutorit√† irlandese (che, per via del meccanismo del ‚Äúone-stop-shop‚Äù in UE, funge da capofila per OpenAI). E qui siamo ancora in attesa di una decisione chiara, ma il messaggio √® forte: </span><strong>le regole valgono per tutti, anche per le Big Tech</strong><span style=\"font-weight: 400;\">. Non basta dire ‚Äú√® nel nostro interesse‚Äù. Serve dimostrarlo.</span></p>\n<h3>Trasparenza: il nodo delle informative (e la fatica di capirle)</h3>\n<p><span style=\"font-weight: 400;\">Il GDPR impone anche che le aziende spieghino bene come usano i dati. Ma spiegare bene, cosa significa? Facciamo un esempio: per un po‚Äô, OpenAI non diceva chiaramente che i prompt degli utenti (cio√® le domande fatte a ChatGPT) venivano usati per addestrare il modello. N√© specificava che i dati personali inseriti nelle chat potevano finire in mano a revisori umani.</span></p>\n<p><span style=\"font-weight: 400;\">Solo dopo l‚Äôintervento del </span><a href=\"https://www.garanteprivacy.it/home/docweb/-/docweb-display/docweb/10085432\"><span style=\"font-weight: 400;\">Garante italiano ‚Äì con tanto di sanzione da 15 milioni di euro a dicembre 2024 ‚Äì OpenAI</span></a><span style=\"font-weight: 400;\"> ha dovuto aggiornare la privacy policy, avviare una campagna informativa, e mettere a disposizione opzioni per ‚Äúuscire‚Äù dal training (l‚Äôopt-out). Ma resta un problema: </span><strong>anche se disattivi la cronologia, i tuoi dati restano per 30 giorni sui server.</strong><span style=\"font-weight: 400;\"> E, spesso, non √® cos√¨ semplice capire dove finiscano davvero le informazioni.</span></p>\n<p><span style=\"font-weight: 400;\">√à un po‚Äô come leggere le clausole scritte in piccolo in un contratto di assicurazione: puoi farlo, ma devi armarti di pazienza ‚Äì e magari di una lente d‚Äôingrandimento.</span></p>\n<h3>Esattezza e allucinazioni: quando l‚ÄôIA sbaglia (e non puoi rimediare)</h3>\n<p><span style=\"font-weight: 400;\">Un altro tema caldo √® quello dell‚Äô</span><strong>accuratezza</strong><span style=\"font-weight: 400;\">. Secondo il GDPR, i dati personali devono essere </span><strong>corretti e aggiornati</strong><span style=\"font-weight: 400;\">. Ma con un LLM, come fai? Se il modello ha imparato che ‚ÄúMario Rossi √® nato nel 1978‚Äù e in realt√† Mario Rossi √® nato nel 1982, come correggi quell‚Äôinformazione? La risposta breve √®: </span><strong>non puoi, almeno non facilmente</strong><span style=\"font-weight: 400;\">.</span></p>\n<h3>Minori e soggetti vulnerabili: tutele deboli, rischi alti</h3>\n<p><span style=\"font-weight: 400;\">Un altro punto dolente riguarda i </span><strong>minori</strong><span style=\"font-weight: 400;\">. Il GDPR dice chiaramente che per usare un servizio online sotto i 16 anni (o 13, in base allo Stato), serve il consenso dei genitori. Eppure, fino a poco tempo fa, chiunque poteva accedere a ChatGPT semplicemente inserendo una data di nascita a caso. Solo dopo il richiamo del Garante, OpenAI ha introdotto controlli pi√π robusti (prima un semplice ‚Äúage-gate‚Äù, poi un sistema pi√π avanzato con verifica di terze parti). Ma siamo ancora in una fase di rodaggio: il sistema funziona davvero? E come si tutelano i dati dei minori una volta dentro il sistema?</span></p>\n<p><span style=\"font-weight: 400;\">Insomma, le falle ci sono. E l‚Äôimpressione √® che le aziende abbiano corso per lanciare i prodotti, senza preoccuparsi troppo delle regole ‚Äì salvo poi correre ai ripari quando arrivano le multe.</span></p>\n<h3>Il nuovo arrivato: l‚ÄôAI Act europeo</h3>\n<p><span style=\"font-weight: 400;\">E ora parliamo di lui, l‚Äô</span><a href=\"https://artificialintelligenceact.eu/\"><strong>AI Act</strong></a><span style=\"font-weight: 400;\">, che nel 2025 √® in dirittura d‚Äôarrivo come primo regolamento europeo ‚Äúomnibus‚Äù sull‚ÄôIA. Il GDPR resta la legge sui dati personali, ma l‚ÄôAI Act interviene </span><strong>a monte</strong><span style=\"font-weight: 400;\">, fissando regole per lo sviluppo e l‚Äôuso delle AI ‚Äì compresi i modelli generativi come ChatGPT.</span></p>\n<p><span style=\"font-weight: 400;\">Quali sono i punti chiave? Te li riassumo cos√¨:</span></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><strong>Classificazione per rischio</strong><span style=\"font-weight: 400;\">: l‚ÄôIA viene divisa in categorie (inaccettabile, alto rischio, basso, minimo). Gli LLM general-purpose non sono ‚Äúad alto rischio‚Äù di per s√©, ma attenzione: se usati in certi contesti (per esempio per la selezione del personale), scattano regole pi√π stringenti.</span><span style=\"font-weight: 400;\"><br><br></span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><strong>Trasparenza sui dati di training</strong><span style=\"font-weight: 400;\">: i fornitori dovranno pubblicare un ‚Äúriassunto‚Äù dei dati usati per addestrare il modello. Non tutti i dettagli, ma almeno un‚Äôindicazione. Questo per dare un minimo di controllo: sapere se ci sono dentro i tuoi post o quelli di qualcun altro.</span><span style=\"font-weight: 400;\"><br><br></span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><strong>Obblighi di sicurezza</strong><span style=\"font-weight: 400;\">: ridurre il rischio di output illegali o discriminatori.</span><span style=\"font-weight: 400;\"><br><br></span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><strong>Etichettatura dei contenuti generati</strong><span style=\"font-weight: 400;\">: testi, immagini, video prodotti dall‚ÄôIA dovranno essere segnalati come tali, per evitare inganni e deepfake.</span><span style=\"font-weight: 400;\"><br><br></span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><strong>Divieti specifici</strong><span style=\"font-weight: 400;\">: per esempio, niente pi√π scraping massivo di immagini per creare database di riconoscimento facciale, niente AI per manipolare il comportamento umano in modi dannosi.</span><span style=\"font-weight: 400;\"><br><br></span></li>\n</ul>\n<p><span style=\"font-weight: 400;\">Il messaggio √® chiaro: pi√π regole, pi√π responsabilit√†. E, se non si rispettano, si rischiano multe pesanti: fino a 40 milioni di euro o il 7% del fatturato.</span></p>\n<p><span style=\"font-weight: 400;\">Ma attenzione: l‚ÄôAI Act non sostituisce il GDPR. Piuttosto, ci lavora insieme: il GDPR tutela i dati a valle, l‚ÄôAI Act agisce a monte. In pratica, il GDPR dice: ‚ÄúSe tratti dati personali, fallo bene‚Äù. L‚ÄôAI Act aggiunge: ‚ÄúE se sviluppi l‚ÄôIA, progettala in modo sicuro, trasparente e rispettoso dei diritti delle persone‚Äù.</span></p>\n<h2>Casi concreti: quando i rischi diventano realt√†</h2>\n<p><span style=\"font-weight: 400;\">A questo punto potresti pensare: ‚ÄúOk, tutto chiaro, ma questi rischi sono solo ipotesi o sono gi√† successe cose serie?‚Äù. Spoiler: sono successe. Eccome, e altre ne succederanno in futuro. Ecco alcuni casi che mostrano come le cose possano andare storte ‚Äì anche quando si tratta di aziende multimiliardarie.</span></p>\n<h5><strong>üö® </strong>La sanzione italiana a OpenAI: un campanello d‚Äôallarme</h5>\n<p><span style=\"font-weight: 400;\">Dicembre 2024, Italia. OpenAI si becca una multa da 15 milioni di euro per violazioni al GDPR legate a ChatGPT: mancanza di trasparenza, nessun filtro per i minori, inesattezze nei dati, e per finire, una notifica incompleta di un data breach. In pratica, OpenAI aveva creato uno strumento potentissimo, ma si era dimenticata (o aveva trascurato) le regole europee sulla privacy. La multa italiana √® stata la prima di questo livello in Europa per un sistema di AI generativa. Un segnale fortissimo, quasi un messaggio in codice: ‚ÄúEhi, Big Tech, svegliatevi. Le regole valgono anche per voi‚Äù.</span></p>\n<p><span style=\"font-weight: 400;\">E guarda caso, dopo questo scossone, altre autorit√† europee hanno iniziato a muoversi, e il Comitato Europeo per la Protezione dei Dati (EDPB) ha creato una task force su ChatGPT. Segno che, ormai, l‚Äôattenzione √® alta.</span></p>\n<h5>üö® Il reclamo NOYB in Austria: l‚ÄôIA non √® infallibile</h5>\n<p><span style=\"font-weight: 400;\">Altro caso interessante:</span><a href=\"https://noyb.eu/it/chatgpt-provides-false-information-about-people-and-openai-cant-correct-it\"><span style=\"font-weight: 400;\"> il reclamo presentato da NOYB</span></a><span style=\"font-weight: 400;\"> (l‚Äôassociazione fondata da Max Schrems, un nome che chi si occupa di privacy conosce bene) contro OpenAI in Austria. Il problema? Un personaggio pubblico ha chiesto a ChatGPT informazioni su di s√© e ha ricevuto dati sbagliati. Ha provato a far correggere l‚Äôerrore, ma niente da fare: OpenAI ha detto che non pu√≤ n√© modificare i dati generati n√© sapere esattamente da dove provengano.</span></p>\n<h5>üö®¬†Il bug di ChatGPT (2023): quando le chat private diventano pubbliche</h5>\n<p><span style=\"font-weight: 400;\">Marzo 2023. Un bug tecnico su ChatGPT permette ad alcuni utenti di vedere i titoli delle conversazioni di altri e, in certi casi, dettagli di pagamento. Roba che fa venire i brividi, perch√© ci ricorda che </span><strong>nulla √® davvero privato</strong><span style=\"font-weight: 400;\"> su queste piattaforme. OpenAI ha dovuto correre ai ripari, ma ha commesso un errore grave: non ha notificato subito il data breach a tutte le autorit√† europee, come richiesto dal GDPR. Questo ha pesato nella sanzione italiana del 2024.</span></p>\n<h5>üö® Samsung e il divieto interno: un caso significativo</h5>\n<p><span style=\"font-weight: 400;\">Ad aprile 2023, alcuni ingegneri di Samsung ‚Äì probabilmente in buona fede ‚Äì hanno caricato pezzi di codice sorgente su ChatGPT per farsi aiutare nel debug. Risultato? Quello stesso codice √® finito nei log del chatbot e potenzialmente potrebbe essere stato usato per addestrare modelli futuri. Immagina: un segreto industriale che finisce in un sistema terzo fuori dal tuo controllo. La reazione di Samsung? Un divieto netto: niente pi√π chatbot sulle reti aziendali e sui dispositivi interni. E non sono stati i soli: anche banche come JPMorgan e aziende come Apple hanno preso provvedimenti rigorosi simili. Queste casistiche evidenziano un rischio privacy ‚Äúindiretto‚Äù: non tanto la violazione dei dati personali, quanto la perdita di </span><strong>confidenzialit√† di dati aziendali</strong><span style=\"font-weight: 400;\"> (che spesso includono anche dati personali di clienti) quando si usano LLM senza cautele o pensiero critico.</span></p>\n<h5>üö® Zoom e l‚Äôaggiornamento delle policy: quando ‚Äúconsenso‚Äù diventa un concetto elastico</h5>\n<p><span style=\"font-weight: 400;\">Estate 2023: Zoom aggiorna i suoi termini di servizio e sembra voler usare audio, video e chat delle riunioni per addestrare le proprie IA. Scoppia il caso: utenti e media insorgono, e Zoom fa marcia indietro (almeno in parte). Ma la faccenda resta ambigua: perch√© se tu, come organizzatore della riunione, accetti certe funzionalit√† AI (come la trascrizione automatica), di fatto stai anche dando il consenso all‚Äôuso dei dati per il training. I partecipanti? Se non vogliono che le loro parole vengano usate, devono semplicemente‚Ä¶ non partecipare alla riunione. √à un po‚Äô come firmare un contratto senza possibilit√† di negoziare le clausole: o prendi tutto o niente.</span></p>\n<h2>Le strategie delle Big Tech: tra ‚Äúdata grabbing‚Äù e correzioni tardive</h2>\n<p><span style=\"font-weight: 400;\">Ora, fermiamoci un attimo. Perch√© le Big Tech fanno quello che fanno? √à semplice: i modelli generativi ‚Äì ChatGPT, Claude, Gemini, e compagnia ‚Äì </span><strong>hanno fame di dati</strong><span style=\"font-weight: 400;\">. E non di due spiccioli: servono trilioni di parole, milioni di immagini, video, registrazioni audio. Pi√π dati hai, pi√π il modello √® potente.</span></p>\n<p><span style=\"font-weight: 400;\">Il problema √® che per un po‚Äô le regole sono state ignorate. OpenAI, Google, Meta ‚Äì tutti hanno fatto scraping selvaggio del web: post, articoli, commenti, banche dati opache, perfino dati personali come email o numeri di telefono lasciati su forum dimenticati. E hanno usato questi dati senza chiedere nulla a nessuno. Quando le proteste sono iniziate ‚Äì autori, artisti, giornalisti, cittadini comuni ‚Äì le aziende hanno cominciato a fare un passo indietro (o quasi).</span></p>\n<p><span style=\"font-weight: 400;\">OpenAI ha smesso di elencare dettagli sui dataset usati per GPT-4, dopo averlo fatto per GPT-3. Perch√©? Dicono per ragioni di sicurezza e competizione, ma la verit√† √® che meno si dice, meno problemi si rischia.</span></p>\n<p><span style=\"font-weight: 400;\">Google, invece, ha aggiornato la sua privacy policy per dire chiaramente che usa ‚Äúdati pubblicamente disponibili‚Äù per addestrare l‚ÄôIA. Ma cosa significa ‚Äúpubblicamente disponibili‚Äù? Anche un post su un blog personale √® pubblico, ma non vuol dire che chi lo ha scritto voglia vederlo usato per addestrare un chatbot. √à un terreno scivoloso, e il rischio di cause legali √® concreto: nel 2023, ad esempio, ci sono state class action contro OpenAI e Meta per l‚Äôuso di contenuti protetti da copyright nei training set.</span></p>\n<p><span style=\"font-weight: 400;\">Poi ci sono le correzioni di rotta. OpenAI, dopo il caso italiano, ha introdotto un modulo per richiedere la cancellazione dei dati personali dai risultati di ChatGPT. Un passo avanti, certo. Ma resta una domanda: <strong>chi controlla davvero che questi dati vengano rimossi?</strong> E in quanti sanno che possono fare questa richiesta?</span></p>\n<p><span style=\"font-weight: 400;\">Intanto, le aziende stanno anche sperimentando nuove strategie: partnership con editori (ad esempio OpenAI con Associated Press), licenze con piattaforme come Shutterstock, e modelli ‚Äúbusiness‚Äù a pagamento che promettono pi√π privacy. <strong>√à come se la privacy stesse diventando un servizio premium</strong>: se paghi, ti proteggiamo i dati; se usi il servizio gratuito, sappi che i tuoi dati potrebbero servire a migliorare il modello, del resto, come ci ricorda Friedman, in economia ‚Äú<strong>non esistono pasti gratis</strong>‚Äù e quando stai utilizzando qualcosa di gratuito probabilmente il prodotto sei tu.</span></p>\n<h2>E noi? Cosa possiamo fare per proteggerci?</h2>\n<p><span style=\"font-weight: 400;\">A questo punto ci si potrebbe sentire un po‚Äô sopraffatti. Ma non √® tutto fuori dal nostro controllo. Ci sono cose concrete che possiamo fare per proteggerci, come utenti e come cittadini.</span></p>\n<ul>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><strong>Non condividere dati sensibili nelle chat AI</strong><span style=\"font-weight: 400;\">: sembra banale, ma spesso ci dimentichiamo che anche un messaggio apparentemente innocuo (‚ÄúMio figlio fa la terza media a Milano e ha problemi con la matematica‚Äù) contiene dati personali. Meglio evitare.</span><span style=\"font-weight: 400;\"><br><br></span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><strong>Controllare le impostazioni di privacy</strong><span style=\"font-weight: 400;\">: molti servizi, come ChatGPT, ora offrono opzioni per non salvare la cronologia o non contribuire al training. In alcuni casi sono nascoste. Usale. E, quando i servizi lo consentono, cancellare la cronologia o disattivare la memoria. </span><span style=\"font-weight: 400;\"><br><br></span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><strong>Leggere (almeno una volta) le informative privacy</strong><span style=\"font-weight: 400;\">: lo sappiamo, √® noioso. Ma almeno una volta proviamo a darci un‚Äôocchiata: ci sono spesso dettagli importanti. Atrettanto spesso per√≤ cambiano e quindi vanno rilette ogni tanto.</span><span style=\"font-weight: 400;\"><br><br></span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><strong>Esercitare i tuoi diritti</strong><span style=\"font-weight: 400;\">: puoi chiedere di accedere ai tuoi dati, di cancellarli, o di opporti al trattamento. √à un tuo diritto ‚Äì usalo.</span><span style=\"font-weight: 400;\"><br><br></span></li>\n<li style=\"font-weight: 400;\" aria-level=\"1\"><strong>Se sei un educatore o un genitore, parla di questi temi con i ragazzi</strong><span style=\"font-weight: 400;\">: sono loro i primi a usare queste tecnologie, spesso senza rendersene conto. Un po‚Äô di consapevolezza in pi√π pu√≤ fare la differenza.</span><span style=\"font-weight: 400;\"><br><br></span></li>\n</ul>\n<h2>In fondo, privacy e AI non sono nemici</h2>\n<p><span style=\"font-weight: 400;\">Lo so, la tentazione √® pensare che la privacy e l‚ÄôIA siano due cose in conflitto: o proteggi i tuoi dati o usi la tecnologia. Ma non deve per forza essere cos√¨. Possiamo (e dobbiamo) trovare un equilibrio: costruire AI potenti e utili, ma rispettose della nostra sfera privata, sopratutto etiche e non discriminatorie.</span></p>\n<p><span style=\"font-weight: 400;\">Le leggi ci sono ‚Äì il GDPR, l‚ÄôAI Act ‚Äì ma da sole non bastano. Servono aziende pi√π trasparenti, utenti pi√π consapevoli, e autorit√† pi√π reattive. <strong>√à una sfida collettiva</strong>.</span></p>\n<p><span style=\"font-weight: 400;\">Una cosa √® certa: pi√π conosciamo questi strumenti, pi√π possiamo usarli in modo intelligente, senza rinunciare ai nostri diritti. Non dobbiamo smettere di fare domande, di pretendere chiarezza, di chiedere ‚ÄúScusate, ma i miei dati dove vanno a finire?‚Äù. √à solo cos√¨ che l‚ÄôIA diventer√† davvero uno strumento al nostro servizio, e non il contrario.</span></p>\n<h2>Quanti dati sa di te l‚ÄôAI? Pi√π di quanto immagini (ma meno di quanto pensi)</h2>\n<p>√à una domanda che inizia a girare sempre pi√π spesso tra chi usa ChatGPT o altri assistenti intelligenti: <em>‚ÄúMa questa AI, quanto sa di me?‚Äù</em> Se la usi spesso, potresti avere l‚Äôimpressione che ti legga nel pensiero. A volte ti anticipa, altre volte ti d√† una risposta che suona... troppo su misura. La verit√†? Un LLM (modello linguistico) non ha una memoria infinita n√© spia la tua vita ‚Äì almeno, non nel modo in cui immagini. Ma pu√≤ <strong>dedurre molte cose da come gli parli</strong>, anche se non gliele hai dette esplicitamente. √à un po‚Äô come con un barista che ti vede tutti i giorni: anche se non ti sei mai presentato, sa che prendi il cappuccino con poco zucchero, che arrivi trafelato e che il luned√¨ sei pi√π silenzioso. Il barista poi ricorda ci√≤ che sente ed √® capace di collegarlo ad altre notizie o informazioni. L‚ÄôAI fa lo stesso, solo che lo fa in silenzio, e in modo statistico.</p>\n<h5>Esperimenti da fare in salotto</h5>\n<p>Vuoi testare quanto un chatbot AI ha imparato su di te? <span style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\">Prova questi piccoli esperimenti. Niente di tecnico, promesso. Prima cosa: chiedi all‚ÄôAI direttamente </span><em style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\">‚ÄúCosa sai di me?‚Äù</em><span style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\">. Nella maggior parte dei casi, se stai usando un modello chiuso come ChatGPT o Claude, ti risponder√† qualcosa tipo </span><em style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\">‚ÄúNon ho informazioni personali su di te‚Äù</em><span style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\">. </span><span style=\"font-weight: 400;\">I modelli chiusi come quelli di OpenAI o Anthropic sono </span><strong style=\"font-family: var(--editor-font-family); font-size: inherit;\">programmati per non fornire dati personali</strong><span style=\"font-weight: 400;\"> di individui privati.</span><span style=\"font-weight: 400;\"> </span><span style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\">Ma se sei nella </span><strong style=\"font-family: var(--editor-font-family); font-size: inherit;\">stessa chat</strong><span style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\"> in cui hai gi√† detto ‚ÄúMi chiamo Lucia e faccio l‚Äôinfermiera‚Äù, potresti scoprire che te lo ripete: ha </span><strong style=\"font-family: var(--editor-font-family); font-size: inherit;\">memoria contestuale</strong><span style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\">, cio√® ricorda quello che le hai detto poco fa. Vuoi spingerti oltre? Chiedile: </span><em style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\">‚ÄúChe tipo di personalit√† pensi io abbia?\", \"Puoi fare un profilo della mia personalit√†?‚Äù</em><span style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\"> oppure </span><em style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\">‚ÄúQuali argomenti tratto pi√π spesso con te?‚Äù</em><span style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\">. </span><span style=\"font-weight: 400;\">Questo invoglia l‚ÄôAI a sintetizzare i </span><strong style=\"font-family: var(--editor-font-family); font-size: inherit;\">tratti ricorrenti</strong><span style=\"font-weight: 400;\"> che hai mostrato. Potrebbe </span><span style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\">stupire con un piccolo ritratto basato su ci√≤ che hai scritto. Non √® una scheda FBI, ma una </span><strong style=\"font-family: var(--editor-font-family); font-size: inherit;\">fotografia probabilistica</strong><span style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\">. E se usi un servizio con memoria attiva (come la funzione ‚Äúistruzioni personalizzate‚Äù di OpenAI), puoi anche provare: </span><em style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\">‚ÄúQuali dettagli su di me stai usando?‚Äù</em><span style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\"> ‚Äì cos√¨ verifichi cosa si √® tenuta in tasca da altre conversazioni. Si potrebbe tentare anche qualche domanda investigativa inversa </span><strong style=\"font-family: var(--editor-font-family); font-size: inherit;\"> <i><span style=\"font-weight: 400;\">‚ÄúEsaminando come ti ho posto le domande finora, noti qualche errore o abitudine sbagliata che ho quando chiedo qualcosa?‚Äù, \"Puoi dirmi quali sono i tipi di aiuto o gli argomenti che ti ho chiesto pi√π spesso finora?‚Äù</span></i><span style=\"font-weight: 400;\">. Questo costringe l‚ÄôAI a ripensare alle tue interazioni e magari citare esempi di domande che hai fatto. </span></strong><span style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\">Potremmo indagare il cosidetto \"blind spot\" </span><strong style=\"font-family: var(--editor-font-family); font-size: inherit;\"><span style=\"font-weight: 400;\">chiedendo <i>‚ÄúBasandoti sulle nostre conversazioni, c‚Äô√® qualcosa di significativo che secondo te mi sfugge o tendo a ignorare?‚Äù. </i></span><span style=\"font-weight: 400;\">√à come chiedere un parere esterno sulle tue abitudini. </span></strong><span style=\"font-weight: 400;\">Questo non √® tanto un dato ‚Äúraccolto‚Äù, quanto una </span><span style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\">inferenza</span><strong style=\"font-family: var(--editor-font-family); font-size: inherit;\"><span style=\"font-weight: 400;\">: l‚ÄôAI rielabora i dati delle tue interazioni per darti un feedback su di te e questo ti fa capire come il modello analizza e profila in qualche modo il tuo comportamento.</span></strong></p>\n<p>Teniamo bene a mente che sono sempre tutte <strong>risposte di tipo probabilistico </strong>(senza intelligenza) e quindi vanno prese con leggerezza e nella consapevolezza che <strong>possono essere errate.</strong></p>\n<h5>Un dossier invisibile? No, ma meglio restare svegli</h5>\n<p>C‚Äô√® per√≤ un‚Äôaltra faccia della medaglia. Anche se il modello stesso non ti pu√≤ elencare i dati raccolti (non √® progettato per questo), <strong>la piattaforma che lo gestisce s√¨</strong>. Dietro le quinte, i server registrano la cronologia delle chat, l‚Äôorario, il tipo di dispositivo usato, la posizione approssimativa. Principalmente per motivi tecnici e legali. Il problema √® che tu, utente comune, <strong>non puoi vedere tutto questo in chiaro</strong>: non c‚Äô√® un pulsante ‚Äú<em>Scarica ci√≤ che sai di me</em>‚Äù o ‚Äú<em>Cancella tutto e dimenticati di me</em>‚Äù accessibile direttamente dall‚ÄôAI. Vuoi sapere davvero quali dati hanno memorizzato? Devi fare una richiesta formale al provider ‚Äì ad esempio tramite i moduli privacy di OpenAI ‚Äì oppure disattivare le funzioni di cronologia e memoria, e purtroppo una vera cancellazione non sempre √® possibile, ancor pi√π oggi e in futuro dove i sistemi sono e stanno diventando sempre pi√π Agenti, inevitabilmente condividono sempre pi√π dati con sistemi terzi (anche a noi ignoti). Insomma, l‚Äô<strong>AI non ha una sfera di cristallo</strong>, ma se la alimenti a lungo e le lasci indizi... <strong>impara a riconoscerti</strong>. Con misura e consapevolezza, pu√≤ essere uno specchio utile e potrebbe diventare anche uno strumento introspettivo interessante. Ma non dimenticare: ogni volta che parli con un sistema AI, <strong>non sei mai del tutto solo</strong>.</p>\n<p>Un consiglio guida potrebbe essere ‚Äú<strong>mai condividere cose che normalmente non condivideresti in pubblico</strong>‚Äù.</p>\n<hr>\n<p class=\"align-center\">Questo post √® parte della rubrica <strong><a href=\"https://pianetararo.org/traiettorie/\">TrAIettorie</a></strong> di cui potete trovare l'indice completo <a href=\"https://pianetararo.org/tags/traiettorie/\">qui</a>.</p>",
            "image": "https://pianetararo.org/media/posts/21/g9ddxhg9ddxhg9dd.jfif",
            "author": {
                "name": "Pianetararo Associazione Culturale"
            },
            "tags": [
                   "TRAIETTORIE"
            ],
            "date_published": "2025-04-13T20:49:00+02:00",
            "date_modified": "2025-06-15T14:08:00+02:00"
        },
        {
            "id": "https://pianetararo.org/traiettorie-2/",
            "url": "https://pianetararo.org/traiettorie-2/",
            "title": "TrAIettorie",
            "summary": "üìå √à online TRAIETTORIE, la nuova sezione di pianetararo¬†dedicata a esplorare l'educazione critica e consapevole nell'universo digitale. Insegnanti, educatori, famiglie e curiosi del digitale troveranno riflessioni, approfondimenti e strumenti pratici per comprendere come le tecnologie digitali e l'intelligenza artificiale stanno cambiando il nostro modo di&hellip;",
            "content_html": "<p>üìå √à online <strong><a href=\"https://pianetararo.org/traiettorie/\">TRAIETTORIE</a></strong>, la nuova sezione di <strong>pianetararo</strong>¬†dedicata a esplorare l'educazione critica e consapevole nell'universo digitale. Insegnanti, educatori, famiglie e curiosi del digitale troveranno <span style=\"text-decoration: underline;\"><span style=\"color: #000000; text-decoration: underline;\">riflessioni</span></span>, approfondimenti e strumenti pratici per comprendere come le tecnologie digitali e l'intelligenza artificiale stanno cambiando il nostro modo di apprendere e comunicare. Non ci limitiamo a raccontare l'innovazione, ma ne analizziamo rischi, opportunit√† e implicazioni educative ed etiche. Un viaggio aperto e dinamico, fatto di <span style=\"text-decoration: underline;\">domande</span>, confronti e <span style=\"text-decoration: underline;\">laboratori </span>per costruire insieme una <strong>cultura digitale consapevole e responsabile</strong>. Seguici, iscriviti alla nostra <strong>newsletter </strong>e contattaci per proposte educative personalizzate!</p>",
            "image": "https://pianetararo.org/media/posts/20/aditya-vyas-jey6eFHP4kA-unsplash.jpg",
            "author": {
                "name": "Pianetararo Associazione Culturale"
            },
            "tags": [
            ],
            "date_published": "2025-04-13T20:02:00+02:00",
            "date_modified": "2025-06-13T12:00:18+02:00"
        },
        {
            "id": "https://pianetararo.org/frammenti-25-ora-disponibile-su-lulu-2/",
            "url": "https://pianetararo.org/frammenti-25-ora-disponibile-su-lulu-2/",
            "title": "FRAMMENTI #25 disponibile anche su Amazon",
            "summary": "<p>Da poco disponibile <strong>FRAMMENTI #25</strong> anche su Amazon.it in versione pi√π compatta.</p>\n",
            "content_html": "<p>Da poco disponibile <strong>FRAMMENTI #25</strong> anche su Amazon.it in versione pi√π compatta.</p>\n\n<h2><strong>üìì Disponibile l'edizione in formato brossura¬†</strong></h2>\n<p>¬†</p>\n<figure class=\"post__image post__image--center\"><img loading=\"lazy\"  src=\"https://pianetararo.org/media/posts/14/frammenti.brosssura.PNG\" alt=\"\" width=\"363\" height=\"416\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://pianetararo.org/media/posts/14/responsive/frammenti.brosssura-xs.PNG 640w ,https://pianetararo.org/media/posts/14/responsive/frammenti.brosssura-sm.PNG 768w ,https://pianetararo.org/media/posts/14/responsive/frammenti.brosssura-md.PNG 1024w ,https://pianetararo.org/media/posts/14/responsive/frammenti.brosssura-lg.PNG 1366w ,https://pianetararo.org/media/posts/14/responsive/frammenti.brosssura-xl.PNG 1600w ,https://pianetararo.org/media/posts/14/responsive/frammenti.brosssura-2xl.PNG 1920w\"></figure>\n<p>Se preferite la <strong>versione rilegata in brossura, </strong>ora potete acquistarla! Questa edizione, manterr√† tutta la qualit√† dei contenuti di <strong>FRAMMENTI #25</strong>, con una rilegatura pi√π tradizionale.</p>\n<p><a href=\"https://www.amazon.it/FRAMMENTI-25-Pamela-Benedetti/dp/B0DPG4L2NN/ref=sr_1_2?__mk_it_IT=%C3%85M%C3%85%C5%BD%C3%95%C3%91&amp;crid=KYMAD9XVXXIA&amp;dib=eyJ2IjoiMSJ9.t9wRYiv452AhlPvrqf6An_6nPKQggLbmWWjrdjbe6CfWp9YvubMoS0URzm26falnV-JsGPST5KLvCz_BZ-zZHBOhoBINrpbfs2ZEC0LuGDQ3hCLoe0i6ATIGY1esXskQ1h5U3_FN0-BB1AWPlX8QHlCVDOQTSKd4FxIzwcoyx0e5kcNp7nHjoiXTBQwxub5p_Jt-xavqFdks07LV9BC9c_yePzrzo_hOQILXWWVKJ7Y.rdi9V1NTcjffx1NUoG5YhXEB6RO2verJeQ1GV1yQJl8&amp;dib_tag=se&amp;keywords=frammenti+25&amp;nsdOptOutParam=true&amp;qid=1734382345&amp;sprefix=frammenti25%2Caps%2C107&amp;sr=8-2\" target=\"_blank\" rel=\"noopener noreferrer\">Acquista su Amazon</a></p>\n<p>¬†</p>\n<p><a href=\"https://www.lulu.com/it/shop/erica-menozzi-and-fabrizio-lugli-and-pamela-benedetti/frammenti-25/paperback/product-rm8ppj5.html?q=frammenti%2325&amp;page=1&amp;pageSize=4\"></a><strong><a href=\"https://pianetararo.org/frammenti25intro/\">Qui troverai maggiori informazioni su FRAMMENTI #25</a></strong></p>",
            "image": "https://pianetararo.org/media/posts/14/frammenti.brosssura-2.PNG",
            "author": {
                "name": "Pianetararo Associazione Culturale"
            },
            "tags": [
                   "FRAMMENTI"
            ],
            "date_published": "2025-01-01T13:14:24+01:00",
            "date_modified": "2025-06-10T08:56:36+02:00"
        },
        {
            "id": "https://pianetararo.org/frammenti-25-ora-disponibile-su-lulu/",
            "url": "https://pianetararo.org/frammenti-25-ora-disponibile-su-lulu/",
            "title": "FRAMMENTI #25 Ora Disponibile su Lulu",
            "summary": "<p>Siamo entusiasti di annunciarvi che <strong>FRAMMENTI #25</strong> √® finalmente disponibile per l'acquisto online su <strong>Lulu</strong>! La prima edizione √® arrivata in una versione <strong>rilegata a spirale</strong>, perfetta per chi ama combinare funzionalit√† ed estetica.</p>\n",
            "content_html": "<p>Siamo entusiasti di annunciarvi che <strong>FRAMMENTI #25</strong> √® finalmente disponibile per l'acquisto online su <strong>Lulu</strong>! La prima edizione √® arrivata in una versione <strong>rilegata a spirale</strong>, perfetta per chi ama combinare funzionalit√† ed estetica.</p>\n\n<h3><strong>Perch√© scegliere la versione a spirale?</strong></h3>\n<p>La rilegatura a spirale offre vantaggi, soprattutto per chi desidera un'esperienza di scrittura pratica e piacevole. La versione a spirale permette infatti di aprire completamente il taccuino a 360¬∞, lasciando le pagine perfettamente piatte e rendendo pi√π facile annotare, disegnare e prendere appunti senza il fastidio di dover tenere le pagine ferme. Inoltre vi da l'opportunit√† di estrarre o strappare le pagine :-) e avere pieno controllo dello spazio su ogni angolo delle pagine. Insomma, √® la scelta perfetta per chi ama la creativit√† senza limiti.</p>\n<figure class=\"post__image post__image--center\"><img loading=\"lazy\"  src=\"https://pianetararo.org/media/posts/11/PXL_20241130_062812942.jpg\" alt=\"\" width=\"498\" height=\"280\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://pianetararo.org/media/posts/11/responsive/PXL_20241130_062812942-xs.jpg 640w ,https://pianetararo.org/media/posts/11/responsive/PXL_20241130_062812942-sm.jpg 768w ,https://pianetararo.org/media/posts/11/responsive/PXL_20241130_062812942-md.jpg 1024w ,https://pianetararo.org/media/posts/11/responsive/PXL_20241130_062812942-lg.jpg 1366w ,https://pianetararo.org/media/posts/11/responsive/PXL_20241130_062812942-xl.jpg 1600w ,https://pianetararo.org/media/posts/11/responsive/PXL_20241130_062812942-2xl.jpg 1920w\"></figure>\n<h3><strong>Spedizione e tempistiche...</strong></h3>\n<p>I tempi di spedizione che Lulu stimer√† in fase di ordine potrebbero risultare piuttosto lunghi, forse perch√® si tratta di una previsione con partenza dagli USA. <span style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\">Abbiamo sperimentato noi stessi un paio di ordini di prova e, nella realt√†, i tempi sono risultati molto diversi e decisamente pi√π rapidi rispetto alle stime (in genere meno della met√† della previsione) perch√® ci √® sempre stato assegnato uno stabilimento situato in Francia. Confidiamo che anche voi possiate sperimentare un esperienza di consegna facile e veloce.¬†¬†</span></p>\n<p><a href=\"https://www.lulu.com/it/shop/erica-menozzi-and-fabrizio-lugli-and-pamela-benedetti/frammenti-25/paperback/product-rm8ppj5.html?q=frammenti%2325&amp;page=1&amp;pageSize=4\"><strong>Acquista ora la tua copia su Lulu</strong></a></p>\n<p>Grazie a tutti voi che avete atteso con pazienza. Siamo certi che <strong>FRAMMENTI #25</strong> diventer√† un compagno piacevole per il vostro anno di scoperte e ispirazioni!</p>\n<p><a href=\"https://www.lulu.com/it/shop/erica-menozzi-and-fabrizio-lugli-and-pamela-benedetti/frammenti-25/paperback/product-rm8ppj5.html?q=frammenti%2325&amp;page=1&amp;pageSize=4\"></a><strong><a href=\"https://pianetararo.org/frammenti25intro/\">Qui troverai maggiori informazioni su FRAMMENTI #25</a></strong></p>",
            "image": "https://pianetararo.org/media/posts/11/PXL_20241130_063133590.jpg",
            "author": {
                "name": "Pianetararo Associazione Culturale"
            },
            "tags": [
                   "FRAMMENTI"
            ],
            "date_published": "2024-11-30T07:32:52+01:00",
            "date_modified": "2025-06-10T08:56:44+02:00"
        }
    ]
}
