<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <title>pianetararo</title>
    <link href="https://pianetararo.org/feed.xml" rel="self" />
    <link href="https://pianetararo.org" />
    <updated>2025-06-11T13:42:00+02:00</updated>
    <author>
        <name>Pianetararo Associazione Culturale</name>
    </author>
    <id>https://pianetararo.org</id>

    <entry>
        <title>Come funzionano le AI che ci scrivono</title>
        <author>
            <name>Pianetararo Associazione Culturale</name>
        </author>
        <link href="https://pianetararo.org/come-funzionano-le-ia-che-ci-scrivono/"/>
        <id>https://pianetararo.org/come-funzionano-le-ia-che-ci-scrivono/</id>
        <media:content url="https://pianetararo.org/media/posts/22/penna-formula.png" medium="image" />
            <category term="TRAIETTORIE"/>

        <updated>2025-06-01T20:00:00+02:00</updated>
            <summary>
                <![CDATA[
                        <img src="https://pianetararo.org/media/posts/22/penna-formula.png" alt="" />
                    Interagire con un chatbot â€“ che sia ChatGPT, Gemini, Claude o uno dei tanti assistenti virtuali â€“ ormai Ã¨ quasi normale, anzi sta rimpiazzando velocemente la classica ricerca sul web. Chiediamo a unâ€™AI di cercare qualcosa, scriverci il riassunto di un testo, una poesia in&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                    <p><img src="https://pianetararo.org/media/posts/22/penna-formula.png" class="type:primaryImage" alt="" /></p>
                <h1>Â </h1>
<p><span style="font-weight: 400;">Interagire con un chatbot â€“ che sia ChatGPT, Gemini, Claude o uno dei tanti assistenti virtuali â€“ ormai Ã¨ quasi normale, anzi sta rimpiazzando velocemente la classica ricerca sul web. Chiediamo a unâ€™</span>AI<span style="font-weight: 400;"> di cercare qualcosa, scriverci il riassunto di un testo, una poesia in rima o un consiglio per la cena, e quella risponde in italiano fluente e creativo. A volte sembra di parlare con un piccolo scrittore artificiale dalla fantasia infinita. </span><strong>Ma come fa, davvero, un modello linguistico a generare queste risposte?</strong><span style="font-weight: 400;"> Sta </span><strong>pensando</strong><span style="font-weight: 400;"> e </span><i><span style="font-weight: 400;">capendo</span></i><span style="font-weight: 400;"> la domanda come farebbe una persona? Risposta veloce: No. E capire </span><i><span style="font-weight: 400;">come funziona sul serio</span></i><span style="font-weight: 400;"> un LLM â€“ acronimo di </span>Large Language Model<span style="font-weight: 400;">, ovvero modello linguistico di grandi dimensioni â€“ Ã¨ importante per sfatare alcuni miti e usarlo al meglio.Â </span></p>
<p><span style="font-weight: 400;">Questo articolo proverÃ  a fare chiarezza, semplificando, su cosa avviene </span><i><span style="font-weight: 400;">dietro le quinte</span></i><span style="font-weight: 400;"> quando una di queste IA elabora una domanda e produce una risposta. Con esempi semplici (anche fiabeschi!) vedremo passo passo </span><strong>come Ã¨ fatto internamente un LLM, come funziona e come genera testo</strong><span style="font-weight: 400;">, toccando concetti chiave e termini come </span><i><span style="font-weight: 400;">tokenizzazione</span></i><span style="font-weight: 400;">, </span><i><span style="font-weight: 400;">embedding</span></i><span style="font-weight: 400;"> e </span><i><span style="font-weight: 400;">trasformatori</span></i><span style="font-weight: 400;">. Scopriremo inoltre perchÃ© un LLM, per quanto sofisticato, </span><strong>non Ã¨ una mente cosciente</strong><span style="font-weight: 400;"> nÃ© infallibile, e come conoscere la sua struttura ci aiuta a usarlo in modo piÃ¹ consapevole, apprezzandone le potenzialitÃ  senza dimenticarne i limiti.Â </span></p>
<h2>Come funziona un LLM: dallâ€™input alla risposta</h2>
<p><span style="font-weight: 400;">Immaginiamo di chiedere a un modello come ChatGPT qualcosa di creativo. Ad esempio: </span><i><span style="font-weight: 400;">â€œCâ€™era una volta un regno incantato dove viveva un giovane drago. Un giornoâ€¦â€</span></i><span style="font-weight: 400;"> e gli domandiamo di continuare la storia. In pochi secondi lâ€™LLM produce magari un racconto avvincente, pieno di avventure. </span><strong>Cosa Ã¨ successo, in termini semplici, dentro il â€œcervelloâ€ artificiale del modello?</strong><span style="font-weight: 400;"> Ecco le fasi principali del processo:</span></p>
<ol>
<li style="font-weight: 400;" aria-level="1"><strong>Comprensione del prompt (input):</strong><span style="font-weight: 400;"> il testo della nostra richiesta viene prima </span><i><span style="font-weight: 400;">preparato</span></i><span style="font-weight: 400;"> in modo che il modello possa lavorarci. In pratica lâ€™LLM spezzetta la frase in unitÃ  piÃ¹ piccole chiamate </span><strong>token</strong><span style="font-weight: 400;"> (parole o frammenti di parole) e le converte in numeri. Ãˆ un poâ€™ come tradurre la frase in un linguaggio matematico che la macchina possa elaborare.</span><span style="font-weight: 400;"><br><br></span></li>
<li style="font-weight: 400;" aria-level="1"><strong>Analisi del contesto:</strong><span style="font-weight: 400;"> a questo punto i token numerici vengono passati attraverso la rete neurale del modello. Lâ€™LLM </span><i><span style="font-weight: 400;">esamina il contesto</span></i><span style="font-weight: 400;"> della frase e, sulla base di ciÃ² che â€œha imparatoâ€ da miliardi di parole di training, stima quale potrebbe essere la parola (o token) piÃ¹ probabile dopo quelle giÃ  date. In questa fase interviene il </span><strong>meccanismo di attenzione</strong><span style="font-weight: 400;"> tipico dei trasformatori: il modello valuta in parallelo tutti i termini presenti nel prompt e assegna piÃ¹ peso a quelli piÃ¹ rilevanti, ignorando quelli meno significativi. In altre parole, â€œcapisceâ€ quali concetti chiave sono emersi finora (es. </span><i><span style="font-weight: 400;">regno incantato</span></i><span style="font-weight: 400;">, </span><i><span style="font-weight: 400;">giovane drago</span></i><span style="font-weight: 400;">) e li usa per predire come la storia potrebbe proseguire.</span><span style="font-weight: 400;"><br><br></span></li>
<li style="font-weight: 400;" aria-level="1"><strong>Previsione della prossima parola:</strong><span style="font-weight: 400;"> in base allâ€™analisi, lâ€™LLM produce una sorta di elenco di possibili continuazioni, ciascuna con una certa </span><strong>probabilitÃ  statistica</strong><span style="font-weight: 400;">. Ad esempio, dopo la frase </span><i><span style="font-weight: 400;">â€œCâ€™era una volta un giovane dragoâ€</span></i><span style="font-weight: 400;"> il modello potrebbe calcolare che il token </span><i><span style="font-weight: 400;">â€œcheâ€</span></i><span style="font-weight: 400;"> ha il 40% di probabilitÃ  di venire dopo, </span><i><span style="font-weight: 400;">â€œdragoneâ€</span></i><span style="font-weight: 400;"> il 15%, </span><i><span style="font-weight: 400;">â€œdiâ€</span></i><span style="font-weight: 400;"> il 10%, </span><i><span style="font-weight: 400;">â€œprincipeâ€</span></i><span style="font-weight: 400;"> il 5%, e cosÃ¬ via â€“ a seconda di ciÃ² che ha appreso dai testi durante lâ€™addestramento. In effetti, lâ€™LLM non inventa dal nulla la continuazione: sta scegliendo la parola successiva basandosi sui </span><strong>pattern linguistici</strong><span style="font-weight: 400;"> che ha giÃ  visto moltissime volte.</span><span style="font-weight: 400;"><br><br></span></li>
<li style="font-weight: 400;" aria-level="1"><strong>Generazione iterativa della risposta:</strong><span style="font-weight: 400;"> una volta ottenute le probabilitÃ , il modello </span><strong>sceglie un token</strong><span style="font-weight: 400;"> come prossimo elemento della risposta. Spesso seleziona quello con la probabilitÃ  piÃ¹ alta, ma puÃ² introdurre un poâ€™ di casualitÃ  per rendere il testo meno prevedibile. Immaginiamo che scelga ad esempio </span><i><span style="font-weight: 400;">â€œcheâ€</span></i><span style="font-weight: 400;">. A questo punto il token </span><i><span style="font-weight: 400;">â€œcheâ€</span></i><span style="font-weight: 400;"> viene aggiunto alla frase generata e il modello </span><strong>ripete</strong><span style="font-weight: 400;"> nuovamente il passo 2: rianalizza tutto il contesto aggiornato (</span><i><span style="font-weight: 400;">â€œCâ€™era una volta un giovane drago cheâ€</span></i><span style="font-weight: 400;">) e calcola il token successivo. Poi di nuovo e cosÃ¬ via, parola dopo parola, </span><strong>fino a completare la frase o il paragrafo</strong><span style="font-weight: 400;"> richiesto. Questo processo a catena continua finchÃ© lâ€™LLM produce un segnale di </span><strong>fine risposta</strong><span style="font-weight: 400;"> (ad esempio un token speciale di stop) oppure finchÃ© raggiunge un limite di lunghezza prestabilito.</span><span style="font-weight: 400;"><br><br></span></li>
</ol>
<p><span style="font-weight: 400;">Possiamo paragonare il tutto a </span><strong>un super-autocompletamento</strong><span style="font-weight: 400;"> intelligente: come quando il telefono ci suggerisce le parole mentre digitiamo un messaggio, ma in questo caso con una potenza e una base di conoscenza immensamente piÃ¹ grandi. Lâ€™LLM, addestrato su innumerevoli esempi di frasi, </span><i><span style="font-weight: 400;">prevede</span></i><span style="font-weight: 400;"> di volta in volta il pezzo mancante successivo, cucendo insieme una risposta frase dopo frase.</span></p>
<blockquote>
<h5>ğŸ” Token ed embedding: lâ€™alfabeto segreto</h5>
<p><strong><i><br></i></strong><span style="font-weight: 400;">Un computer non â€œcomprendeâ€ realmente le parole testuali: deve rappresentarle con dei numeri. La </span><strong>tokenizzazione</strong><span style="font-weight: 400;"> Ã¨ il procedimento che converte il testo in piccoli segmenti (token) che possono essere elaborati dal modello. Spesso i token corrispondono a parole intere, ma possono anche essere sillabe o addirittura singole lettere nei casi complessi. Ad ogni token lâ€™LLM associa poi un </span><strong>embedding</strong><span style="font-weight: 400;">, ovvero un </span><strong>vettore di numeri</strong><span style="font-weight: 400;"> (di solito decine o centinaia di valori) che rappresenta quella parola in forma matematica allâ€™interno dello spazio â€œmentaleâ€ del modello. Lâ€™idea Ã¨ che parole con significato o uso simile avranno vettori (embedding) </span><i><span style="font-weight: 400;">simili</span></i><span style="font-weight: 400;"> tra loro. Ad esempio, in inglese </span><i><span style="font-weight: 400;">â€œseaâ€</span></i><span style="font-weight: 400;"> e </span><i><span style="font-weight: 400;">â€œoceanâ€</span></i><span style="font-weight: 400;"> (cioÃ¨ </span><i><span style="font-weight: 400;">mare</span></i><span style="font-weight: 400;"> e </span><i><span style="font-weight: 400;">oceano</span></i><span style="font-weight: 400;">) risultano molto vicini (perchÃ© simili) nello spazio vettoriale degli embedding â€“ segno che il modello li considera concetti affini. In pratica, lâ€™embedding Ã¨ come unâ€™impronta numerica che cattura il senso di un token: Ã¨ grazie a queste rappresentazioni che lâ€™LLM puÃ² â€œragionareâ€ sulle parole in ingresso e trovare connessioni tra termini correlati.</span></p>
</blockquote>
<h2>Dentro la scatola nera: comâ€™Ã¨ fatto (e addestrato) un LLM</h2>
<p><span style="font-weight: 400;">Abbiamo visto a grandi linee </span><i><span style="font-weight: 400;">come</span></i><span style="font-weight: 400;"> un LLM genera testo. Ma comâ€™Ã¨ strutturato internamente questo â€œscrittore automaticoâ€? La risposta breve: Ã¨ una </span><strong>rete neurale</strong><span style="font-weight: 400;"> enorme, con miliardi di connessioni, addestrata su </span><strong>quantitÃ  mastodontiche di dati testuali</strong><span style="font-weight: 400;">. Due ingredienti, </span><i><span style="font-weight: 400;">scala</span></i><span style="font-weight: 400;"> e </span><i><span style="font-weight: 400;">quantitÃ </span></i><span style="font-weight: 400;">, sono stati fondamentali per il salto di qualitÃ  di questi modelli negli ultimi anni.</span></p>
<ul>
<li style="font-weight: 400;" aria-level="1"><strong>Dati in abbondanza (token):</strong><span style="font-weight: 400;"> i Large Language Model vengono </span><i><span style="font-weight: 400;">pre-addestrati</span></i><span style="font-weight: 400;"> leggendo praticamente tutto quello che trovano. Documenti pubblici, libri, articoli, pagine web, conversazioni di forum â€“ un vero tesoro linguistico. Il modello â€œdigerisceâ€ questo corpus immenso imparando, tramite un lungo processo di ottimizzazione, a predire la parola successiva in ogni frase. Ad esempio, il modello </span>GPT-3<span style="font-weight: 400;"> di OpenAI (sviluppato nel 2020) Ã¨ stato addestrato usando circa </span>300 miliardi di token, che corrispondono a circa 45â€“60 TB di dati testuali<strong>Â </strong>(sui modelli successivi non si hanno informazioni ma si ipotizza tra 1 e 5 trilioni di token)<span style="font-weight: 400;">. Durante il training, lâ€™LLM macina questi testi miliardi di volte, aggiustando gradualmente i propri parametri per migliorare la capacitÃ  di indovinare le parole seguenti. </span>Un token puÃ² essere una parola intera, una radice (es. <em data-start="472" data-end="479">scriv</em>), una sillaba, o persino una singola lettera o segno di punteggiatura. Tutto dipende dal metodo di tokenizzazione scelto. La frase â€œ<em>Ciao, come stai?</em>â€ potrebbe diventare semplicisticamenteÂ  â†’ <code data-start="666" data-end="702">["Ciao", ",", "come", "stai", "?"]</code> â†’ <strong data-start="705" data-end="716">5 token</strong>. Ma i metodi sono i piÃ¹ disparati. La stessa frase ChatGPT la "<em><a href="https://platform.openai.com/tokenizer">tokenizza</a></em>" ancora piÃ¹ finemente: <figure class="post__image"><img loading="lazy"  src="https://pianetararo.org/media/posts/22/token-Screenshot-2025-06-11-121527.png" alt="" width="398" height="367" sizes="(max-width: 1920px) 100vw, 1920px" srcset="https://pianetararo.org/media/posts/22/responsive/token-Screenshot-2025-06-11-121527-xs.png 640w ,https://pianetararo.org/media/posts/22/responsive/token-Screenshot-2025-06-11-121527-sm.png 768w ,https://pianetararo.org/media/posts/22/responsive/token-Screenshot-2025-06-11-121527-md.png 1024w ,https://pianetararo.org/media/posts/22/responsive/token-Screenshot-2025-06-11-121527-lg.png 1366w ,https://pianetararo.org/media/posts/22/responsive/token-Screenshot-2025-06-11-121527-xl.png 1600w ,https://pianetararo.org/media/posts/22/responsive/token-Screenshot-2025-06-11-121527-2xl.png 1920w"></figure>Â </li>
</ul>
<p>Â </p>
<ul>
<li style="font-weight: 400;" aria-level="1"><strong>Tanti parametri (il â€œcervelloâ€ della rete):</strong><span style="font-weight: 400;"> se i token sono i pezzi di linguaggio, i parametri sono le <strong data-start="1145" data-end="1168">connessioni apprese</strong> durante lâ€™addestramento. I parametri di un modello sono i coefficienti numerici (pesi) che collegano i neuroni artificiali al suo interno. Ogni parametro Ã¨ come una manopola o un interruttore che il modello puÃ² regolare mentre impara. Quando il modello Ã¨ addestrato, queste â€œmanopoleâ€ restano fisse e determinano come lâ€™IA risponde. PiÃ¹ parametri ci sono, piÃ¹ </span><i><span style="font-weight: 400;">capacitÃ  espressiva</span></i><span style="font-weight: 400;"> ha la rete neurale â€“ in teoria â€“ per cogliere sfumature e pattern del linguaggio. I moderni LLM sono giganteschi: GPT-3, ad esempio, ha </span><strong>175 miliardi di parametri</strong><span style="font-weight: 400;">. Per dare unâ€™idea, il suo predecessore GPT-2 ne aveva â€œsoloâ€ 1,5 miliardi. Questa crescita esponenziale ha permesso al modello di </span><strong>immagazzinare conoscenza linguistica</strong><span style="font-weight: 400;"> molto piÃ¹ approfondita (anche se non organizzata come una conoscenza umana, ovviamente). PiÃ¹ neuroni e connessioni significano che il modello puÃ² rappresentare concetti molto complessi e variegati. Naturalmente addestrare modelli del genere richiede risorse computazionali enormi (supercomputer con migliaia di GPU che macinano dati per settimane), ma il risultato Ã¨ unâ€™IA capace di generare testi straordinariamente coerenti.</span></li>
</ul>
<p data-start="1909" data-end="1965">Immaginiamo che un LLM sia uno <strong data-start="1937" data-end="1964">chef che scrive ricette</strong>:</p>
<ul data-start="1967" data-end="2199">
<li data-start="1967" data-end="2049">
<p data-start="1969" data-end="2049">I <strong data-start="1971" data-end="1980">token</strong> sono gli <strong data-start="1990" data-end="2005">ingredienti</strong> che lo chef usa (le parole da combinare).</p>
</li>
<li data-start="2050" data-end="2199">
<p data-start="2052" data-end="2199">I <strong data-start="2054" data-end="2067">parametri</strong> sono le <strong data-start="2076" data-end="2101">esperienze accumulate</strong>, le prove e gli errori che gli hanno insegnato a cucinare bene (cioÃ¨ a generare testo sensato).</p>
</li>
</ul>
<p data-start="2201" data-end="2300">PiÃ¹ parametri = uno chef piÃ¹ esperto.<br data-start="2238" data-end="2241">PiÃ¹ token = piÃ¹ ingredienti con cui preparare nuovi piatti.</p>
<p><span style="font-weight: 400;">A dare veramente il via a questa nuova generazione di IA linguistiche Ã¨ stata perÃ² una </span><strong>svolta architetturale</strong><span style="font-weight: 400;">. Fino a qualche anno fa, i modelli di elaborazione del linguaggio (come i traduttori automatici o i vecchi chatbot) si basavano in gran parte su reti neurali ricorrenti o sequenziali, che leggevano il testo parola per parola in ordine. Nel </span><strong>2017</strong><span style="font-weight: 400;">, un team di ricercatori di Google ha introdotto un modello diverso, chiamato </span><strong>Transformer</strong><span style="font-weight: 400;"> (trasformatore), descrivendolo in un celebre paper scientifico dal titolo </span><i><span style="font-weight: 400;">â€œAttention Is All You Needâ€</span></i><span style="font-weight: 400;">. Questa architettura ha rivoluzionato il campo perchÃ© </span><strong>analizza una sequenza di testo in parallelo anzichÃ© in sequenza</strong><span style="font-weight: 400;">, usando un meccanismo di </span><strong>self-attention</strong><span style="font-weight: 400;"> (auto-attenzione) che permette al modello di </span><i><span style="font-weight: 400;">concentrarsi</span></i><span style="font-weight: 400;"> sui punti importanti di una frase ignorandone i dettagli meno rilevanti. In pratica il trasformatore guarda allâ€™intera frase (o anche interi paragrafi) tutta in una volta, e per ogni parola capisce quali altre parole del contesto sono piÃ¹ utili per interpretarla. Ãˆ un poâ€™ quello che facciamo noi leggendo: se diciamo â€œ</span><strong>il giovane drago</strong><span style="font-weight: 400;"> imparÃ² a volareâ€, il nostro cervello collega </span><i><span style="font-weight: 400;">drago</span></i><span style="font-weight: 400;"> con </span><i><span style="font-weight: 400;">volare</span></i><span style="font-weight: 400;"> e non dÃ  peso a parole come </span><i><span style="font-weight: 400;">il</span></i><span style="font-weight: 400;"> o </span><i><span style="font-weight: 400;">a</span></i><span style="font-weight: 400;">. Il </span><strong>Transformer</strong><span style="font-weight: 400;"> permette allâ€™LLM di fare lo stesso tipo di collegamenti in maniera efficiente e accurata.</span></p>
<p><span style="font-weight: 400;">Questa innovazione ha reso possibili modelli con contesti molto ampi (capaci di â€œricordareâ€ e tenere in considerazione molte frasi precedenti) e con output di qualitÃ  molto piÃ¹ alta. Non sorprende che tutti i principali LLM odierni â€“ da GPT-3 e GPT-4 di OpenAI ai modelli di Google, Meta, Anthropic ecc. â€“ siano basati su architettura transformer. Per chi volesse vedere con i propri occhi come funziona un trasformatore, il </span><strong>Financial Times</strong><span style="font-weight: 400;"> ha pubblicato un bellissimo </span><strong>articolo interattivo</strong><span style="font-weight: 400;"> che illustra passo passo questi meccanismi. Scorrendo quella pagina web speciale, Ã¨ possibile visualizzare come un LLM codifica le parole, come lâ€™attenzione evidenzia certe parole chiave, e persino come possono emergere fenomeni come le </span><i><span style="font-weight: 400;">allucinazioni</span></i><span style="font-weight: 400;"> durante la generazione di testo. Ãˆ un ottimo complemento visuale a quanto stiamo raccontando qui.</span></p>
<h2>LLM â‰  intelligenza umana: miti e realtÃ </h2>
<p><span style="font-weight: 400;">Dopo tutto quello che abbiamo visto, potrebbe sorgere spontanea una domanda: </span><i><span style="font-weight: 400;">ma dunque questi LLM sono davvero â€œintelligentiâ€?</span></i><span style="font-weight: 400;"> Dipende da cosa intendiamo per intelligente. Certo, </span><strong>sanno generare testo di senso compiuto</strong><span style="font-weight: 400;">, usare un lessico ricco, perfino imitare stili letterari. Tuttavia, </span><strong>non possiedono una comprensione profonda</strong><span style="font-weight: 400;"> di ciÃ² che scrivono, nÃ© coscienza o intenzionalitÃ . Spesso attribuiamo loro caratteristiche umane (câ€™Ã¨ chi chiede al chatbot se </span><i><span style="font-weight: 400;">prova emozioni</span></i><span style="font-weight: 400;"> o se </span><i><span style="font-weight: 400;">pensa come noi</span></i><span style="font-weight: 400;">), ma Ã¨ unâ€™illusione. In realtÃ  un LLM </span><strong>non â€œcapisceâ€ il significato</strong><span style="font-weight: 400;"> come lo capiremmo noi, ma manipola simboli statistici. Alcuni ricercatori hanno icasticamente definito questi modelli </span><i><span style="font-weight: 400;">â€œpappagalli stocasticiâ€</span></i><span style="font-weight: 400;">: in pratica, imitano il linguaggio umano senza averne la </span><i><span style="font-weight: 400;">consapevolezza</span></i><span style="font-weight: 400;">.</span></p>
<p><span style="font-weight: 400;">Conoscere la struttura e il metodo di generazione di un LLM ci aiuta a </span><strong>ridimensionare alcune aspettative</strong><span style="font-weight: 400;"> e ad usarlo con maggiore senso critico. Ecco alcuni punti da tenere a mente quando interagiamo con queste IA:</span></p>
<ul>
<li style="font-weight: 400;" aria-level="1"><strong>Non hanno vera comprensione o conoscenza</strong><span style="font-weight: 400;"> â€“ Un LLM non </span><i><span style="font-weight: 400;">sa</span></i><span style="font-weight: 400;"> di cosa parla; mette insieme frasi basate sulle probabilitÃ  apprese. PuÃ² scrivere </span><i><span style="font-weight: 400;">â€œIl Sole Ã¨ una stellaâ€</span></i><span style="font-weight: 400;"> perchÃ© ha visto spesso quella frase, ma non ha in testa un modello del sistema solare. Come detto, Ã¨ un </span><i><span style="font-weight: 400;">pappagallo statistico</span></i><span style="font-weight: 400;"> che ripete strutture linguistiche plausibili senza ancorarle a un significato vero. Dunque, anche se le sue risposte </span><strong>suonano</strong><span style="font-weight: 400;"> competenti, lâ€™LLM non dispone di un vero </span><strong>filtro di veritÃ </strong><span style="font-weight: 400;"> o di logica: sta solo seguendo i pattern appresi.</span><span style="font-weight: 400;"><br><br></span></li>
<li style="font-weight: 400;" aria-level="1"><strong>Possono </strong><strong><i>allucinare</i></strong><strong> (inventare) fatti</strong><span style="font-weight: 400;"> â€“ Capita spesso che un LLM fornisca informazioni del tutto sbagliate con tono sicuro. Ad esempio, potrebbe affermare una data storica errata, citare una legge inesistente o mischiare biografie di persone diverse. Questo avviene perchÃ© il modello </span><strong>non ha modo di verificare</strong><span style="font-weight: 400;"> le sue affermazioni: se certi termini compaiono frequentemente insieme nei suoi dati di training, lui li userÃ , anche se lâ€™informazione Ã¨ falsa. In gergo si parla di </span><i><span style="font-weight: 400;">allucinazioni dellâ€™IA</span></i><span style="font-weight: 400;">. Il problema Ã¨ che lâ€™LLM </span><strong>non sa di non sapere</strong><span style="font-weight: 400;">: non ha un feedback interno che gli dica â€œquesta cosa Ã¨ sbagliataâ€. Un gruppo di esperti ha sottolineato proprio che, </span><i><span style="font-weight: 400;">â€œsiccome si limita a mettere insieme parole in base ai dati di addestramento, un LLM non si rende conto se sta dicendo qualcosa di scorretto o inopportunoâ€</span></i><span style="font-weight: 400;">. Sta a noi utenti, quindi, fare da filtro: </span><strong>mai prendere per oro colato</strong><span style="font-weight: 400;"> tutto ciÃ² che esce da ChatGPT &amp; co., specialmente dati di fatto importanti, senza una verifica esterna.</span><span style="font-weight: 400;"><br><br></span></li>
<li style="font-weight: 400;" aria-level="1"><strong>Hanno i bias dei dati (e dei programmatori)</strong><span style="font-weight: 400;"> â€“ Un LLM assorbe pregiudizi, errori e punti di vista presenti nei testi con cui Ã¨ stato addestrato. Se gran parte del web contiene un bias (ad esempio stereotipi di genere o discriminazioni razziali), il modello puÃ² rifletterli nelle sue risposte. E anche se ci sono processi di correzione e filtraggio, non esiste garanzia assoluta di neutralitÃ  o accuratezza. In piÃ¹, i </span><strong>valori</strong><span style="font-weight: 400;"> che guidano il modello (cosa considera accettabile o meno dire) dipendono in larga misura da scelte dei suoi sviluppatori durante la fase di fine-tuning. Questo non significa che lâ€™LLM sia â€œmalvagioâ€ o manipolatore di per sÃ© â€“ ricordiamo, non ha volontÃ  â€“ ma che </span><strong>puÃ² ereditare sia il meglio sia il peggio</strong><span style="font-weight: 400;"> del materiale su cui Ã¨ stato addestrato.</span><span style="font-weight: 400;"><br><br></span></li>
<li style="font-weight: 400;" aria-level="1"><strong>Non provano emozioni (anche se le simulano)</strong><span style="font-weight: 400;"> â€“ Gli LLM possono scrivere frasi molto empatiche (</span><i><span style="font-weight: 400;">â€œMi dispiace che tu stia attraversando questo momento difficileâ€¦â€</span></i><span style="font-weight: 400;">), ma ciÃ² non implica alcuna esperienza emotiva da parte loro. Quando leggiamo una risposta accorata di un chatbot, siamo tentati di attribuirle unâ€™intenzione o una sensibilitÃ ; in realtÃ  il modello sta semplicemente riproducendo schemi linguistici tipici delle conversazioni empatiche che ha visto nei suoi dati. </span><strong>Non câ€™Ã¨ un â€œioâ€ dietro quelle parole</strong><span style="font-weight: 400;">, nessuna coscienza che soffre, gode o tiene davvero a noi. Ãˆ fondamentale ricordarlo per evitare di prendere decisioni emotive basate su una falsa percezione dellâ€™IA (ad esempio, sentirsi giudicati da lei, o credere che â€œci tengaâ€ davvero). Lâ€™LLM Ã¨ </span><i><span style="font-weight: 400;">abile imitazione</span></i><span style="font-weight: 400;"> di un parlante umano, ma resta unâ€™imitazione.</span><span style="font-weight: 400;"><br><br></span></li>
</ul>
<p><span style="font-weight: 400;">Conoscere </span><i><span style="font-weight: 400;">come Ã¨ fatto e come lavora</span></i><span style="font-weight: 400;"> un Large Language Model ci aiuta a usarlo in modo piÃ¹ </span><strong>maturo e consapevole</strong><span style="font-weight: 400;">. Possiamo ammirarne le capacitÃ  â€“ perchÃ© Ã¨ straordinario che un software </span><strong>autocompleti</strong><span style="font-weight: 400;"> testi cosÃ¬ bene da sembrare creativi o competenti â€“ </span><strong>senza perÃ² mitizzarlo</strong><span style="font-weight: 400;">. Un LLM non Ã¨ un oracolo infallibile nÃ© una mente artificiale dotata di saggezza propria: Ã¨ un potente strumento statistico, un prodotto dellâ€™ingegno umano (ricerca, algoritmi e tonnellate di dati). Sta a noi utilizzarlo come </span><i><span style="font-weight: 400;">amplificatore</span></i><span style="font-weight: 400;"> della nostra creativitÃ  e produttivitÃ , ma anche come soggetto da monitorare. In fondo, </span><strong>dietro le quinte di unâ€™IA linguistica non câ€™Ã¨ magia</strong><span style="font-weight: 400;"> â€“ câ€™Ã¨ matematica, informatica e tanta probabilitÃ . E piÃ¹ ne siamo consapevoli, meglio potremo sfruttare queste nuove tecnologie senza farci sfruttare da esse.</span></p>
<h2>Da dove arrivano i dati? (Spoiler: anche da te)Â </h2>
<p><span style="font-weight: 400;">Immagina per un attimo unâ€™IA come un grande scrittore che non ha mai vissuto nulla in prima persona. Non ha viaggiato, non ha amato, non ha mai mangiato una pizza vera. Eppure scrive poesie, articoli, dialoghi brillanti. Come fa? Semplice: </span><strong><i>legge tutto quello che trova</i></strong><span style="font-weight: 400;">. Interi oceani di parole â€“ siti web, manuali, romanzi, ricette, forum, tweet, commenti, newsletter, persino battute da meme e recensioni su Amazon. Se câ€™Ã¨ stato un momento in cui hai pubblicato qualcosa online, câ€™Ã¨ una buona possibilitÃ  che lâ€™IA lo abbia letto (o almeno scannerizzato) in silenzio.</span></p>
<p><span style="font-weight: 400;">Ma ecco il punto critico: per anni si Ã¨ attinto a piene mani da Internet â€“ tutto a portata di clic. Il problema Ã¨ che molti di quei contenuti sono protetti da copyright: libri, articoli, blog, canzoni, manuali. E non sempre chi li ha scritti ha dato il permesso di usarli. Negli Stati Uniti, diversi autori, editori e giornalisti hanno fatto causa a colossi come OpenAI e Meta, accusandoli di aver "ingurgitato" opere intere senza autorizzazione per addestrare i loro modelli. Le aziende, dal canto loro, si difendono invocando il â€œfair useâ€, una clausola del diritto americano che permette lâ€™uso di opere protette in certi casi (come ricerca o parodia). Ma il confine tra uso lecito e sfruttamento improprio Ã¨ sempre piÃ¹ sottile, specialmente se lâ€™output dellâ€™IA finisce per somigliare troppo a un contenuto originale. In Europa, intanto, si spingono nuove regole per obbligare le aziende a dichiarare chiaramente </span><strong>che dati usano, dove li prendono e per che cosa</strong><span style="font-weight: 400;">. Insomma, si sta cercando di trasformare la scatola nera dei LLM in una finestra (almeno socchiusa) sulla loro memoria. E non Ã¨ una battaglia da poco: in gioco non câ€™Ã¨ solo la proprietÃ  intellettuale, ma il diritto delle persone a sapere se â€“ e come â€“ i loro contenuti vengono usati per creare â€œlâ€™intelligenzaâ€ delle macchine.</span></p>
<p><span style="font-weight: 400;">Ultimamente, parlare di come vengono â€œallenateâ€ le intelligenze artificiali significa entrare in una cucina in pieno fermento. Gli ingredienti sono testi presi dal web, grandi banche dati, righe di codice, dati artificiali creati da altre AI, e â€“ sempre piÃ¹ spesso â€“ un pizzico di controversia legale. Le grandi aziende del settore lavorano costantemente per rendere questi modelli piÃ¹ performanti, piÃ¹ affidabili, piÃ¹ â€œumaniâ€ nel modo di rispondere. Ma non si tratta solo di potenza di calcolo: il vero salto lo stanno facendo con tecniche di fine-tuning mirato e dati sintetici. Detto in modo semplice, si prendono modelli generici e li si â€œriprogrammaâ€ su settori specifici â€“ medicina, giurisprudenza, creativitÃ  â€“ usando dati nuovi, a volte prodotti proprio da unâ€™altra IA. Un poâ€™ come allenare un buon musicista a specializzarsi nel jazz, dopo anni di classica. Si aggiungono e affiancano anche altre tecniche prima di arrivare alla risposta vera e propria come ad esempio il Reinforcement Learning from Human Feedback: sÃ¬, lâ€™AI viene corretta anche a mano da persone in carne e ossa, che le dicono cosa suona naturale, cosa Ã¨ fuori luogo, cosa Ã¨ utile (avete presente quel pollice su/giÃ¹ che compare alla fine in ogni risposta?). E questo, strano a dirsi, Ã¨ ciÃ² che la rende un poâ€™ meno â€œmacchinaâ€ e un poâ€™ piÃ¹ â€œdialoganteâ€.</span></p>
<p>Â </p>
<h2>LLM con le mani: la nuova generazione di AI che pensa e agisce</h2>
<p><span style="font-weight: 400;">Lâ€™AI oggi non si accontenta piÃ¹ di rispondere a una domanda: vuole (o meglio, puÃ²) agire. Stiamo assistendo a un passaggio cruciale, quello dagli LLM tradizionali â€“ che producono qualcosa e si fermano lÃ¬ â€“ a </span><strong>sistemi agentici</strong><span style="font-weight: 400;">, cioÃ¨ agenti digitali capaci di compiere azioni complesse, in autonomia, su piÃ¹ passaggi. Sembra fantascienza, ma non lo Ã¨. Immagina di chiedere a unâ€™IA: â€œ</span><i><span style="font-weight: 400;">Prenotami un viaggio per Roma a ottobre, con hotel vicino al centro e voli in orari comodi.</span></i><span style="font-weight: 400;">â€ Fino a poco fa avresti ricevuto un elenco di opzioni. Oggi, un </span><i><span style="font-weight: 400;">agente AI</span></i><span style="font-weight: 400;"> come quelli su cui stanno lavorando OpenAI, Google o Meta puÃ² effettivamente aprire siti, cercare voli e hotel, confrontare prezzi, compilare moduli, e â€“ in certi casi â€“ completare il tutto. PuÃ² interagire direttamente e in modo autonomo con piattaforme e servizi di terze parti. Il tutto seguendo una logica propria, imparata in fase di addestramento, pre-allenata dal fornitore dello strumento e </span><i><span style="font-weight: 400;">senza che tu debba intervenire di continuo</span></i><span style="font-weight: 400;">. E non parliamo piÃ¹ solo di esperimenti in laboratorio: OpenAI, ad esempio, ha presentato â€œOperatorâ€, un prototipo capace di usare un computer virtuale come farebbe un utente umano, con tanto di mouse e tastiera simulati. Ãˆ stato addestrato non solo a generare testo, ma a </span><i><span style="font-weight: 400;">capire cosa fare</span></i><span style="font-weight: 400;"> in contesti digitali complessi, adattandosi passo dopo passo. La novitÃ ? Questi agenti non sono piÃ¹ solo bravi a scrivere, produrre immagini, audio o videoÂ  â€“ stanno diventando</span><strong> </strong><span style="font-weight: 400;">capaci di </span><strong>comprendere il contesto</strong><span style="font-weight: 400;"> eÂ  </span><strong>portare a termine </strong><strong><i>task</i></strong><strong> pratici</strong><span style="font-weight: 400;">. E, se tutto funziona come sperano le big tech, potremmo presto avere agenti personali evoluti che ci gestiscono email, documenti, viaggi e appuntamenti o interi flussi di attivitÃ  complesse.Â </span></p>
<p><span style="font-weight: 400;">Ma, ovviamente, qui iniziano anche le </span><strong>domande spinose, </strong><span style="font-weight: 400;">per ora ce ne poniamo solo qualcuna dato che la lista potrebbe essere molto piÃ¹ ricca:Â </span></p>
<ul>
<li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">Quanto possiamo fidarci di un software che agisce al posto nostro?Â </span></li>
<li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">Abbiamo davvero controllo su ciÃ² che lâ€™agente fa quando agisce â€œda soloâ€?Â </span></li>
<li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">E come assicurarci che faccia davvero ciÃ² che vogliamo â€“ e non altro?Â </span></li>
<li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">Chi Ã¨ responsabile se un agente AI prende una decisione sbagliata o dannosa?Â </span></li>
<li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">Chi controlla i filtri, i limiti e le â€œzone ciecheâ€ dellâ€™agente AI?Â </span></li>
<li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">Quanto Ã¨ accettabile â€“ eticamente e culturalmente â€“ permettere che un software â€œparli e agisca per noiâ€?Â </span></li>
<li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">Soprattutto nei contesti educativi, professionali o affettivi: vogliamo che le nostre parole siano le nostre, o solo le piÃ¹ efficienti?</span></li>
</ul>
<hr>
<p>Questo post Ã¨ parte della rubrica <strong><a href="https://pianetararo.org/traiettorie/">TrAIettorie</a></strong> di cui potete trovare l'indice completo <a href="https://pianetararo.org/tags/traiettorie/">qui</a>.</p>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Privacy e intelligenza artificiale: cosa dobbiamo sapere nel 2025</title>
        <author>
            <name>Pianetararo Associazione Culturale</name>
        </author>
        <link href="https://pianetararo.org/privacy-e-intelligenza-artificiale-cosa-dobbiamo-sapere-nel-2025/"/>
        <id>https://pianetararo.org/privacy-e-intelligenza-artificiale-cosa-dobbiamo-sapere-nel-2025/</id>
        <media:content url="https://pianetararo.org/media/posts/21/g9ddxhg9ddxhg9dd.jfif" medium="image" />
            <category term="TRAIETTORIE"/>

        <updated>2025-05-01T20:49:00+02:00</updated>
            <summary>
                <![CDATA[
                        <img src="https://pianetararo.org/media/posts/21/g9ddxhg9ddxhg9dd.jfif" alt="" />
                    Diciamocelo: ormai interagire con un chatbot â€“ che sia ChatGPT, Gemini, Claude o uno dei mille assistenti virtuali â€“ Ã¨ diventato quasi come fare una chiacchierata al bar. Solo che, al posto del barista, câ€™Ã¨ un algoritmo che ci risponde in un italiano perfetto (o&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                    <p><img src="https://pianetararo.org/media/posts/21/g9ddxhg9ddxhg9dd.jfif" class="type:primaryImage" alt="" /></p>
                <p>Â </p>
<p><span style="font-weight: 400;">Diciamocelo: ormai interagire con un chatbot â€“ che sia ChatGPT, Gemini, Claude o uno dei mille assistenti virtuali â€“ Ã¨ diventato quasi come fare una chiacchierata al bar. Solo che, al posto del barista, câ€™Ã¨ un algoritmo che ci risponde in un italiano perfetto (o quasi). Studenti, insegnanti, genitori, professionisti â€“ chi piÃ¹ chi meno â€“ ci siamo messi a â€œparlareâ€ con queste AI per fare domande, chiedere aiuto, o semplicemente toglierci una curiositÃ . Ma sai cosa? Ogni volta che parliamo con un LLM â€“ un modello linguistico generativo, per usare il termine tecnico â€“ stiamo lasciando dietro di noi una scia di dati. Un poâ€™ come se, dopo aver chiesto al barista un consiglio, scoprissimo che stava registrando la nostra conversazione per studiarci meglio.</span></p>
<p><span style="font-weight: 400;">E qui si apre un tema enorme: </span><strong>la privacy</strong><span style="font-weight: 400;">. PerchÃ© questi strumenti, sÃ¬, sono incredibili â€“ ma a che prezzo? Quali dati cediamo, consapevoli o meno, quando chiediamo un consiglio per lâ€™ansia, carichiamo la foto di famiglia su un generatore dâ€™immagini, o raccontiamo una situazione privata al chatbot? Questo articolo (che sÃ¬, Ã¨ lungo, ma merita) prova a fare chiarezza e stimolare qualche riflessione. Analizzeremo i rischi, le leggi in gioco â€“ il </span><a href="https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32016R0679"><span style="font-weight: 400;">GDPR</span></a><span style="font-weight: 400;">, lâ€™</span><a href="https://artificialintelligenceact.eu/"><span style="font-weight: 400;">AI Act</span></a><span style="font-weight: 400;">Â  â€“ e ci faremo anche qualche domanda scomoda: </span><strong>cosa fanno le Big Tech con i nostri dati?</strong><span style="font-weight: 400;"> E noi, ci dobbiamo preoccupare?</span></p>
<p><span style="font-weight: 400;">Prima perÃ², fermiamoci un attimo a guardare i rischi veri. Quelli meno ovvi. Quelli che spesso ignoriamo mentre chattiamo con lâ€™IA pensando â€œtanto Ã¨ solo un robotâ€.</span></p>
<p><span style="font-weight: 400;">Non Ã¨ roba da smanettoni o da esperti: riguarda tutti noi. Studenti, insegnanti, genitori, professionisti, chiunque usi questi strumenti per lavorare, imparare o semplicemente divertirsi. PerchÃ© lâ€™IA non Ã¨ piÃ¹ â€œroba da laboratorioâ€: Ã¨ parte della nostra vita di tutti i giorni. E capire come funziona â€“ e come puÃ² influire sulla nostra privacy â€“ Ã¨ un modo per proteggere non solo i nostri dati, ma anche la nostra libertÃ  di essere chi siamo, senza che un algoritmo ci metta in unâ€™etichetta.</span></p>
<h2>I rischi principali: una panoramica pratica</h2>
<p><span style="font-weight: 400;">Partiamo dalle basi. Usare uno strumento di Intelligenza artificiale, per esempio un Large Language Model come ChatGPT, non Ã¨ come scrivere sul quaderno: Ã¨ come parlare in un microfono acceso, con qualcuno (o qualcosa) che sta ascoltando, registrando e, talvolta, imparando da quello che diciamo. Ecco una carrellata di rischi, spiegati in modo semplice â€“ con esempi reali, perchÃ© non stiamo parlando di teorie campate in aria.</span></p>
<h5>âš ï¸ Condivisione involontaria di dati</h5>
<p><span style="font-weight: 400;">Quando scrivi â€œEhi ChatGPT, dammi un consiglio per il compleanno del mio amico Marco, che soffre di ansiaâ€? Ecco: in quel momento hai appena dato due informazioni personali â€“ il nome di Marco e un dato sensibile sulla sua salute. Magari non ci hai fatto caso, ma il chatbot (e chi lo gestisce) le ha registrate. E potrebbero rimanere lÃ¬, nei log, anche per mesi.</span></p>
<h5>âš ï¸Prompt conservati e riutilizzati</h5>
<p><span style="font-weight: 400;">Le conversazioni con gli LLM non spariscono nel nulla. Spesso vengono archiviate e usate per â€œinsegnareâ€ al modello a migliorare. Quindi il tuo messaggio, la tua storia, le tue domande â€“ potrebbero contribuire ad addestrare la prossima versione di quel chatbot. Se pensi che basti cancellare la cronologia per stare tranquilli, sappi che anche in quel caso i dati potrebbero rimanere salvati per 30 giorni (come succedeva e succede anche con alcuni piani con ChatGPT) oppure anche </span><a href="https://www.repubblica.it/tecnologia/2025/06/09/news/open-ai-obbligata-conservare-conversazioni-chatgpt-new-york-times-424657181/"><span style="font-weight: 400;">per sempre</span></a><span style="font-weight: 400;">.</span></p>
<h5>âš ï¸Occhi umani dietro le quinte</h5>
<p><span style="font-weight: 400;">Non câ€™Ã¨ solo lâ€™algoritmo: a volte, per migliorare lâ€™IA, ci sono anche persone in carne e ossa che leggono pezzi delle conversazioni. Certo, si parla di chat â€œanonimizzateâ€, ma se scrivi â€œMio figlio Lorenzo fa le medie a Roma e ha problemi con la matematicaâ€, quei dati, anche senza il tuo nome, sono comunque riconoscibili. E magari finiscono davanti agli occhi di un revisore umano, chissÃ  dove nel mondo.</span></p>
<h5>âš ï¸Tracciamento invisibile e fingerprinting</h5>
<p><span style="font-weight: 400;">Un poâ€™ come quando navighi su un sito e ti senti â€œseguitoâ€ dagli annunci, anche qui i sistemi AI raccolgono informazioni di contorno: il tuo IP, il browser, il dispositivo, perfino quanto tempo rimani su una pagina o a che ora scrivi. Tutti dettagli che, messi insieme, costruiscono un profilo abbastanza dettagliato â€“ e tu magari nemmeno te ne accorgi. Ãˆ come lasciare briciole digitali che qualcun altro raccoglie.</span></p>
<h5>âš ï¸Â Profilazione implicita</h5>
<p><span style="font-weight: 400;">Anche senza dirlo esplicitamente, il chatbot puÃ² â€œcapireâ€ cose su di te. Se gli chiedi spesso consigli su sintomi di malattie, oppure parli di viaggi in determinati Paesi, o di hobby particolari, il sistema puÃ² dedurre â€“ e magari registrare â€“ che sei interessato a quelle cose. E questo profilo, se finisce in mani sbagliate o viene usato per scopi di marketing, o peggio azioni di condizionamento e diventa un problema serio.</span></p>
<h5>âš ï¸ Perdita di controllo sui dati</h5>
<p><span style="font-weight: 400;">Una volta che i tuoi dati entrano in un sistema AI, non câ€™Ã¨ piÃ¹ modo di riprenderli indietro. Sono archiviati su server, magari in un altro continente, e chi garantisce che non vengano usati in futuro per scopi diversi? Pensiamo, ad esempio, a una mamma che carica foto di famiglia su un generatore di immagini AI: quelle immagini potrebbero essere usate per altro, e se domani câ€™Ã¨ una violazione o un cambio di policy, potrebbero anche finire in mani sbagliate.Â </span></p>
<h5>âš ï¸ Memorizzazione nascosta e rischio leak</h5>
<p><span style="font-weight: 400;">Ecco il punto forse piÃ¹ inquietante: i modelli AI apprendono dai dati, e talvolta possono â€œricordareâ€ dettagli sensibili, anche se non dovrebbero. Ci sono stati casi in cui i ricercatori hanno dimostrato che un chatbot poteva rigenerare numeri di carte di credito usate durante lâ€™addestramento. E se capita con una carta, perchÃ© non con il tuo indirizzo email o il nome del tuo amico Marco?</span></p>
<h5>âš ï¸ RepsonsabilitÃ  per condivisione di dati riservati</h5>
<p><span style="font-weight: 400;">Argomento decisamente problematico. Quando condividi con il chatbot un pdf, l'email (magari con dati personali altrui), il codice sorgente, un file excel che desideri rielaborare o riassumere ? Sei sicuro di poterlo fare ? Stai condividendo materiale generico o materiale riservato, magari protetto da diritti autore o segreto industriale? Occorre riflettere e porre attenzione sui materiali che maneggiamo in relazione agli strumenti che utlizziamo. Nel dubbio vale la regola - evitare.</span></p>
<h5>âš ï¸ Allucinazioni problematiche o pericolose</h5>
<p><span style="font-weight: 400;">Le IA non sono infallibili. Possono â€œinventareâ€ dati â€“ e a volte, quei dati inventati riguardano persone vere. Se il chatbot ti dÃ  la data di nascita sbagliata di un politico, o ti attribuisce un titolo di studio che non hai mai conseguito, si tratta di un problema serio di accuratezza. E correggere questi errori? Spesso impossibile, perchÃ© lâ€™IA non sa nemmeno da dove ha preso quellâ€™informazione.</span></p>
<h5>âš ï¸ Minori e poca protezione</h5>
<p><span style="font-weight: 400;">Non dimentichiamo i piÃ¹ giovani: i minorenni usano chatbot senza sempre capire i rischi. Fino al 2023, bastava inserire una data di nascita falsa per usare ChatGPT, anche se avevi 12 anni. Solo dopo interventi dei Garanti (come quello italiano) si Ã¨ iniziato a introdurre controlli piÃ¹ robusti, ma il problema rimane: i dati dei minori finiscono spesso nel sistema, senza garanzie e consapevolezza.</span></p>
<h5>âš ï¸ Data breach e falle di sicurezza</h5>
<p><span style="font-weight: 400;">Infine, i bug e le violazioni. Ãˆ giÃ  successo (ad esempio a marzo 2024, con ChatGPT) che per errore tecnico alcuni utenti vedessero le chat di altri â€“ inclusi dettagli su abbonamenti e pagamenti. OpenAI allâ€™epoca non avvisÃ² subito tutti i Garanti europei, e questo ha portato a una multa salata. Ãˆ un promemoria importante: i dati che forniamo a queste piattaforme non sono blindati, e un semplice bug puÃ² renderli visibili ad altri.</span></p>
<hr>
<h2>Le regole del gioco: GDPR, AI Act e il nodo della privacy nellâ€™IA</h2>
<p><span style="font-weight: 400;">Cosa rende il mondo dellâ€™intelligenza artificiale cosÃ¬ affascinante, ma anche cosÃ¬ complicato? Il fatto che corriamo alla velocitÃ  della luce â€“ nuovi modelli, nuove app, nuove possibilitÃ  â€“ mentre le leggi, beh, fanno un poâ€™ fatica a stare al passo. E non Ã¨ per cattiveria: regolamentare lâ€™IA Ã¨ come provare a dare la caccia a unâ€™ombra che cambia forma ogni volta che ti avvicini. Ma vediamo insieme cosa sta succedendo, perchÃ© se usi un chatbot, agenti o lavori con questi strumenti, capire le regole Ã¨ fondamentale.</span></p>
<h3>Il GDPR: una bussola ancora valida, ma con qualche ammaccatura</h3>
<p><span style="font-weight: 400;">Partiamo da quello che giÃ  conosciamo: il </span><a href="https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32016R0679"><strong>Regolamento Generale sulla Protezione dei Dati (GDPR)</strong></a><span style="font-weight: 400;">. SÃ¬, proprio quello che ci ricorda di leggere le informative privacy (quelle chilometriche che spesso scorriamo velocemente). Il GDPR non Ã¨ roba vecchia: anche nel 2025 resta </span><strong>la cornice principale</strong><span style="font-weight: 400;"> per la protezione dei dati personali in Europa, e si applica pure ai dati trattati dagli LLM.</span></p>
<p><span style="font-weight: 400;">PerchÃ© Ã¨ importante? PerchÃ© il GDPR stabilisce principi fondamentali come:</span></p>
<ul>
<li style="font-weight: 400;" aria-level="1"><strong>Trasparenza</strong><span style="font-weight: 400;">: devi sapere come vengono usati i tuoi dati.</span><span style="font-weight: 400;"><br><br></span></li>
<li style="font-weight: 400;" aria-level="1"><strong>Minimizzazione</strong><span style="font-weight: 400;">: non si possono raccogliere piÃ¹ dati del necessario.</span><span style="font-weight: 400;"><br><br></span></li>
<li style="font-weight: 400;" aria-level="1"><strong>Esattezza</strong><span style="font-weight: 400;">: i dati personali devono essere corretti e aggiornati.</span><span style="font-weight: 400;"><br><br></span></li>
<li style="font-weight: 400;" aria-level="1"><strong>Sicurezza</strong><span style="font-weight: 400;">: le aziende devono proteggere i tuoi dati da violazioni o furti.</span><span style="font-weight: 400;"><br><br></span></li>
<li style="font-weight: 400;" aria-level="1"><span style="font-weight: 400;">E, soprattutto, </span><strong>diritti dellâ€™interessato</strong><span style="font-weight: 400;">: puoi chiedere di accedere ai tuoi dati, farli cancellare, correggere o opporsi al trattamento.</span><span style="font-weight: 400;"><br><br></span></li>
</ul>
<p><span style="font-weight: 400;">Ora, fin qui tutto chiaro, no? Ma il punto Ã¨ che </span><strong>gli LLM non sono come una rubrica telefonica</strong><span style="font-weight: 400;">. Sono sistemi complessi, che apprendono da quantitÃ  immense di dati â€“ inclusi i tuoi post sui social, i tuoi articoli, perfino quel commento lasciato dieci anni fa su un forum dimenticato. E qui casca lâ€™asino: </span><strong>su quale base legale si fonda il loro addestramento?</strong></p>
<h3>La questione della base giuridica: legittimo interesse o consenso?</h3>
<p><span style="font-weight: 400;">Prendiamo </span><a href="https://www.agendadigitale.eu/sicurezza/privacy/ai-di-meta-e-davvero-legittimo-interesse-lecito-dubitarne/"><span style="font-weight: 400;">Meta</span></a><span style="font-weight: 400;"> o OpenAI e ChatGPT come esempio. Quando hanno iniziato a raccogliere dati da internet (forum, blog, pagine web) per addestrare i modelli, non hanno chiesto a nessuno. Nessuna email, nessun banner di consenso. Loro hanno detto: â€œVa bene cosÃ¬, Ã¨ nel nostro legittimo interesseâ€.</span></p>
<p><span style="font-weight: 400;">Il problema? Beh, il GDPR non Ã¨ cosÃ¬ permissivo. Usare dati personali â€“ anche se pubblici â€“ per scopi di addestramento richiede una </span><strong>valutazione rigorosa</strong><span style="font-weight: 400;">, e forse anche il consenso esplicito degli interessati. Il Garante Privacy italiano, infatti, ha sollevato la questione: </span><strong>â€œScusate, ma su che base giuridica avete preso e usato questi dati?â€</strong></p>
<p><span style="font-weight: 400;">Risultato: il caso Ã¨ finito per esempio nelle mani dellâ€™AutoritÃ  irlandese (che, per via del meccanismo del â€œone-stop-shopâ€ in UE, funge da capofila per OpenAI). E qui siamo ancora in attesa di una decisione chiara, ma il messaggio Ã¨ forte: </span><strong>le regole valgono per tutti, anche per le Big Tech</strong><span style="font-weight: 400;">. Non basta dire â€œÃ¨ nel nostro interesseâ€. Serve dimostrarlo.</span></p>
<h3>Trasparenza: il nodo delle informative (e la fatica di capirle)</h3>
<p><span style="font-weight: 400;">Il GDPR impone anche che le aziende spieghino bene come usano i dati. Ma spiegare bene, cosa significa? Facciamo un esempio: per un poâ€™, OpenAI non diceva chiaramente che i prompt degli utenti (cioÃ¨ le domande fatte a ChatGPT) venivano usati per addestrare il modello. NÃ© specificava che i dati personali inseriti nelle chat potevano finire in mano a revisori umani.</span></p>
<p><span style="font-weight: 400;">Solo dopo lâ€™intervento del </span><a href="https://www.garanteprivacy.it/home/docweb/-/docweb-display/docweb/10085432"><span style="font-weight: 400;">Garante italiano â€“ con tanto di sanzione da 15 milioni di euro a dicembre 2024 â€“ OpenAI</span></a><span style="font-weight: 400;"> ha dovuto aggiornare la privacy policy, avviare una campagna informativa, e mettere a disposizione opzioni per â€œuscireâ€ dal training (lâ€™opt-out). Ma resta un problema: </span><strong>anche se disattivi la cronologia, i tuoi dati restano per 30 giorni sui server.</strong><span style="font-weight: 400;"> E, spesso, non Ã¨ cosÃ¬ semplice capire dove finiscano davvero le informazioni.</span></p>
<p><span style="font-weight: 400;">Ãˆ un poâ€™ come leggere le clausole scritte in piccolo in un contratto di assicurazione: puoi farlo, ma devi armarti di pazienza â€“ e magari di una lente dâ€™ingrandimento.</span></p>
<h3>Esattezza e allucinazioni: quando lâ€™IA sbaglia (e non puoi rimediare)</h3>
<p><span style="font-weight: 400;">Un altro tema caldo Ã¨ quello dellâ€™</span><strong>accuratezza</strong><span style="font-weight: 400;">. Secondo il GDPR, i dati personali devono essere </span><strong>corretti e aggiornati</strong><span style="font-weight: 400;">. Ma con un LLM, come fai? Se il modello ha imparato che â€œMario Rossi Ã¨ nato nel 1978â€ e in realtÃ  Mario Rossi Ã¨ nato nel 1982, come correggi quellâ€™informazione? La risposta breve Ã¨: </span><strong>non puoi, almeno non facilmente</strong><span style="font-weight: 400;">.</span></p>
<h3>Minori e soggetti vulnerabili: tutele deboli, rischi alti</h3>
<p><span style="font-weight: 400;">Un altro punto dolente riguarda i </span><strong>minori</strong><span style="font-weight: 400;">. Il GDPR dice chiaramente che per usare un servizio online sotto i 16 anni (o 13, in base allo Stato), serve il consenso dei genitori. Eppure, fino a poco tempo fa, chiunque poteva accedere a ChatGPT semplicemente inserendo una data di nascita a caso. Solo dopo il richiamo del Garante, OpenAI ha introdotto controlli piÃ¹ robusti (prima un semplice â€œage-gateâ€, poi un sistema piÃ¹ avanzato con verifica di terze parti). Ma siamo ancora in una fase di rodaggio: il sistema funziona davvero? E come si tutelano i dati dei minori una volta dentro il sistema?</span></p>
<p><span style="font-weight: 400;">Insomma, le falle ci sono. E lâ€™impressione Ã¨ che le aziende abbiano corso per lanciare i prodotti, senza preoccuparsi troppo delle regole â€“ salvo poi correre ai ripari quando arrivano le multe.</span></p>
<h3>Il nuovo arrivato: lâ€™AI Act europeo</h3>
<p><span style="font-weight: 400;">E ora parliamo di lui, lâ€™</span><a href="https://artificialintelligenceact.eu/"><strong>AI Act</strong></a><span style="font-weight: 400;">, che nel 2025 Ã¨ in dirittura dâ€™arrivo come primo regolamento europeo â€œomnibusâ€ sullâ€™IA. Il GDPR resta la legge sui dati personali, ma lâ€™AI Act interviene </span><strong>a monte</strong><span style="font-weight: 400;">, fissando regole per lo sviluppo e lâ€™uso delle IA â€“ compresi i modelli generativi come ChatGPT.</span></p>
<p><span style="font-weight: 400;">Quali sono i punti chiave? Te li riassumo cosÃ¬:</span></p>
<ul>
<li style="font-weight: 400;" aria-level="1"><strong>Classificazione per rischio</strong><span style="font-weight: 400;">: lâ€™IA viene divisa in categorie (inaccettabile, alto rischio, basso, minimo). Gli LLM general-purpose non sono â€œad alto rischioâ€ di per sÃ©, ma attenzione: se usati in certi contesti (per esempio per la selezione del personale), scattano regole piÃ¹ stringenti.</span><span style="font-weight: 400;"><br><br></span></li>
<li style="font-weight: 400;" aria-level="1"><strong>Trasparenza sui dati di training</strong><span style="font-weight: 400;">: i fornitori dovranno pubblicare un â€œriassuntoâ€ dei dati usati per addestrare il modello. Non tutti i dettagli, ma almeno unâ€™indicazione. Questo per dare un minimo di controllo: sapere se ci sono dentro i tuoi post o quelli di qualcun altro.</span><span style="font-weight: 400;"><br><br></span></li>
<li style="font-weight: 400;" aria-level="1"><strong>Obblighi di sicurezza</strong><span style="font-weight: 400;">: ridurre il rischio di output illegali o discriminatori.</span><span style="font-weight: 400;"><br><br></span></li>
<li style="font-weight: 400;" aria-level="1"><strong>Etichettatura dei contenuti generati</strong><span style="font-weight: 400;">: testi, immagini, video prodotti dallâ€™IA dovranno essere segnalati come tali, per evitare inganni e deepfake.</span><span style="font-weight: 400;"><br><br></span></li>
<li style="font-weight: 400;" aria-level="1"><strong>Divieti specifici</strong><span style="font-weight: 400;">: per esempio, niente piÃ¹ scraping massivo di immagini per creare database di riconoscimento facciale, niente AI per manipolare il comportamento umano in modi dannosi.</span><span style="font-weight: 400;"><br><br></span></li>
</ul>
<p><span style="font-weight: 400;">Il messaggio Ã¨ chiaro: piÃ¹ regole, piÃ¹ responsabilitÃ . E, se non si rispettano, si rischiano multe pesanti: fino a 40 milioni di euro o il 7% del fatturato.</span></p>
<p><span style="font-weight: 400;">Ma attenzione: lâ€™AI Act non sostituisce il GDPR. Piuttosto, ci lavora insieme: il GDPR tutela i dati a valle, lâ€™AI Act agisce a monte. In pratica, il GDPR dice: â€œSe tratti dati personali, fallo beneâ€. Lâ€™AI Act aggiunge: â€œE se sviluppi lâ€™IA, progettala in modo sicuro, trasparente e rispettoso dei diritti delle personeâ€.</span></p>
<h2>Casi concreti: quando i rischi diventano realtÃ </h2>
<p><span style="font-weight: 400;">A questo punto potresti pensare: â€œOk, tutto chiaro, ma questi rischi sono solo ipotesi o sono giÃ  successe cose serie?â€. Spoiler: sono successe. Eccome, e altre ne succederanno in futuro. Ecco alcuni casi che mostrano come le cose possano andare storte â€“ anche quando si tratta di aziende multimiliardarie.</span></p>
<h5><strong>ğŸš¨ </strong>La sanzione italiana a OpenAI: un campanello dâ€™allarme</h5>
<p><span style="font-weight: 400;">Dicembre 2024, Italia. OpenAI si becca una multa da 15 milioni di euro per violazioni al GDPR legate a ChatGPT: mancanza di trasparenza, nessun filtro per i minori, inesattezze nei dati, e per finire, una notifica incompleta di un data breach. In pratica, OpenAI aveva creato uno strumento potentissimo, ma si era dimenticata (o aveva trascurato) le regole europee sulla privacy. La multa italiana Ã¨ stata la prima di questo livello in Europa per un sistema di IA generativa. Un segnale fortissimo, quasi un messaggio in codice: â€œEhi, Big Tech, svegliatevi. Le regole valgono anche per voiâ€.</span></p>
<p><span style="font-weight: 400;">E guarda caso, dopo questo scossone, altre autoritÃ  europee hanno iniziato a muoversi, e il Comitato Europeo per la Protezione dei Dati (EDPB) ha creato una task force su ChatGPT. Segno che, ormai, lâ€™attenzione Ã¨ alta.</span></p>
<h5>ğŸš¨ Il reclamo NOYB in Austria: lâ€™IA non Ã¨ infallibile</h5>
<p><span style="font-weight: 400;">Altro caso interessante:</span><a href="https://noyb.eu/it/chatgpt-provides-false-information-about-people-and-openai-cant-correct-it"><span style="font-weight: 400;"> il reclamo presentato da NOYB</span></a><span style="font-weight: 400;"> (lâ€™associazione fondata da Max Schrems, un nome che chi si occupa di privacy conosce bene) contro OpenAI in Austria. Il problema? Un personaggio pubblico ha chiesto a ChatGPT informazioni su di sÃ© e ha ricevuto dati sbagliati. Ha provato a far correggere lâ€™errore, ma niente da fare: OpenAI ha detto che non puÃ² nÃ© modificare i dati generati nÃ© sapere esattamente da dove provengano.</span></p>
<h5>ğŸš¨Â Il bug di ChatGPT (2023): quando le chat private diventano pubbliche</h5>
<p><span style="font-weight: 400;">Marzo 2023. Un bug tecnico su ChatGPT permette ad alcuni utenti di vedere i titoli delle conversazioni di altri e, in certi casi, dettagli di pagamento. Roba che fa venire i brividi, perchÃ© ci ricorda che </span><strong>nulla Ã¨ davvero privato</strong><span style="font-weight: 400;"> su queste piattaforme. OpenAI ha dovuto correre ai ripari, ma ha commesso un errore grave: non ha notificato subito il data breach a tutte le autoritÃ  europee, come richiesto dal GDPR. Questo ha pesato nella sanzione italiana del 2024.</span></p>
<h5>ğŸš¨ Samsung e il divieto interno: un caso significativo</h5>
<p><span style="font-weight: 400;">Ad aprile 2023, alcuni ingegneri di Samsung â€“ probabilmente in buona fede â€“ hanno caricato pezzi di codice sorgente su ChatGPT per farsi aiutare nel debug. Risultato? Quello stesso codice Ã¨ finito nei log del chatbot e potenzialmente potrebbe essere stato usato per addestrare modelli futuri. Immagina: un segreto industriale che finisce in un sistema terzo fuori dal tuo controllo. La reazione di Samsung? Un divieto netto: niente piÃ¹ chatbot sulle reti aziendali e sui dispositivi interni. E non sono stati i soli: anche banche come JPMorgan e aziende come Apple hanno preso provvedimenti rigorosi simili. Queste casistiche evidenziano un rischio privacy â€œindirettoâ€: non tanto la violazione dei dati personali, quanto la perdita di </span><strong>confidenzialitÃ  di dati aziendali</strong><span style="font-weight: 400;"> (che spesso includono anche dati personali di clienti) quando si usano LLM senza cautele o pensiero critico.</span></p>
<h5>ğŸš¨ Zoom e lâ€™aggiornamento delle policy: quando â€œconsensoâ€ diventa un concetto elastico</h5>
<p><span style="font-weight: 400;">Estate 2023: Zoom aggiorna i suoi termini di servizio e sembra voler usare audio, video e chat delle riunioni per addestrare le proprie IA. Scoppia il caso: utenti e media insorgono, e Zoom fa marcia indietro (almeno in parte). Ma la faccenda resta ambigua: perchÃ© se tu, come organizzatore della riunione, accetti certe funzionalitÃ  AI (come la trascrizione automatica), di fatto stai anche dando il consenso allâ€™uso dei dati per il training. I partecipanti? Se non vogliono che le loro parole vengano usate, devono semplicementeâ€¦ non partecipare alla riunione. Ãˆ un poâ€™ come firmare un contratto senza possibilitÃ  di negoziare le clausole: o prendi tutto o niente.</span></p>
<h2>Le strategie delle Big Tech: tra â€œdata grabbingâ€ e correzioni tardive</h2>
<p><span style="font-weight: 400;">Ora, fermiamoci un attimo. PerchÃ© le Big Tech fanno quello che fanno? Ãˆ semplice: i modelli generativi â€“ ChatGPT, Claude, Gemini, e compagnia â€“ </span><strong>hanno fame di dati</strong><span style="font-weight: 400;">. E non di due spiccioli: servono trilioni di parole, milioni di immagini, video, registrazioni audio. PiÃ¹ dati hai, piÃ¹ il modello Ã¨ potente.</span></p>
<p><span style="font-weight: 400;">Il problema Ã¨ che per un poâ€™ le regole sono state ignorate. OpenAI, Google, Meta â€“ tutti hanno fatto scraping selvaggio del web: post, articoli, commenti, banche dati opache, perfino dati personali come email o numeri di telefono lasciati su forum dimenticati. E hanno usato questi dati senza chiedere nulla a nessuno. Quando le proteste sono iniziate â€“ autori, artisti, giornalisti, cittadini comuni â€“ le aziende hanno cominciato a fare un passo indietro (o quasi).</span></p>
<p><span style="font-weight: 400;">OpenAI ha smesso di elencare dettagli sui dataset usati per GPT-4, dopo averlo fatto per GPT-3. PerchÃ©? Dicono per ragioni di sicurezza e competizione, ma la veritÃ  Ã¨ che meno si dice, meno problemi si rischia.</span></p>
<p><span style="font-weight: 400;">Google, invece, ha aggiornato la sua privacy policy per dire chiaramente che usa â€œdati pubblicamente disponibiliâ€ per addestrare lâ€™IA. Ma cosa significa â€œpubblicamente disponibiliâ€? Anche un post su un blog personale Ã¨ pubblico, ma non vuol dire che chi lo ha scritto voglia vederlo usato per addestrare un chatbot. Ãˆ un terreno scivoloso, e il rischio di cause legali Ã¨ concreto: nel 2023, ad esempio, ci sono state class action contro OpenAI e Meta per lâ€™uso di contenuti protetti da copyright nei training set.</span></p>
<p><span style="font-weight: 400;">Poi ci sono le correzioni di rotta. OpenAI, dopo il caso italiano, ha introdotto un modulo per richiedere la cancellazione dei dati personali dai risultati di ChatGPT. Un passo avanti, certo. Ma resta una domanda: <strong>chi controlla davvero che questi dati vengano rimossi?</strong> E in quanti sanno che possono fare questa richiesta?</span></p>
<p><span style="font-weight: 400;">Intanto, le aziende stanno anche sperimentando nuove strategie: partnership con editori (ad esempio OpenAI con Associated Press), licenze con piattaforme come Shutterstock, e modelli â€œbusinessâ€ a pagamento che promettono piÃ¹ privacy. <strong>Ãˆ come se la privacy stesse diventando un servizio premium</strong>: se paghi, ti proteggiamo i dati; se usi il servizio gratuito, sappi che i tuoi dati potrebbero servire a migliorare il modello, del resto, come ci ricorda Friedman, in economia â€œ<strong>non esistono pasti gratis</strong>â€ e quando stai utilizzando qualcosa di gratuito probabilmente il prodotto sei tu.</span></p>
<h2>E noi? Cosa possiamo fare per proteggerci?</h2>
<p><span style="font-weight: 400;">A questo punto ci si potrebbe sentire un poâ€™ sopraffatti. Ma non Ã¨ tutto fuori dal nostro controllo. Ci sono cose concrete che possiamo fare per proteggerci, come utenti e come cittadini.</span></p>
<ul>
<li style="font-weight: 400;" aria-level="1"><strong>Non condividere dati sensibili nelle chat AI</strong><span style="font-weight: 400;">: sembra banale, ma spesso ci dimentichiamo che anche un messaggio apparentemente innocuo (â€œMio figlio fa la terza media a Milano e ha problemi con la matematicaâ€) contiene dati personali. Meglio evitare.</span><span style="font-weight: 400;"><br><br></span></li>
<li style="font-weight: 400;" aria-level="1"><strong>Controllare le impostazioni di privacy</strong><span style="font-weight: 400;">: molti servizi, come ChatGPT, ora offrono opzioni per non salvare la cronologia o non contribuire al training. In alcuni casi sono nascoste. Usale. E, quando i servizi lo consentono, cancellare la cronologia o disattivare la memoria. </span><span style="font-weight: 400;"><br><br></span></li>
<li style="font-weight: 400;" aria-level="1"><strong>Leggere (almeno una volta) le informative privacy</strong><span style="font-weight: 400;">: lo sappiamo, Ã¨ noioso. Ma almeno una volta proviamo a darci unâ€™occhiata: ci sono spesso dettagli importanti. Atrettanto spesso perÃ² cambiano e quindi vanno rilette ogni tanto.</span><span style="font-weight: 400;"><br><br></span></li>
<li style="font-weight: 400;" aria-level="1"><strong>Esercitare i tuoi diritti</strong><span style="font-weight: 400;">: puoi chiedere di accedere ai tuoi dati, di cancellarli, o di opporti al trattamento. Ãˆ un tuo diritto â€“ usalo.</span><span style="font-weight: 400;"><br><br></span></li>
<li style="font-weight: 400;" aria-level="1"><strong>Se sei un educatore o un genitore, parla di questi temi con i ragazzi</strong><span style="font-weight: 400;">: sono loro i primi a usare queste tecnologie, spesso senza rendersene conto. Un poâ€™ di consapevolezza in piÃ¹ puÃ² fare la differenza.</span><span style="font-weight: 400;"><br><br></span></li>
</ul>
<h2>In fondo, privacy e IA non sono nemici</h2>
<p><span style="font-weight: 400;">Lo so, la tentazione Ã¨ pensare che la privacy e lâ€™IA siano due cose in conflitto: o proteggi i tuoi dati o usi la tecnologia. Ma non deve per forza essere cosÃ¬. Possiamo (e dobbiamo) trovare un equilibrio: costruire IA potenti e utili, ma rispettose della nostra sfera privata, sopratutto etiche e non discriminatorie.</span></p>
<p><span style="font-weight: 400;">Le leggi ci sono â€“ il GDPR, lâ€™AI Act â€“ ma da sole non bastano. Servono aziende piÃ¹ trasparenti, utenti piÃ¹ consapevoli, e autoritÃ  piÃ¹ reattive. <strong>Ãˆ una sfida collettiva</strong>.</span></p>
<p><span style="font-weight: 400;">Una cosa Ã¨ certa: piÃ¹ conosciamo questi strumenti, piÃ¹ possiamo usarli in modo intelligente, senza rinunciare ai nostri diritti. Non dobbiamo smettere di fare domande, di pretendere chiarezza, di chiedere â€œScusate, ma i miei dati dove vanno a finire?â€. Ãˆ solo cosÃ¬ che lâ€™IA diventerÃ  davvero uno strumento al nostro servizio, e non il contrario.</span></p>
<h2>Quanti dati sa di te lâ€™AI? PiÃ¹ di quanto immagini (ma meno di quanto pensi)</h2>
<p>Ãˆ una domanda che inizia a girare sempre piÃ¹ spesso tra chi usa ChatGPT o altri assistenti intelligenti: <em>â€œMa questa AI, quanto sa di me?â€</em> Se la usi spesso, potresti avere lâ€™impressione che ti legga nel pensiero. A volte ti anticipa, altre volte ti dÃ  una risposta che suona... troppo su misura. La veritÃ ? Un LLM (modello linguistico) non ha una memoria infinita nÃ© spia la tua vita â€“ almeno, non nel modo in cui immagini. Ma puÃ² <strong>dedurre molte cose da come gli parli</strong>, anche se non gliele hai dette esplicitamente. Ãˆ un poâ€™ come con un barista che ti vede tutti i giorni: anche se non ti sei mai presentato, sa che prendi il cappuccino con poco zucchero, che arrivi trafelato e che il lunedÃ¬ sei piÃ¹ silenzioso. Il barista poi ricorda ciÃ² che sente ed Ã¨ capace di collegarlo ad altre notizie o informazioni. Lâ€™AI fa lo stesso, solo che lo fa in silenzio, e in modo statistico.</p>
<h5>Esperimenti da fare in salotto</h5>
<p>Vuoi testare quanto un chatbot AI ha imparato su di te? <span style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);">Prova questi piccoli esperimenti. Niente di tecnico, promesso. Prima cosa: chiedi allâ€™AI direttamente </span><em style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);">â€œCosa sai di me?â€</em><span style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);">. Nella maggior parte dei casi, se stai usando un modello chiuso come ChatGPT o Claude, ti risponderÃ  qualcosa tipo </span><em style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);">â€œNon ho informazioni personali su di teâ€</em><span style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);">. </span><span style="font-weight: 400;">I modelli chiusi come quelli di OpenAI o Anthropic sono </span><strong style="font-family: var(--editor-font-family); font-size: inherit;">programmati per non fornire dati personali</strong><span style="font-weight: 400;"> di individui privati.</span><span style="font-weight: 400;"> </span><span style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);">Ma se sei nella </span><strong style="font-family: var(--editor-font-family); font-size: inherit;">stessa chat</strong><span style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);"> in cui hai giÃ  detto â€œMi chiamo Lucia e faccio lâ€™infermieraâ€, potresti scoprire che te lo ripete: ha </span><strong style="font-family: var(--editor-font-family); font-size: inherit;">memoria contestuale</strong><span style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);">, cioÃ¨ ricorda quello che le hai detto poco fa. Vuoi spingerti oltre? Chiedile: </span><em style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);">â€œChe tipo di personalitÃ  pensi io abbia?", "Puoi fare un profilo della mia personalitÃ ?â€</em><span style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);"> oppure </span><em style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);">â€œQuali argomenti tratto piÃ¹ spesso con te?â€</em><span style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);">. </span><span style="font-weight: 400;">Questo invoglia lâ€™AI a sintetizzare i </span><strong style="font-family: var(--editor-font-family); font-size: inherit;">tratti ricorrenti</strong><span style="font-weight: 400;"> che hai mostrato. Potrebbe </span><span style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);">stupire con un piccolo ritratto basato su ciÃ² che hai scritto. Non Ã¨ una scheda FBI, ma una </span><strong style="font-family: var(--editor-font-family); font-size: inherit;">fotografia probabilistica</strong><span style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);">. E se usi un servizio con memoria attiva (come la funzione â€œistruzioni personalizzateâ€ di OpenAI), puoi anche provare: </span><em style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);">â€œQuali dettagli su di me stai usando?â€</em><span style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);"> â€“ cosÃ¬ verifichi cosa si Ã¨ tenuta in tasca da altre conversazioni. Si potrebbe tentare anche qualche domanda investigativa inversa </span><strong style="font-family: var(--editor-font-family); font-size: inherit;"> <i><span style="font-weight: 400;">â€œEsaminando come ti ho posto le domande finora, noti qualche errore o abitudine sbagliata che ho quando chiedo qualcosa?â€, "Puoi dirmi quali sono i tipi di aiuto o gli argomenti che ti ho chiesto piÃ¹ spesso finora?â€</span></i><span style="font-weight: 400;">. Questo costringe lâ€™AI a ripensare alle tue interazioni e magari citare esempi di domande che hai fatto. </span></strong><span style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);">Potremmo indagare il cosidetto "blind spot" </span><strong style="font-family: var(--editor-font-family); font-size: inherit;"><span style="font-weight: 400;">chiedendo <i>â€œBasandoti sulle nostre conversazioni, câ€™Ã¨ qualcosa di significativo che secondo te mi sfugge o tendo a ignorare?â€. </i></span><span style="font-weight: 400;">Ãˆ come chiedere un parere esterno sulle tue abitudini. </span></strong><span style="font-weight: 400;">Questo non Ã¨ tanto un dato â€œraccoltoâ€, quanto una </span><span style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);">inferenza</span><strong style="font-family: var(--editor-font-family); font-size: inherit;"><span style="font-weight: 400;">: lâ€™AI rielabora i dati delle tue interazioni per darti un feedback su di te e questo ti fa capire come il modello analizza e profila in qualche modo il tuo comportamento.</span></strong></p>
<p>Teniamo bene a mente che sono sempre tutte <strong>risposte di tipo probabilistico </strong>(senza intelligenza) e quindi vanno prese con leggerezza e nella consapevolezza che <strong>possono essere errate.</strong></p>
<h5>Un dossier invisibile? No, ma meglio restare svegli</h5>
<p>Câ€™Ã¨ perÃ² unâ€™altra faccia della medaglia. Anche se il modello stesso non ti puÃ² elencare i dati raccolti (non Ã¨ progettato per questo), <strong>la piattaforma che lo gestisce sÃ¬</strong>. Dietro le quinte, i server registrano la cronologia delle chat, lâ€™orario, il tipo di dispositivo usato, la posizione approssimativa. Principalmente per motivi tecnici e legali. Il problema Ã¨ che tu, utente comune, <strong>non puoi vedere tutto questo in chiaro</strong>: non câ€™Ã¨ un pulsante â€œ<em>Scarica ciÃ² che sai di me</em>â€ o â€œ<em>Cancella tutto e dimenticati di me</em>â€ accessibile direttamente dallâ€™AI. Vuoi sapere davvero quali dati hanno memorizzato? Devi fare una richiesta formale al provider â€“ ad esempio tramite i moduli privacy di OpenAI â€“ oppure disattivare le funzioni di cronologia e memoria, e purtroppo una vera cancellazione non sempre Ã¨ possibile, ancor piÃ¹ oggi e in futuro dove i sistemi sono e stanno diventando sempre piÃ¹ Agenti, inevitabilmente condividono sempre piÃ¹ dati con sistemi terzi (anche a noi ignoti). Insomma, lâ€™<strong>AI non ha una sfera di cristallo</strong>, ma se la alimenti a lungo e le lasci indizi... <strong>impara a riconoscerti</strong>. Con misura e consapevolezza, puÃ² essere uno specchio utile e potrebbe diventare anche uno strumento introspettivo interessante. Ma non dimenticare: ogni volta che parli con un sistema AI, <strong>non sei mai del tutto solo</strong>.</p>
<p>Un consiglio guida potrebbe essere â€œ<strong>mai condividere cose che normalmente non condivideresti in pubblico</strong>â€.</p>
<hr>
<p class="align-center">Questo post Ã¨ parte della rubrica <strong><a href="https://pianetararo.org/traiettorie/">TrAIettorie</a></strong> di cui potete trovare l'indice completo <a href="https://pianetararo.org/tags/traiettorie/">qui</a>.</p>
            ]]>
        </content>
    </entry>
    <entry>
        <title>TrAIettorie</title>
        <author>
            <name>Pianetararo Associazione Culturale</name>
        </author>
        <link href="https://pianetararo.org/traiettorie-2/"/>
        <id>https://pianetararo.org/traiettorie-2/</id>
        <media:content url="https://pianetararo.org/media/posts/20/aditya-vyas-jey6eFHP4kA-unsplash.jpg" medium="image" />

        <updated>2025-05-01T16:39:00+02:00</updated>
            <summary>
                <![CDATA[
                        <img src="https://pianetararo.org/media/posts/20/aditya-vyas-jey6eFHP4kA-unsplash.jpg" alt="" />
                    ğŸ“Œ Ãˆ online TRAIETTORIE, la nuova sezione di pianetararoÂ dedicata a esplorare l'educazione critica e consapevole nell'universo digitale. Insegnanti, educatori, famiglie e curiosi del digitale troveranno riflessioni, approfondimenti e strumenti pratici per comprendere come le tecnologie digitali e l'intelligenza artificiale stanno cambiando il nostro modo di&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                    <p><img src="https://pianetararo.org/media/posts/20/aditya-vyas-jey6eFHP4kA-unsplash.jpg" class="type:primaryImage" alt="" /></p>
                <p>ğŸ“Œ Ãˆ online <strong><a href="https://pianetararo.org/traiettorie/">TRAIETTORIE</a></strong>, la nuova sezione di <strong>pianetararo</strong>Â dedicata a esplorare l'educazione critica e consapevole nell'universo digitale. Insegnanti, educatori, famiglie e curiosi del digitale troveranno <span style="text-decoration: underline;"><span style="color: #000000; text-decoration: underline;">riflessioni</span></span>, approfondimenti e strumenti pratici per comprendere come le tecnologie digitali e l'intelligenza artificiale stanno cambiando il nostro modo di apprendere e comunicare. Non ci limitiamo a raccontare l'innovazione, ma ne analizziamo rischi, opportunitÃ  e implicazioni educative ed etiche. Un viaggio aperto e dinamico, fatto di <span style="text-decoration: underline;">domande</span>, confronti e <span style="text-decoration: underline;">laboratori </span>per costruire insieme una <strong>cultura digitale consapevole e responsabile</strong>. Seguici, iscriviti alla nostra <strong>newsletter </strong>e contattaci per proposte educative personalizzate!</p>
            ]]>
        </content>
    </entry>
    <entry>
        <title>FRAMMENTI #25 disponibile anche su Amazon</title>
        <author>
            <name>Pianetararo Associazione Culturale</name>
        </author>
        <link href="https://pianetararo.org/frammenti-25-ora-disponibile-su-lulu-2/"/>
        <id>https://pianetararo.org/frammenti-25-ora-disponibile-su-lulu-2/</id>
        <media:content url="https://pianetararo.org/media/posts/14/frammenti.brosssura-2.PNG" medium="image" />
            <category term="FRAMMENTI"/>

        <updated>2025-01-01T13:14:24+01:00</updated>
            <summary>
                <![CDATA[
                        <img src="https://pianetararo.org/media/posts/14/frammenti.brosssura-2.PNG" alt="" />
                    <p>Da poco disponibile <strong>FRAMMENTI #25</strong> anche su Amazon.it in versione piÃ¹ compatta.</p>

                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                    <p><img src="https://pianetararo.org/media/posts/14/frammenti.brosssura-2.PNG" class="type:primaryImage" alt="" /></p>
                <p>Da poco disponibile <strong>FRAMMENTI #25</strong> anche su Amazon.it in versione piÃ¹ compatta.</p>

<h2><strong>ğŸ““ Disponibile l'edizione in formato brossuraÂ </strong></h2>
<p>Â </p>
<figure class="post__image post__image--center"><img loading="lazy"  src="https://pianetararo.org/media/posts/14/frammenti.brosssura.PNG" alt="" width="363" height="416" sizes="(max-width: 1920px) 100vw, 1920px" srcset="https://pianetararo.org/media/posts/14/responsive/frammenti.brosssura-xs.PNG 640w ,https://pianetararo.org/media/posts/14/responsive/frammenti.brosssura-sm.PNG 768w ,https://pianetararo.org/media/posts/14/responsive/frammenti.brosssura-md.PNG 1024w ,https://pianetararo.org/media/posts/14/responsive/frammenti.brosssura-lg.PNG 1366w ,https://pianetararo.org/media/posts/14/responsive/frammenti.brosssura-xl.PNG 1600w ,https://pianetararo.org/media/posts/14/responsive/frammenti.brosssura-2xl.PNG 1920w"></figure>
<p>Se preferite la <strong>versione rilegata in brossura, </strong>ora potete acquistarla! Questa edizione, manterrÃ  tutta la qualitÃ  dei contenuti di <strong>FRAMMENTI #25</strong>, con una rilegatura piÃ¹ tradizionale.</p>
<p><a href="https://www.amazon.it/FRAMMENTI-25-Pamela-Benedetti/dp/B0DPG4L2NN/ref=sr_1_2?__mk_it_IT=%C3%85M%C3%85%C5%BD%C3%95%C3%91&amp;crid=KYMAD9XVXXIA&amp;dib=eyJ2IjoiMSJ9.t9wRYiv452AhlPvrqf6An_6nPKQggLbmWWjrdjbe6CfWp9YvubMoS0URzm26falnV-JsGPST5KLvCz_BZ-zZHBOhoBINrpbfs2ZEC0LuGDQ3hCLoe0i6ATIGY1esXskQ1h5U3_FN0-BB1AWPlX8QHlCVDOQTSKd4FxIzwcoyx0e5kcNp7nHjoiXTBQwxub5p_Jt-xavqFdks07LV9BC9c_yePzrzo_hOQILXWWVKJ7Y.rdi9V1NTcjffx1NUoG5YhXEB6RO2verJeQ1GV1yQJl8&amp;dib_tag=se&amp;keywords=frammenti+25&amp;nsdOptOutParam=true&amp;qid=1734382345&amp;sprefix=frammenti25%2Caps%2C107&amp;sr=8-2" target="_blank" rel="noopener noreferrer">Acquista su Amazon</a></p>
<p>Â </p>
<p><a href="https://www.lulu.com/it/shop/erica-menozzi-and-fabrizio-lugli-and-pamela-benedetti/frammenti-25/paperback/product-rm8ppj5.html?q=frammenti%2325&amp;page=1&amp;pageSize=4"></a><strong><a href="https://pianetararo.org/frammenti25intro/">Qui troverai maggiori informazioni su FRAMMENTI #25</a></strong></p>
            ]]>
        </content>
    </entry>
    <entry>
        <title>FRAMMENTI #25 Ora Disponibile su Lulu</title>
        <author>
            <name>Pianetararo Associazione Culturale</name>
        </author>
        <link href="https://pianetararo.org/frammenti-25-ora-disponibile-su-lulu/"/>
        <id>https://pianetararo.org/frammenti-25-ora-disponibile-su-lulu/</id>
        <media:content url="https://pianetararo.org/media/posts/11/PXL_20241130_063133590.jpg" medium="image" />
            <category term="FRAMMENTI"/>

        <updated>2024-11-30T07:32:52+01:00</updated>
            <summary>
                <![CDATA[
                        <img src="https://pianetararo.org/media/posts/11/PXL_20241130_063133590.jpg" alt="" />
                    <p>Siamo entusiasti di annunciarvi che <strong>FRAMMENTI #25</strong> Ã¨ finalmente disponibile per l'acquisto online su <strong>Lulu</strong>! La prima edizione Ã¨ arrivata in una versione <strong>rilegata a spirale</strong>, perfetta per chi ama combinare funzionalitÃ  ed estetica.</p>

                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                    <p><img src="https://pianetararo.org/media/posts/11/PXL_20241130_063133590.jpg" class="type:primaryImage" alt="" /></p>
                <p>Siamo entusiasti di annunciarvi che <strong>FRAMMENTI #25</strong> Ã¨ finalmente disponibile per l'acquisto online su <strong>Lulu</strong>! La prima edizione Ã¨ arrivata in una versione <strong>rilegata a spirale</strong>, perfetta per chi ama combinare funzionalitÃ  ed estetica.</p>

<h3><strong>PerchÃ© scegliere la versione a spirale?</strong></h3>
<p>La rilegatura a spirale offre vantaggi, soprattutto per chi desidera un'esperienza di scrittura pratica e piacevole. La versione a spirale permette infatti di aprire completamente il taccuino a 360Â°, lasciando le pagine perfettamente piatte e rendendo piÃ¹ facile annotare, disegnare e prendere appunti senza il fastidio di dover tenere le pagine ferme. Inoltre vi da l'opportunitÃ  di estrarre o strappare le pagine :-) e avere pieno controllo dello spazio su ogni angolo delle pagine. Insomma, Ã¨ la scelta perfetta per chi ama la creativitÃ  senza limiti.</p>
<figure class="post__image post__image--center"><img loading="lazy"  src="https://pianetararo.org/media/posts/11/PXL_20241130_062812942.jpg" alt="" width="498" height="280" sizes="(max-width: 1920px) 100vw, 1920px" srcset="https://pianetararo.org/media/posts/11/responsive/PXL_20241130_062812942-xs.jpg 640w ,https://pianetararo.org/media/posts/11/responsive/PXL_20241130_062812942-sm.jpg 768w ,https://pianetararo.org/media/posts/11/responsive/PXL_20241130_062812942-md.jpg 1024w ,https://pianetararo.org/media/posts/11/responsive/PXL_20241130_062812942-lg.jpg 1366w ,https://pianetararo.org/media/posts/11/responsive/PXL_20241130_062812942-xl.jpg 1600w ,https://pianetararo.org/media/posts/11/responsive/PXL_20241130_062812942-2xl.jpg 1920w"></figure>
<h3><strong>Spedizione e tempistiche...</strong></h3>
<p>I tempi di spedizione che Lulu stimerÃ  in fase di ordine potrebbero risultare piuttosto lunghi, forse perchÃ¨ si tratta di una previsione con partenza dagli USA. <span style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);">Abbiamo sperimentato noi stessi un paio di ordini di prova e, nella realtÃ , i tempi sono risultati molto diversi e decisamente piÃ¹ rapidi rispetto alle stime (in genere meno della metÃ  della previsione) perchÃ¨ ci Ã¨ sempre stato assegnato uno stabilimento situato in Francia. Confidiamo che anche voi possiate sperimentare un esperienza di consegna facile e veloce.Â Â </span></p>
<p><a href="https://www.lulu.com/it/shop/erica-menozzi-and-fabrizio-lugli-and-pamela-benedetti/frammenti-25/paperback/product-rm8ppj5.html?q=frammenti%2325&amp;page=1&amp;pageSize=4"><strong>Acquista ora la tua copia su Lulu</strong></a></p>
<p>Grazie a tutti voi che avete atteso con pazienza. Siamo certi che <strong>FRAMMENTI #25</strong> diventerÃ  un compagno piacevole per il vostro anno di scoperte e ispirazioni!</p>
<p><a href="https://www.lulu.com/it/shop/erica-menozzi-and-fabrizio-lugli-and-pamela-benedetti/frammenti-25/paperback/product-rm8ppj5.html?q=frammenti%2325&amp;page=1&amp;pageSize=4"></a><strong><a href="https://pianetararo.org/frammenti25intro/">Qui troverai maggiori informazioni su FRAMMENTI #25</a></strong></p>
            ]]>
        </content>
    </entry>
</feed>
