<!DOCTYPE html><html lang="it"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Armi di distruzione matematica (Cathy O‚ÄôNeil) - pianetararo</title><meta name="description" content="Esamina il libro di Cathy‚ÄØO‚ÄôNeil su algoritmi ingiusti: esempi reali, effetti sociali e riflessioni su bias, trasparenza e democrazia."><meta name="generator" content="Publii Open-Source CMS for Static Site"><link rel="canonical" href="https://pianetararo.org/armi-di-distruzione-matematica-cathy-oneil/"><link rel="alternate" type="application/atom+xml" href="https://pianetararo.org/feed.xml"><link rel="alternate" type="application/json" href="https://pianetararo.org/feed.json"><meta property="og:title" content="Armi di distruzione matematica (Cathy O‚ÄôNeil)"><meta property="og:image" content="https://pianetararo.org/media/posts/23/Gemini_Generated_Image_mh5uqymh5uqymh5u-2.jfif"><meta property="og:image:width" content="2048"><meta property="og:image:height" content="2048"><meta property="og:site_name" content="pianetararo"><meta property="og:description" content="Esamina il libro di Cathy‚ÄØO‚ÄôNeil su algoritmi ingiusti: esempi reali, effetti sociali e riflessioni su bias, trasparenza e democrazia."><meta property="og:url" content="https://pianetararo.org//armi-di-distruzione-matematica-cathy-oneil/"><meta property="og:type" content="article"><link rel="stylesheet" href="https://pianetararo.org/assets/css/style.css?v=812e0178178abea4ea9399c6007c2ff4"><script type="application/ld+json">{"@context":"http://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://pianetararo.org/armi-di-distruzione-matematica-cathy-oneil/"},"headline":"Armi di distruzione matematica (Cathy O‚ÄôNeil)","datePublished":"2025-05-01T21:27+02:00","dateModified":"2025-06-13T16:17+02:00","image":{"@type":"ImageObject","url":"https://pianetararo.org/media/posts/23/Gemini_Generated_Image_mh5uqymh5uqymh5u-2.jfif","height":2048,"width":2048},"description":"Esamina il libro di Cathy‚ÄØO‚ÄôNeil su algoritmi ingiusti: esempi reali, effetti sociali e riflessioni su bias, trasparenza e democrazia.","author":{"@type":"Person","name":"Pianetararo Associazione Culturale","url":"https://pianetararo.org/authors/pianetararo-associazione-culturale/"},"publisher":{"@type":"Organization","name":"Pianetararo Associazione Culturale","logo":{"@type":"ImageObject","url":"https://pianetararo.org/media/website/PIANETARARO-1-1-1.svg","height":375,"width":375}}}</script><noscript><style>img[loading] {
                    opacity: 1;
                }</style></noscript></head><body class="post-template"><header class="top js-header"><a class="logo" href="https://pianetararo.org/"><img src="https://pianetararo.org/media/website/PIANETARARO-1-1-1.svg" alt="pianetararo" width="375" height="375"></a><nav class="navbar js-navbar"><button class="navbar__toggle js-toggle" aria-label="Menu" aria-haspopup="true" aria-expanded="false"><span class="navbar__toggle-box"><span class="navbar__toggle-inner">Menu</span></span></button><ul class="navbar__menu"><li><a href="https://pianetararo.org/test-2/" title="pianetararo" target="_self">Chi siamo</a></li><li><a href="https://pianetararo.org/traiettorie/" target="_self">TrAIettorie</a></li><li class="has-submenu"><a href="https://pianetararo.org/frammenti25intro/" title="frammenti25" target="_self" aria-haspopup="true">FRAMMENTI#25</a><ul class="navbar__submenu level-2" aria-hidden="true"><li><a href="https://pianetararo.org/frammenti25intro/frammenti25/" target="_self">FRAMMENTI DIGITAL - Come funziona ?</a></li><li><a href="https://pianetararo.org/frammenti25intro/frammenti25/1-il-pozzo-di-san-patrizio/" target="_self">#1 - Gennaio</a></li><li><a href="https://pianetararo.org/frammenti25intro/frammenti25/2-la-rocca-di-calascio/" target="_self">#2 - Febbraio</a></li><li><a href="https://pianetararo.org/frammenti25intro/frammenti25/3-il-palio-delle-rane/" target="_self">#3 - Marzo</a></li><li><a href="https://pianetararo.org/frammenti25intro/frammenti25/4-il-carnevale-di-mamoiada/" target="_self">#4 - Aprile</a></li><li><a href="https://pianetararo.org/frammenti25intro/frammenti25/5-il-castello-di-montebello-e-la-dama-bianca/" target="_self">#5 - Maggio</a></li><li><a href="https://pianetararo.org/frammenti25intro/frammenti25/6/" target="_self">#6 - Giugno</a></li></ul></li><li><a href="https://pianetararo.org/stradora/" title="STRADORA" target="_self">STRADORA</a></li><li><a href="https://pianetararo.org/pensieri/" title="PENSIERI" target="_self">Pensieri</a></li><li><a href="https://pianetararo.org/tags/" target="_self">Tags</a></li></ul></nav></header><main class="post"><article class="content"><div class="hero"><header class="hero__content"><div class="wrapper"><h1>Armi di distruzione matematica (Cathy O‚ÄôNeil)</h1><div class="feed__meta content__meta"><time datetime="2025-05-01T21:27" class="feed__date">1 mag 2025</time></div></div></header><figure class="hero__image"><div class="hero__image-wrapper"><img src="https://pianetararo.org/media/posts/23/Gemini_Generated_Image_mh5uqymh5uqymh5u-2.jfif" loading="eager" height="2048" width="2048" alt=""></div></figure></div><div class="entry-wrapper content__entry"><h4 class="align-center"><strong>Quando l‚Äôalgoritmo diventa ingiusto senza che ce ne accorgiamo</strong></h4><p class="align-center"><em>(Recensione e riflessioni ispirate al libro di Cathy O‚ÄôNeil)</em></p><hr><p>C‚Äô√® un‚Äôillusione di fondo che ancora ci accompagna quando pensiamo ai numeri, alle formule, agli algoritmi: quella di una matematica ‚Äú<em>neutrale</em>‚Äù, distaccata, quasi al di sopra dei pregiudizi umani. <strong>Cathy O‚ÄôNeil</strong>, con il suo libro ‚Äú<strong><a href="https://search.worldcat.org/it/title/1015979069">Armi di distruzione matematica</a></strong>‚Äù, demolisce questa illusione pezzo dopo pezzo, e lo fa con una chiarezza e una passione che davvero costringono a rimettere in discussione tutto ci√≤ che pensavamo di sapere sul potere dei dati.</p><p>Per chi non l‚Äôavesse ancora letto ‚Äì consigliamo vivamente di farlo, magari anche solo per farsi due domande scomode davanti alla prossima richiesta di ‚Äúaccetta i cookie‚Äù ‚Äì O‚ÄôNeil parte proprio dal suo percorso personale. Matematica di formazione, finita tra hedge fund e startup tech, lei per prima aveva creduto che pi√π numeri significasse pi√π giustizia. Invece, a Wall Street, ha visto i modelli matematici gonfiare la bolla dei subprime, amplificare rischi e ingiustizie, e, paradossalmente, fornire una giustificazione ‚Äúscientifica‚Äù a decisioni che poi, di scientifico, avevano ben poco.</p><p>La cosa che colpisce √® come i modelli, una volta usciti dai laboratori e dalle simulazioni accademiche, si siano infilati in ogni anfratto della societ√†. Oggi li troviamo ovunque: dalla scuola ai tribunali, dalle banche alle pubblicit√† che ci inseguono online. E non solo: decidono chi ricever√† un prestito, chi sar√† chiamato per un colloquio, chi verr√† licenziato, chi dovr√† pagare di pi√π per l‚Äôassicurazione auto, chi sar√† sorvegliato da una pattuglia di polizia. Sembra il set di un film distopico, e invece √® la routine di ogni giorno.</p><p>Leggendo O‚ÄôNeil sorge una domanda semplice e spiazzante: <strong>quando un modello matematico diventa pericoloso?</strong> Non basta dire ‚Äúquando sbaglia‚Äù, perch√© anche un modello ben fatto pu√≤ sbagliare di tanto in tanto. Il problema nasce, piuttosto, quando un algoritmo si fa opaco, si applica su vasta scala e produce danni sistemici, colpendo soprattutto chi ha meno mezzi per difendersi. Un po‚Äô come una burocrazia impazzita: fredda, senza volto, incapace di ascoltare. L√¨, s√¨, che diventa un‚Äôarma ‚Äì un‚Äôarma di distruzione matematica.</p><p>Un esempio raccontato ‚Äì che resta in testa come una piccola ingiustizia che nessuno ha voglia di raccontare ‚Äì √® la storia di Sarah Wysocki, insegnante a Washington. Amata da studenti e genitori, si vede licenziata all‚Äôimprovviso perch√© un algoritmo, il famoso IMPACT, l‚Äôaveva bollata come ‚Äútra i peggiori docenti‚Äù. Poco importa se il modello, a monte, era fallato (bastava che l‚Äôanno prima fossero stati truccati i risultati dei test degli studenti per falsare tutto). Poco importa il contesto reale, la storia personale, la voce di chi la conosceva davvero. Il numero parla, il destino si compie. E nessuno che possa contestare, spiegare, nemmeno appellarsi. Cos√¨ nasce il circolo vizioso: pi√π il modello punisce, pi√π la gente impara a ‚Äúgiocare con le regole‚Äù ‚Äì truccando dati, aggirando ostacoli ‚Äì e meno il sistema assomiglia a ci√≤ che dovrebbe valutare.</p><p>Poi ci sono storie pi√π quotidiane ma ugualmente inquietanti, come quella del credit scoring usato nei colloqui di lavoro. Negli Stati Uniti (ma attenzione, la tendenza si sta diffondendo anche altrove), molte aziende ora stanno controllando il punteggio di affidabilit√† creditizia anche prima di assumere. Cos√¨, chi parte gi√† da condizioni svantaggiate ‚Äì magari per colpe non sue ‚Äì si trova chiuso fuori dal mercato del lavoro. Il meccanismo, alla fine, √® quello della doppia pena: povero perch√© non hai credito, senza credito perch√© sei povero, e intanto l‚Äôalgoritmo, come un giudice invisibile, inchioda il futuro a un numero.</p><p>O‚ÄôNeil ci mette in guardia: ogni volta che un modello <strong>decide sulla base di ‚Äúproxy‚Äù</strong> (cio√® sostituti di dati veri, come il codice postale al posto del rischio reale, o il test standardizzato al posto della qualit√† educativa), siamo in zona rossa. Nel baseball, ci ricorda, le statistiche funzionano perch√© ogni dato riflette azioni concrete (un punto segnato, una palla mancata). Ma quando si passa dalla palla al campo sociale, i proxy diventano pericolosi: il codice postale riflette la povert√† e, di riflesso, la razza; i punteggi dei test riflettono il contesto familiare, non solo l‚Äôimpegno. Cos√¨ l‚Äôalgoritmo, travestito da giudice imparziale, diventa lo <strong>specchio dei nostri pregiudizi</strong>.</p><p>Un altro mito che O‚ÄôNeil smonta senza piet√† √® quello del ‚Äúpi√π dati uguale pi√π verit√†‚Äù. Anzi, ci ricorda che <strong>ogni modello √® una semplificazione</strong>, e che senza feedback, senza la capacit√† di correggersi quando sbaglia, rischia solo di cristallizzare gli errori. Prendi le classifiche delle universit√† americane ‚Äì veri e propri totem per studenti e famiglie, al punto che le strategie degli atenei vengono dettate da punteggi decisi da una redazione di rivista. E allora via a gonfiare le statistiche, tagliare i corsi meno redditizi, investire in palestre e campus di lusso per salire in classifica. Il vero senso dell‚Äôeducazione? Quello rischia di perdersi per strada.</p><p>E poi c‚Äô√® il mondo della pubblicit√† online, che di neutrale non ha nulla. O‚ÄôNeil ci porta dietro le quinte delle universit√† ‚Äúfor-profit‚Äù, quelle che campano reclutando studenti fragili ‚Äì madri single, disoccupati, reduci di guerra ‚Äì promettendo miraggi di successo e lasciandoli solo con una montagna di debiti. La pubblicit√† mirata, in questo contesto, diventa una macchina perfetta di propaganda e selezione delle vittime: gli algoritmi scelgono chi colpire sulla base di dati che nessuno controlla, chi sta in cima al sistema incassa, chi sta in basso paga il prezzo, e spesso nemmeno si accorge di essere stato preso di mira da una ‚Äúmacchina‚Äù.</p><p>Le stesse dinamiche si trovano nella giustizia: polizia predittiva, sistemi di valutazione del rischio di recidiva, sorveglianza capillare. Prendi PredPol, il software che promette di ‚Äúprevenire il crimine‚Äù (a <a href="https://www.imdb.com/it/title/tt0181689/">Minority Report</a> ci stiamo arrivando) indirizzando le pattuglie dove il rischio √® pi√π alto. A parole, tutto neutrale. Ma nella pratica, chi viene sorvegliato di pi√π √® chi vive nei quartieri poveri, e cos√¨ pi√π polizia produce pi√π segnalazioni, che producono pi√π dati, che rafforzano la sorveglianza. Il rischio di automantenere un pregiudizio ‚Äì razziale, sociale ‚Äì √® enorme. E peggio ancora, spesso la persona non sa nemmeno di essere giudicata da un algoritmo; non pu√≤ difendersi, non pu√≤ discutere, non pu√≤ nemmeno sapere cosa l‚Äôha condannata. √à una sorta di tribunale segreto, in cui l‚Äôaccusato non pu√≤ parlare.</p><p>Nel lavoro, la musica non cambia. Dai test di personalit√† automatizzati per le assunzioni (che finiscono spesso per discriminare chi ha storie di malattia o semplicemente risponde fuori dagli schemi) ai software che programmano i turni di lavoro nei negozi, l‚Äôalgoritmo diventa il nuovo portiere, spesso pi√π severo e meno trasparente di quelli in carne e ossa. O‚ÄôNeil racconta il caso di Kyle Behm, scartato sistematicamente da supermercati perch√© i test psicometrici lo bollavano come ‚Äúinadatto‚Äù. Nessuno che possa spiegare o correggere. Eppure, dietro la facciata dell‚Äôimparzialit√†, si nascondono nuove forme di esclusione sociale: chi √® gi√† fragile rischia di rimanere tale a tempo indeterminato, chi √® diverso dal ‚Äúmodello vincente‚Äù dell‚Äôazienda viene messo da parte senza diritto di replica.</p><p>Interessante √® notare come queste forme di automazione colpiscano soprattutto i pi√π deboli: i lavori a basso salario, i candidati meno istruiti, le minoranze. La promessa di una valutazione scientifica ed equa svanisce se il sistema premia solo chi gi√† parte avvantaggiato. E chi pensa che basti ‚Äúavere il giusto profilo‚Äù per essere al sicuro, forse dovrebbe chiedersi quanto sia giusto vivere in un mondo in cui il prossimo ‚Äúupdate‚Äù dell‚Äôalgoritmo potrebbe ribaltare tutto senza preavviso.</p><p>Nella sua opera O‚ÄôNeil illustra come sul posto di lavoro, poi, la logica dell‚Äôottimizzazione continua porta ad esempio a turni spezzettati, orari impossibili da conciliare con la vita familiare o stress cronico. Il termine ‚Äúclopening‚Äù, usato per chi fa chiusura serale e apertura mattutina nello stesso locale, √® ormai familiare a molti commessi e camerieri. Tutto questo per inseguire l‚Äôefficienza massima ‚Äì ogni minuto, ogni ora deve produrre qualcosa ‚Äì ma chi paga davvero sono le persone, che vedono evaporare la possibilit√† di organizzarsi, di prendersi cura dei figli, di vivere serenamente. I sistemi che dovrebbero aiutare finiscono per trasformarsi in strumenti di controllo e di precariet√†.</p><p>Anche i "colletti bianchi" non sono immuni: software come quelli sviluppati da Cataphora (che analizzano email e scambi digitali per mappare l‚Äôinnovazione e decidere chi licenziare) rischiano di ridurre la ricchezza umana a una manciata di dati quantitativi. E se il tuo contributo non si vede nel grafico, poco importa: puoi essere tagliato senza che nessuno sappia davvero cosa hai portato all‚Äôazienda. La tentazione di ‚Äú<strong>scaricare la colpa sull‚Äôalgoritmo</strong>‚Äù √® forte, e per chi subisce il danno, √® quasi impossibile reagire.</p><p>A livello di societ√†, come ci racconta O‚ÄôNeil nel contesto statunitense, il meccanismo si ripete anche nel settore finanziario. Il credito, un tempo assegnato a discrezione di funzionari spesso prevenuti, √® stato ‚Äúdemocratizzato‚Äù dal punteggio FICO, basato su dati oggettivi. Un progresso, finch√© non √® arrivata la nuova generazione di ‚Äúe-scores‚Äù, punteggi opachi costruiti su dati aggregati dai social, dagli acquisti online, dalla cronologia web. <strong>Nessuno sa davvero come funzionino</strong>, nessuno pu√≤ correggere errori, e spesso si finisce per essere valutati sulla base di variabili che non hanno nulla a che vedere con il proprio merito individuale. Sembra quasi che il vecchio ‚Äúredlining‚Äù sia tornato in versione digitale: se vivi in un certo quartiere, se hai certi amici, se non compri certi prodotti, rischi di essere escluso senza saperlo.</p><p>E mentre in Europa qualcosa si muove (il GDPR offre alcune tutele, bench√© perfettibili), negli Stati Uniti il mercato dei dati personali √® ancora un far west: aziende che comprano e vendono profili comportamentali senza che tu possa dire la tua, errori che si propagano nei sistemi senza possibilit√† di rettifica, discriminazioni che passano inosservate perch√© ‚Äúautomatiche‚Äù. O‚ÄôNeil mostra con esempi concreti come le conseguenze siano spesso grottesche: chi paga l‚Äôassicurazione auto pu√≤ trovarsi premi maggiorati non per come guida, ma per il proprio credit score. Se sei povero, paghi di pi√π, e la spirale della povert√† si rafforza. Oppure pensiamo ai sensori di fitness e ai programmi di wellness aziendale: strumenti pensati per migliorare la salute finiscono per fornire alle aziende un tesoro di dati intimi, che potrebbero diventare un domani criteri di selezione per assunzioni e promozioni. Un ‚Äúhealth score‚Äù troppo basso e rischi di essere scartato, magari senza nemmeno saperlo.</p><p>C‚Äô√® poi il tema della cittadinanza e della democrazia. S√¨, perch√© gli algoritmi non si fermano alla sfera privata: influenzano ci√≤ che vediamo nei feed dei social, quali notizie ci raggiungono, come vengono indirizzate le campagne elettorali. Il caso dell‚Äôesperimento di Facebook ‚Äì mostrare o meno il box ‚Äú<em>Hai votato?</em>‚Äù agli utenti, spingendo (scientificamente!) migliaia di persone in pi√π alle urne ‚Äì √® solo la punta dell‚Äôiceberg. Gia oggi viviamo gli effetti delle <strong>distorsioni </strong>sempre maggiorni a fini politici per mezzo di questi strumenti. Se la personalizzazione delle informazioni portasse a una societ√† di ‚Äú<strong>bolle informative</strong>‚Äù in cui ciascuno vive nella propria realt√† parallela? Il rischio che la democrazia stessa sia manipolata da logiche algoritmiche invisibili √® reale, e O‚ÄôNeil suona l‚Äôallarme senza mezzi termini.</p><p>A questo punto, viene spontaneo chiedersi: <em>‚ÄúTutto questo riguarda davvero anche l‚ÄôItalia, oppure √® solo roba d‚Äôoltreoceano?‚Äù</em> Siamo meno avanti di Stati Uniti e Cina nell‚Äôautomazione selvaggia delle decisioni, ma la nostra quotidianit√† sta gi√† da tempo sperimentando forme pi√π o meno occulte di <em data-start="451" data-end="475">‚Äú<strong>giudizio algoritmico</strong>‚Äù</em>.</p><p>Prendiamo il caso emblematico dell‚ÄôINPS e del cosiddetto ‚Äúalgoritmo dei navigator‚Äù durante il Reddito di Cittadinanza: il sistema, pensato per abbinare offerte di lavoro ai beneficiari, ha mostrato limiti enormi nel valutare profili e opportunit√†, spesso producendo risultati casuali o insensati, tanto che la Corte dei Conti (2023) ha evidenziato le lacune del matching automatico nelle sue relazioni.</p><p><span style="font-weight: 400;">Sempre nel settore del lavoro una vicenda esemplare √® quella di Deliveroo. La piattaforma di food delivery utilizzava un algoritmo (denominato </span>Frank<span style="font-weight: 400;">) per gestire le prenotazioni delle sessioni di lavoro dei rider, assegnando priorit√† in base a un punteggio reputazionale di </span>‚Äúaffidabilit√†‚Äù e ‚Äúpartecipazione‚Äù<span style="font-weight: 400;">. Il funzionamento preciso del modello era opaco, l‚Äôazienda non ha divulgato i criteri, ricostruiti solo grazie alle testimonianze dei rider. In pratica, il sistema penalizzava in modo uniforme qualsiasi cancellazione tardiva di un turno, </span>senza considerare i motivi<span style="font-weight: 400;">. Ci√≤ significava che un rider veniva declassato nel ranking anche se rinunciava a una consegna per causa di forza maggiore, ad esempio sciopero, guasto, incidente o un malessere. Trattando allo stesso modo assenze giustificate e non, l‚Äôalgoritmo finiva per </span><strong>discriminare indirettamente</strong><span style="font-weight: 400;"> i lavoratori riducendo le loro opportunit√† di prenotare le fasce orarie pi√π redditizie. Nel 2020 il Tribunale di Bologna ha riconosciuto questo effetto distorsivo</span><span style="font-weight: 400;">¬†condannando Deliveroo per condotta illegittima nei confronti dei rider.</span></p><p><span style="font-weight: 400;">Anche nel mondo della scuola italiana si √® verificato un caso tipico di algoritmo dagli effetti perversi. Nel 2016, a seguito della riforma detta ‚ÄúBuona Scuola‚Äù, il Ministero dell‚ÄôIstruzione ha utilizzato un sistema automatizzato per gestire la </span>mobilit√† di oltre 100 mila insegnanti<span style="font-weight: 400;"> su tutto il territorio nazionale. L‚Äôobiettivo era assegnare le sedi in base a punteggi di servizio e preferenze, ma il risultato √® stato caotico: </span>migliaia di docenti con punteggi alti sono stati trasferiti lontano da casa<span style="font-weight: 400;">, spesso dal Sud al Nord, mentre cattedre pi√π vicine venivano attribuite a colleghi con punteggi inferiori. L‚Äô‚Äúalgoritmo impazzito‚Äù, come fu ribattezzato, presentava errori e criteri oscuri, generando proteste diffuse per le </span>ingiustizie e disagi familiari<span style="font-weight: 400;"> causati. In seguito, una sentenza del TAR del Lazio ha censurato duramente quel sistema, definendolo un </span><strong>‚Äúmetodo orwelliano‚Äù</strong><span style="font-weight: 400;"> in cui una decisione cos√¨ delicata era lasciata a un algoritmo non supervisionato. I giudici hanno evidenziato che il software operava in modo </span>confuso e lacunoso<span style="font-weight: 400;">, basato su dati inseriti male, e soprattutto che </span>non rispettava il merito.</p><p>In campo finanziario, gli algoritmi di credit scoring ‚Äì usati da banche e finanziarie per decidere a chi concedere un prestito e a quali condizioni ‚Äì possono generare <strong data-start="8263" data-end="8292">discriminazioni indirette</strong> verso determinate categorie. In Italia sono emerse evidenze di bias soprattutto nei confronti dei clienti immigrati. Studi recenti condotti anche dalla Banca d‚ÄôItalia hanno rilevato che, <em>a parit√† di caratteristiche socio-economiche</em>, un richiedente straniero ha una probabilit√† di vedersi rifiutare un mutuo pi√π alta di circa 2-3 punti percentuali rispetto a un pari profilo italiano. Inoltre, anche quando il finanziamento viene erogato o viene dimostrata una storia creditizia solida, ai clienti non nativi spesso tocca un tasso d‚Äôinteresse leggermente superiore (in media pochi decimali in pi√π) rispetto ai mutuatari italiani. Questa disparit√† suggerisce che gli algoritmi utilizzati incorporano variabili o dati proxy correlati con l‚Äôorigine etnica/nazionale.</p><p><span style="font-weight: 400;">Anche nella pubblica amministrazione italiana si stanno affacciando sistemi di </span><strong>punteggio algoritmico dei cittadini</strong><span style="font-weight: 400;"> che hanno sollevato dibattito. Ispirandosi (inconsapevolmente) al discusso modello di ‚Äúcredito sociale‚Äù cinese, alcuni enti locali hanno proposto di premiare con punti i comportamenti virtuosi dei residenti. Ad esempio </span>Roma<span style="font-weight: 400;"> ha testato lo </span><i><span style="font-weight: 400;">Smart Citizen Wallet</span></i><span style="font-weight: 400;">, un portafoglio digitale dove i cittadini accumulano crediti se usano mezzi pubblici o riciclano correttamente; il </span>Comune di Bologna<span style="font-weight: 400;"> ha ipotizzato un sistema simile di </span>incentivi per chi adotta stili di vita ‚Äúgreen‚Äù<span style="font-weight: 400;">, dalla mobilit√† sostenibile alla differenziata. Il caso pi√π estremo √® per√≤ quello di </span>Fidenza<span style="font-weight: 400;">: qui l‚Äôamministrazione ha introdotto un meccanismo a punti per gli inquilini delle </span>case popolari<span style="font-weight: 400;">, valutandone il comportamento sociale. I destinatari degli alloggi ottengono bonus o malus e </span>possono persino essere<strong> sfrattati se perdono tutti i punti</strong><span style="font-weight: 400;"> accumulati negativamente. L‚Äôintento dichiarato √® responsabilizzare e incoraggiare il rispetto delle regole condominiali, ma una simile misura rischia di </span>colpire proprio i pi√π fragili<span style="font-weight: 400;">. Iniziative del genere infatti </span>premiano chi pu√≤ permettersi comportamenti ‚Äúvirtuosi‚Äù.<strong>¬†</strong>Senza un opportuno <strong data-start="11889" data-end="11913">contesto di supporto</strong> (migliori trasporti pubblici, politiche sociali, dialogo con i cittadini), questo ‚Äú<strong>rating civico</strong>‚Äù finisce per amplificare le disuguaglianze: per di pi√π raccogliendo una mole di dati personali sui cittadini. Non sorprende quindi che il Garante Privacy e varie associazioni abbiano espresso allarme su questi progetti, evidenziando il rischio di derive antidemocratiche e chiedendone una revisione prima di una loro eventuale attuazione su larga scala.</p><p>A leggere tutto questo, verrebbe da cedere allo sconforto. E invece il libro di O‚ÄôNeil √®, paradossalmente, un invito a reagire. Non a demonizzare la tecnologia, sia chiaro ‚Äì lei stessa, da matematica, ama la disciplina e sa quanto bene pu√≤ fare quando √® usata con consapevolezza e responsabilit√†. Il punto √® non delegare alla matematica (o meglio, a chi la scrive in codice) il compito di decidere cosa √® giusto e cosa no. Serve trasparenza, s√¨, ma serve soprattutto <strong>coscienza collettiva</strong>. Perch√© ogni algoritmo <strong>nasce da scelte umane</strong> ‚Äì da un‚Äôidea di successo, da una definizione di ‚Äúmerito‚Äù, da una scala di valori. Se quei valori sono mal definiti o ciechi rispetto alle diversit√† reali, allora anche il modello pi√π sofisticato diventa una gabbia, e la matematica smette di essere un‚Äôamica della giustizia.</p><p>Forse √® il momento di pensare a una <strong>‚Äúdeontologia degli algoritmi‚Äù</strong>, come suggerisce O‚ÄôNeil: un codice etico per chi scrive, addestra, implementa sistemi che incidono sulle vite delle persone. Immagina se ogni data scientist dovesse giurare, come un medico, di ‚Äúnon nuocere‚Äù. S√¨, sembra idealistico, ma l‚Äôalternativa √® rassegnarsi a una societ√† in cui nessuno sa davvero perch√© le cose gli capitano ‚Äì se hai ottenuto un mutuo, se sei stato scartato da un lavoro, se hai ricevuto una pubblicit√† mirata proprio nel giorno di maggiore fragilit√†.</p><p>Certo, la soluzione non pu√≤ essere solo individuale. O‚ÄôNeil fa notare che senza organismi di controllo pubblici ‚Äì senza ‚Äúauditor degli algoritmi‚Äù, senza regole chiare su cosa si pu√≤ e non si pu√≤ automatizzare ‚Äì rischiamo di inseguire i problemi senza mai affrontarli davvero. L‚ÄôEuropa con l'AI Act si sta provando ad andare in questa direzione, ma sarebbe ora di pensare a istituzioni che vigilino sui modelli ad alto impatto sociale con la stessa seriet√† con cui si controllano i farmaci o le banche.</p><p>Una nota finale, ma che finale non √®: l‚Äôarma di distruzione matematica, in fondo, non √® altro che la matematica privata del suo feedback umano, cieca al contesto, sorda ai casi particolari, indifferente alla storia. Per renderla innocua ‚Äì o meglio, per trasformarla in un‚Äôalleata ‚Äì <strong>serve reintegrare nel processo decisionale le persone</strong>, le loro voci, la possibilit√† di spiegare e correggere. Non tutto pu√≤ essere ridotto a numero, e la democrazia si misura anche da quanto riesce a difendere questa irriducibile complessit√†.</p><p>Non ci sono risposte facili, ma c‚Äô√® una certezza: <strong>il dibattito va portato fuori dai circoli degli esperti, reso materia di educazione civica e di conversazione pubblica</strong>. Gli algoritmi sono troppo importanti per essere lasciati solo ai tecnici, troppo pervasivi per essere ignorati. Se non vogliamo che diventino la nuova burocrazia inespugnabile del XXI secolo, serve un nuovo patto tra scienza, societ√† e diritti umani. E serve subito.</p><p class="align-center">¬´<em>i modelli non sono altro che opinioni scritte nel linguaggio della matematica</em>¬ª cit.</p><p>Forse la vera domanda non √® se gli algoritmi siano ‚Äú<em>buoni</em>‚Äù o ‚Äú<em>cattivi</em>‚Äù, ma se siamo ancora capaci ‚Äì come societ√† ‚Äì di discuterne insieme, di <strong>pretendere che restino strumenti al nostro servizio</strong>, e non il contrario. O‚ÄôNeil con le sue indagini accende la luce in una stanza che sembrava perfettamente in ordine, e ci mostra la polvere sotto il tappeto. Ora, a noi decidere cosa farne.¬†</p><hr><p>Questo post √® parte della rubrica <strong><a href="https://pianetararo.org/traiettorie/">TrAIettorie</a></strong> di cui potete trovare l'indice completo <a href="https://pianetararo.org/tags/traiettorie/">qui</a>.</p></div><footer class="content__footer"><div class="entry-wrapper"><div class="content__actions"><ul class="content__tag"><li><a href="https://pianetararo.org/tags/traiettorie/">TRAIETTORIE</a></li></ul><div class="content__share"><button class="btn--icon content__share-button js-content__share-button"><svg width="20" height="20" aria-hidden="true"><use xlink:href="https://pianetararo.org/assets/svg/svg-map.svg#share"></use></svg> <span>Share It</span></button><div class="content__share-popup js-content__share-popup"><a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fpianetararo.org%2Farmi-di-distruzione-matematica-cathy-oneil%2F" class="js-share facebook" rel="nofollow noopener noreferrer"><svg class="icon" aria-hidden="true" focusable="false"><use xlink:href="https://pianetararo.org/assets/svg/svg-map.svg#facebook"/></svg> <span>Facebook</span> </a><a href="https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fpianetararo.org%2Farmi-di-distruzione-matematica-cathy-oneil%2F" class="js-share linkedin" rel="nofollow noopener noreferrer"><svg class="icon" aria-hidden="true" focusable="false"><use xlink:href="https://pianetararo.org/assets/svg/svg-map.svg#linkedin"/></svg> <span>LinkedIn</span> </a><a href="https://api.whatsapp.com/send?text=Armi%20di%20distruzione%20matematica%20(Cathy%20O%E2%80%99Neil) https%3A%2F%2Fpianetararo.org%2Farmi-di-distruzione-matematica-cathy-oneil%2F" class="js-share whatsapp" rel="nofollow noopener noreferrer"><svg class="icon" aria-hidden="true" focusable="false"><use xlink:href="https://pianetararo.org/assets/svg/svg-map.svg#whatsapp"/></svg> <span>WhatsApp</span></a></div></div></div></div></footer></article></main><footer class="footer"><div class="wrapper"><div class="footer__copyright"><div class="block-footer-fl" style="width: 100%; height: 100%; , max-width: 100%;"><p class="align-center" style="font-size: x-small;"><span style="color: #44684b;">Pianetararo associazione culturale</span><br><span style="color: #44684b;">CF: 04015870365</span><br><span style="color: #44684b;">info@pianetararo.org</span><br><span style="color: #44684b;">Pianetararo √® un associazione senza scopo di lucro e partecipa al programma "Google for Non profits".</span></p><p class="align-center" style="font-size: x-small;"><span style="color: #44684b;"><a href="https://pianetararo.org/privacy-and-cookie/" title="Privacy &amp; Cookie policy" style="color: #44684b;">Privacy &amp; Cookie policy</a></span></p></div></div><button onclick="backToTopFunction()" id="backToTop" class="footer__bttop" aria-label="Back to top" title="Back to top"><svg width="20" height="20"><use xlink:href="https://pianetararo.org/assets/svg/svg-map.svg#toparrow"/></svg></button></div></footer><script defer="defer" src="https://pianetararo.org/assets/js/scripts.min.js?v=700105c316933a8202041b6415abb233"></script><script>window.publiiThemeMenuConfig={mobileMenuMode:'sidebar',animationSpeed:300,submenuWidth: 'auto',doubleClickTime:500,mobileMenuExpandableSubmenus:true,relatedContainerForOverlayMenuSelector:'.top'};</script><script>var images = document.querySelectorAll('img[loading]');
        for (var i = 0; i < images.length; i++) {
            if (images[i].complete) {
                images[i].classList.add('is-loaded');
            } else {
                images[i].addEventListener('load', function () {
                    this.classList.add('is-loaded');
                }, false);
            }
        }</script><div class="pcb" data-behaviour="badge" data-behaviour-link="#cookie-settings" data-revision="1" data-config-ttl="90" data-debug-mode="false"><div role="dialog" aria-modal="true" aria-hidden="true" aria-labelledby="pcb-title" aria-describedby="pcb-txt" class="pcb__banner"><div class="pcb__inner"><div id="pcb-title" role="heading" aria-level="2" class="pcb__title">This website uses cookies</div><div id="pcb-txt" class="pcb__txt">Select which cookies to opt-in to via the checkboxes below; our website uses cookies to examine site traffic and user activity while on our site, for marketing, and to provide social media functionality. <a href="https://pianetararo.org/privacy-and-cookie/">More details...</a></div><div class="pcb__buttons"><button type="button" class="pcb__btn pcb__btn--solid pcb__btn--accept">Accept all</button></div></div></div><button class="pcb__badge" aria-label="Cookie Policy" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" width="40" height="40" viewBox="0 0 23 23" fill="currentColor"><path d="M21.41 12.71c-.08-.01-.15 0-.22 0h-.03c-.03 0-.05 0-.08.01-.07 0-.13.01-.19.04-.52.21-1.44.19-2.02-.22-.44-.31-.65-.83-.62-1.53a.758.758 0 0 0-.27-.61.73.73 0 0 0-.65-.14c-1.98.51-3.49.23-4.26-.78-.82-1.08-.73-2.89.24-4.49.14-.23.14-.52 0-.75a.756.756 0 0 0-.67-.36c-.64.03-1.11-.1-1.31-.35-.19-.26-.13-.71-.01-1.29.04-.18.06-.38.03-.59-.05-.4-.4-.7-.81-.66C5.1 1.54 1 6.04 1 11.48 1 17.28 5.75 22 11.6 22c5.02 0 9.39-3.54 10.39-8.42.08-.4-.18-.78-.58-.87Zm-9.81 7.82c-5.03 0-9.12-4.06-9.12-9.06 0-4.34 3.05-8 7.25-8.86-.08.7.05 1.33.42 1.81.24.32.66.67 1.38.84-.76 1.86-.65 3.78.36 5.11.61.81 2.03 2 4.95 1.51.18.96.71 1.54 1.18 1.87.62.43 1.38.62 2.1.62.05 0 .09 0 .13-.01-1.23 3.64-4.7 6.18-8.64 6.18ZM13 17c0 .55-.45 1-1 1s-1-.45-1-1 .45-1 1-1 1 .45 1 1Zm5.29-12.3a.99.99 0 0 1-.29-.71c0-.55.45-.99 1-.99a1 1 0 0 1 .71.3c.19.19.29.44.29.71 0 .55-.45.99-1 .99a1 1 0 0 1-.71-.3ZM9 13.5c0 .83-.67 1.5-1.5 1.5S6 14.33 6 13.5 6.67 12 7.5 12s1.5.67 1.5 1.5Zm3.25.81a.744.744 0 0 1-.06-1.05c.28-.32.75-.34 1.05-.06.31.28.33.75.05 1.06-.15.16-.35.25-.56.25-.18 0-.36-.06-.5-.19ZM8.68 7.26c.41.37.44 1 .07 1.41-.2.22-.47.33-.75.33a.96.96 0 0 1-.67-.26c-.41-.37-.44-1-.07-1.41.37-.42 1-.45 1.41-.08Zm11.48 1.88c.18-.19.52-.19.7 0 .05.04.09.1.11.16.03.06.04.12.04.19 0 .13-.05.26-.15.35-.09.1-.22.15-.35.15s-.26-.05-.35-.15a.355.355 0 0 1-.11-.16.433.433 0 0 1-.04-.19c0-.13.05-.26.15-.35Zm-4.93-1.86a.75.75 0 1 1 1.059-1.06.75.75 0 0 1-1.059 1.06Z"/></svg></button></div><script>(function(win) {
    if (!document.querySelector('.pcb')) {
        return;
    }

    var cbConfig = {
        behaviour: document.querySelector('.pcb').getAttribute('data-behaviour'),
        behaviourLink: document.querySelector('.pcb').getAttribute('data-behaviour-link'),
        revision: document.querySelector('.pcb').getAttribute('data-revision'),
        configTTL: parseInt(document.querySelector('.pcb').getAttribute('data-config-ttl'), 10),
        debugMode: document.querySelector('.pcb').getAttribute('data-debug-mode') === 'true',
        initialState: null,
        initialLsState: null,
        previouslyAccepted: []
    };

    var cbUI = {
        wrapper: document.querySelector('.pcb'),
        banner: {
            element: null,
            btnAccept: null,
            btnReject: null,
            btnConfigure: null
        },
        popup: {
            element: null,
            btnClose: null,
            btnSave: null,
            btnAccept: null,
            btnReject: null,
            checkboxes: null,
        },
        overlay: null,
        badge: null,
        blockedScripts: document.querySelectorAll('script[type^="gdpr-blocker/"]'),
        triggerLinks: cbConfig.behaviourLink ? document.querySelectorAll('a[href*="' + cbConfig.behaviourLink + '"]') : null
    };

    function initUI () {
        // setup banner elements
        cbUI.banner.element = cbUI.wrapper.querySelector('.pcb__banner');
        cbUI.banner.btnAccept = cbUI.banner.element.querySelector('.pcb__btn--accept');
        cbUI.banner.btnReject = cbUI.banner.element.querySelector('.pcb__btn--reject');
        cbUI.banner.btnConfigure = cbUI.banner.element.querySelector('.pcb__btn--configure');

        // setup popup elements
        if (cbUI.wrapper.querySelector('.pcb__popup')) {
            cbUI.popup.element = cbUI.wrapper.querySelector('.pcb__popup');
            cbUI.popup.btnClose = cbUI.wrapper.querySelector('.pcb__popup__close');
            cbUI.popup.btnSave = cbUI.popup.element.querySelector('.pcb__btn--save');
            cbUI.popup.btnAccept = cbUI.popup.element.querySelector('.pcb__btn--accept');
            cbUI.popup.btnReject = cbUI.popup.element.querySelector('.pcb__btn--reject');
            cbUI.popup.checkboxes = cbUI.popup.element.querySelector('input[type="checkbox"]');
            // setup overlay
            cbUI.overlay = cbUI.wrapper.querySelector('.pcb__overlay');
        }

        cbUI.badge = cbUI.wrapper.querySelector('.pcb__badge');

        if (cbConfig.behaviour.indexOf('link') > -1) {
            for (var i = 0; i < cbUI.triggerLinks.length; i++) {
                cbUI.triggerLinks[i].addEventListener('click', function(e) {
                    e.preventDefault();
                    showBannerOrPopup();
                });
            }
        }
    }

    function initState () {
        var lsKeyName = getConfigName();
        var currentConfig = localStorage.getItem(lsKeyName);
        var configIsFresh = checkIfConfigIsFresh();

        if (!configIsFresh || currentConfig === null) {
            if (cbConfig.debugMode) {
                console.log('üç™ Config not found, or configuration expired');
            }

            if (window.publiiCBGCM) {
                gtag('consent', 'default', {
                    'ad_storage': window.publiiCBGCM.defaultState.ad_storage ? 'granted' : 'denied',
                    'ad_personalization': window.publiiCBGCM.defaultState.ad_personalization ? 'granted' : 'denied',
                    'ad_user_data': window.publiiCBGCM.defaultState.ad_user_data ? 'granted' : 'denied',
                    'analytics_storage': window.publiiCBGCM.defaultState.analytics_storage ? 'granted' : 'denied',
                    'personalization_storage': window.publiiCBGCM.defaultState.personalization_storage ? 'granted' : 'denied',
                    'functionality_storage': window.publiiCBGCM.defaultState.functionality_storage ? 'granted' : 'denied',
                    'security_storage': window.publiiCBGCM.defaultState.security_storage ? 'granted' : 'denied'
                });  
                
                if (cbConfig.debugMode) {
                    console.log('üç™ GCMv2 DEFAULT STATE: ' + JSON.stringify({
                        'ad_storage': window.publiiCBGCM.defaultState.ad_storage ? 'granted' : 'denied',
                        'ad_personalization': window.publiiCBGCM.defaultState.ad_personalization ? 'granted' : 'denied',
                        'ad_user_data': window.publiiCBGCM.defaultState.ad_user_data ? 'granted' : 'denied',
                        'analytics_storage': window.publiiCBGCM.defaultState.analytics_storage ? 'granted' : 'denied',
                        'personalization_storage': window.publiiCBGCM.defaultState.personalization_storage ? 'granted' : 'denied',
                        'functionality_storage': window.publiiCBGCM.defaultState.functionality_storage ? 'granted' : 'denied',
                        'security_storage': window.publiiCBGCM.defaultState.security_storage ? 'granted' : 'denied'
                    }));
                }
            }

            showBanner();
        } else if (typeof currentConfig === 'string') {
            if (cbConfig.debugMode) {
                console.log('üç™ Config founded');
            }

            cbConfig.initialLsState = currentConfig.split(',');

            if (window.publiiCBGCM) {
                gtag('consent', 'default', {
                    'ad_storage': getDefaultConsentState(currentConfig, 'ad_storage'),
                    'ad_personalization': getDefaultConsentState(currentConfig, 'ad_personalization'),
                    'ad_user_data': getDefaultConsentState(currentConfig, 'ad_user_data'),
                    'analytics_storage': getDefaultConsentState(currentConfig, 'analytics_storage'),
                    'personalization_storage': getDefaultConsentState(currentConfig, 'personalization_storage'),
                    'functionality_storage': getDefaultConsentState(currentConfig, 'functionality_storage'),
                    'security_storage': getDefaultConsentState(currentConfig, 'security_storage')
                });
                
                if (cbConfig.debugMode) {
                    console.log('üç™ GCMv2 DEFAULT STATE: ' + JSON.stringify({
                        'ad_storage': getDefaultConsentState(currentConfig, 'ad_storage'),
                        'ad_personalization': getDefaultConsentState(currentConfig, 'ad_personalization'),
                        'ad_user_data': getDefaultConsentState(currentConfig, 'ad_user_data'),
                        'analytics_storage': getDefaultConsentState(currentConfig, 'analytics_storage'),
                        'personalization_storage': getDefaultConsentState(currentConfig, 'personalization_storage'),
                        'functionality_storage': getDefaultConsentState(currentConfig, 'functionality_storage'),
                        'security_storage': getDefaultConsentState(currentConfig, 'security_storage')
                    }));
                }
            }

            showBadge();

            if (cbUI.popup.element) {
                var allowedGroups = currentConfig.split(',');
                var checkedCheckboxes = cbUI.popup.element.querySelectorAll('input[type="checkbox"]:checked');

                for (var j = 0; j < checkedCheckboxes.length; j++) {
                    var name = checkedCheckboxes[j].getAttribute('data-group-name');

                    if (name && name !== '-' && allowedGroups.indexOf(name) === -1) {
                        checkedCheckboxes[j].checked = false;
                    }
                }

                for (var i = 0; i < allowedGroups.length; i++) {
                    var checkbox = cbUI.popup.element.querySelector('input[type="checkbox"][data-group-name="' + allowedGroups[i] + '"]');

                    if (checkbox) {
                        checkbox.checked = true;
                    }

                    allowCookieGroup(allowedGroups[i]);
                }
            }
        }

        setTimeout(function () {
            cbConfig.initialState = getInitialStateOfConsents();
        }, 0);
    }

    function checkIfConfigIsFresh () {
        var lastConfigSave = localStorage.getItem('publii-gdpr-cookies-config-save-date');

        if (lastConfigSave === null) {
            return false;
        }

        lastConfigSave = parseInt(lastConfigSave, 10);

        if (lastConfigSave === 0) {
            return true;
        }

        if (+new Date() - lastConfigSave < cbConfig.configTTL * 24 * 60 * 60 * 1000) {
            return true;
        }

        return false;
    }

    function getDefaultConsentState (currentConfig, consentGroup) {
        let configGroups = currentConfig.split(',');

        for (let i = 0; i < configGroups.length; i++) {
            let groupName = configGroups[i];
            let group = window.publiiCBGCM.groups.find(group => group.cookieGroup === groupName);

            if (group && group[consentGroup]) {
                return 'granted';
            }
        }  
        
        if (window.publiiCBGCM.defaultState[consentGroup]) {
            return 'granted'; 
        }
        
        return 'denied';
    }

    function initBannerEvents () {
        cbUI.banner.btnAccept.addEventListener('click', function (e) {
            e.preventDefault();
            acceptAllCookies('banner');
            showBadge();
        }, false);

        if (cbUI.banner.btnReject) {
            cbUI.banner.btnReject.addEventListener('click', function (e) {
                e.preventDefault();
                rejectAllCookies();
                showBadge();
            }, false);
        }

        if (cbUI.banner.btnConfigure) {
            cbUI.banner.btnConfigure.addEventListener('click', function (e) {
                e.preventDefault();
                hideBanner();
                showAdvancedPopup();
                showBadge();
            }, false);
        }
    }

    function initPopupEvents () {
        if (!cbUI.popup.element) {
            return;
        }

        cbUI.overlay.addEventListener('click', function (e) {
            hideAdvancedPopup();
        }, false);

        cbUI.popup.element.addEventListener('click', function (e) {
            e.stopPropagation();
        }, false);

        cbUI.popup.btnAccept.addEventListener('click', function (e) {
            e.preventDefault();
            acceptAllCookies('popup');
        }, false);

        cbUI.popup.btnReject.addEventListener('click', function (e) {
            e.preventDefault();
            rejectAllCookies();
        }, false);

        cbUI.popup.btnSave.addEventListener('click', function (e) {
            e.preventDefault();
            saveConfiguration();
        }, false);

        cbUI.popup.btnClose.addEventListener('click', function (e) {
            e.preventDefault();
            hideAdvancedPopup();
        }, false);
    }

    function initBadgeEvents () {
        if (!cbUI.badge) {
            return;
        }

        cbUI.badge.addEventListener('click', function (e) {
            showBannerOrPopup();
        }, false);
    }

    initUI();
    initState();
    initBannerEvents();
    initPopupEvents();
    initBadgeEvents();

    /**
     * API
     */
    function addScript (src, inline) {
        var newScript = document.createElement('script');

        if (src) {
            newScript.setAttribute('src', src);
        }

        if (inline) {
            newScript.text = inline;
        }

        document.body.appendChild(newScript);
    }

    function allowCookieGroup (allowedGroup) {
        var scripts = document.querySelectorAll('script[type="gdpr-blocker/' + allowedGroup + '"]');
        cbConfig.previouslyAccepted.push(allowedGroup);
    
        for (var j = 0; j < scripts.length; j++) {
            addScript(scripts[j].src, scripts[j].text);
        }

        var groupEvent = new Event('publii-cookie-banner-unblock-' + allowedGroup);
        document.body.dispatchEvent(groupEvent);
        unlockEmbeds(allowedGroup);

        if (cbConfig.debugMode) {
            console.log('üç™ Allowed group: ' + allowedGroup);
        }

        if (window.publiiCBGCM && cbConfig.initialLsState.indexOf(allowedGroup) === -1) {
            let consentResult = {};
            let group = window.publiiCBGCM.groups.find(group => group.cookieGroup === allowedGroup);

            if (group) {
                let foundSomeConsents = false;

                Object.keys(group).forEach(key => {
                    if (key !== 'cookieGroup' && group[key] === true) {
                        consentResult[key] = 'granted';
                        foundSomeConsents = true;
                    }
                });

                if (foundSomeConsents) {
                    gtag('consent', 'update', consentResult);   

                    if (cbConfig.debugMode) {
                        console.log('üç™ GCMv2 UPDATE: ' + JSON.stringify(consentResult));
                    }
                }
            }
        }
    }

    function showBannerOrPopup () {
        if (cbUI.popup.element) {
            showAdvancedPopup();
        } else {
            showBanner();
        }
    }

    function showAdvancedPopup () {
        cbUI.popup.element.classList.add('is-visible');
        cbUI.overlay.classList.add('is-visible');
        cbUI.popup.element.setAttribute('aria-hidden', 'false');
        cbUI.overlay.setAttribute('aria-hidden', 'false');
    }

    function hideAdvancedPopup () {
        cbUI.popup.element.classList.remove('is-visible');
        cbUI.overlay.classList.remove('is-visible');
        cbUI.popup.element.setAttribute('aria-hidden', 'true');
        cbUI.overlay.setAttribute('aria-hidden', 'true');
    }

    function showBanner () {
        cbUI.banner.element.classList.add('is-visible');
        cbUI.banner.element.setAttribute('aria-hidden', 'false');
    }

    function hideBanner () {
        cbUI.banner.element.classList.remove('is-visible');
        cbUI.banner.element.setAttribute('aria-hidden', 'true');
    }

    function showBadge () {
        if (!cbUI.badge) {
            return;
        }

        cbUI.badge.classList.add('is-visible');
        cbUI.badge.setAttribute('aria-hidden', 'false');
    }

    function getConfigName () {
        var lsKeyName = 'publii-gdpr-allowed-cookies';

        if (cbConfig.revision) {
            lsKeyName = lsKeyName + '-v' + parseInt(cbConfig.revision, 10);
        }

        return lsKeyName;
    }

    function storeConfiguration (allowedGroups) {
        var lsKeyName = getConfigName();
        var dataToStore = allowedGroups.join(',');
        localStorage.setItem(lsKeyName, dataToStore);

        if (cbConfig.configTTL === 0) {
            localStorage.setItem('publii-gdpr-cookies-config-save-date', 0);

            if (cbConfig.debugMode) {
                console.log('üç™ Store never expiring configuration');
            }
        } else {
            localStorage.setItem('publii-gdpr-cookies-config-save-date', +new Date());
        }
    }

    function getInitialStateOfConsents () {
        if (!cbUI.popup.element) {
            return [];
        }

        var checkedGroups = cbUI.popup.element.querySelectorAll('input[type="checkbox"]:checked');
        var groups = [];

        for (var i = 0; i < checkedGroups.length; i++) {
            var allowedGroup = checkedGroups[i].getAttribute('data-group-name');

            if (allowedGroup !== '') {
                groups.push(allowedGroup);
            }
        }

        if (cbConfig.debugMode) {
            console.log('üç™ Initial state: ' + groups.join(', '));
        }

        return groups;
    }

    function getCurrentStateOfConsents () {
        if (!cbUI.popup.element) {
            return [];
        }

        var checkedGroups = cbUI.popup.element.querySelectorAll('input[type="checkbox"]:checked');
        var groups = [];

        for (var i = 0; i < checkedGroups.length; i++) {
            var allowedGroup = checkedGroups[i].getAttribute('data-group-name');

            if (allowedGroup !== '') {
                groups.push(allowedGroup);
            }
        }

        if (cbConfig.debugMode) {
            console.log('üç™ State to save: ' + groups.join(', '));
        }

        return groups;
    }

    function getAllGroups () {
        if (!cbUI.popup.element) {
            return [];
        }

        var checkedGroups = cbUI.popup.element.querySelectorAll('input[type="checkbox"]');
        var groups = [];

        for (var i = 0; i < checkedGroups.length; i++) {
            var allowedGroup = checkedGroups[i].getAttribute('data-group-name');

            if (allowedGroup !== '') {
                groups.push(allowedGroup);
            }
        }

        return groups;
    }

    function acceptAllCookies (source) {
        var groupsToAccept = getAllGroups();
        storeConfiguration(groupsToAccept);

        for (var i = 0; i < groupsToAccept.length; i++) {
            var group = groupsToAccept[i];

            if (cbConfig.initialState.indexOf(group) > -1 || cbConfig.previouslyAccepted.indexOf(group) > -1) {
                if (cbConfig.debugMode) {
                    console.log('üç™ Skip previously activated group: ' + group);
                }

                continue;
            }

            allowCookieGroup(group);
        }

        if (cbUI.popup.element) {
            var checkboxesToCheck = cbUI.popup.element.querySelectorAll('input[type="checkbox"]');

            for (var j = 0; j < checkboxesToCheck.length; j++) {
                checkboxesToCheck[j].checked = true;
            }
        }

        if (cbConfig.debugMode) {
            console.log('üç™ Accept all cookies: ', groupsToAccept.join(', '));
        }

        if (source === 'popup') {
            hideAdvancedPopup();
        } else if (source === 'banner') {
            hideBanner();
        }
    }

    function rejectAllCookies () {
        if (cbConfig.debugMode) {
            console.log('üç™ Reject all cookies');
        }

        storeConfiguration([]);
        setTimeout(function () {
            window.location.reload();
        }, 100);
    }

    function saveConfiguration () {
        var groupsToAccept = getCurrentStateOfConsents();
        storeConfiguration(groupsToAccept);

        if (cbConfig.debugMode) {
            console.log('üç™ Save new config: ', groupsToAccept.join(', '));
        }

        if (reloadIsNeeded(groupsToAccept)) {
            setTimeout(function () {
                window.location.reload();
            }, 100);
            return;
        }

        for (var i = 0; i < groupsToAccept.length; i++) {
            var group = groupsToAccept[i];

            if (cbConfig.initialState.indexOf(group) > -1 || cbConfig.previouslyAccepted.indexOf(group) > -1) {
                if (cbConfig.debugMode) {
                    console.log('üç™ Skip previously activated group: ' + group);
                }

                continue;
            }

            allowCookieGroup(group);
        }

        hideAdvancedPopup();
    }

    function reloadIsNeeded (groupsToAccept) {
        // check if user rejected consent for initial groups
        var initialGroups = cbConfig.initialState;
        var previouslyAcceptedGroups = cbConfig.previouslyAccepted;
        var groupsToCheck = initialGroups.concat(previouslyAcceptedGroups);

        for (var i = 0; i < groupsToCheck.length; i++) {
            var groupToCheck = groupsToCheck[i];

            if (groupToCheck !== '' && groupsToAccept.indexOf(groupToCheck) === -1) {
                if (cbConfig.debugMode) {
                    console.log('üç™ Reload is needed due lack of: ', groupToCheck);
                }

                return true;
            }
        }

        return false;
    }

    function unlockEmbeds (cookieGroup) {
        var iframesToUnlock = document.querySelectorAll('.pec-wrapper[data-consent-group-id="' + cookieGroup + '"]');

        for (var i = 0; i < iframesToUnlock.length; i++) {
            var iframeWrapper = iframesToUnlock[i];
            iframeWrapper.querySelector('.pec-overlay').classList.remove('is-active');
            iframeWrapper.querySelector('.pec-overlay').setAttribute('aria-hidden', 'true');
            var iframe = iframeWrapper.querySelector('iframe');
            iframe.setAttribute('src', iframe.getAttribute('data-consent-src'));
        }
    }

    win.publiiEmbedConsentGiven = function (cookieGroup) {
        // it will unlock embeds
        allowCookieGroup(cookieGroup);

        var checkbox = cbUI.popup.element.querySelector('input[type="checkbox"][data-group-name="' + cookieGroup + '"]');

        if (checkbox) {
            checkbox.checked = true;
        }

        var groupsToAccept = getCurrentStateOfConsents();
        storeConfiguration(groupsToAccept);

        if (cbConfig.debugMode) {
            console.log('üç™ Save new config: ', groupsToAccept.join(', '));
        }
    }
})(window);</script></body></html>